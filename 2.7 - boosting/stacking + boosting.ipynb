{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking + Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные из файлов\n",
    "train = pd.read_csv('./titanic/train.csv')\n",
    "test = pd.read_csv('./titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Заполняем пропуски в данных медианными \n",
    "# значениями факторов на обучающей выборке\n",
    "train_median = train.median()\n",
    "train_imp = train.fillna(train_median)\n",
    "test_imp = test.fillna(train_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Бинаризуем категориальные признаки\n",
    "CATEGORY_COL = ['Sex', 'Pclass', 'Embarked']\n",
    "train_dummies = pd.get_dummies(train_imp, columns=CATEGORY_COL, drop_first=True)\n",
    "test_dummies = pd.get_dummies(test_imp, columns=CATEGORY_COL, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived                                               Name  \\\n",
       "0            1         0                            Braund, Mr. Owen Harris   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3         1                             Heikkinen, Miss. Laina   \n",
       "3            4         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5         0                           Allen, Mr. William Henry   \n",
       "\n",
       "    Age  SibSp  Parch            Ticket     Fare Cabin  Sex_male  Pclass_2  \\\n",
       "0  22.0      1      0         A/5 21171   7.2500   NaN         1         0   \n",
       "1  38.0      1      0          PC 17599  71.2833   C85         0         0   \n",
       "2  26.0      0      0  STON/O2. 3101282   7.9250   NaN         0         0   \n",
       "3  35.0      1      0            113803  53.1000  C123         0         0   \n",
       "4  35.0      0      0            373450   8.0500   NaN         1         0   \n",
       "\n",
       "   Pclass_3  Embarked_Q  Embarked_S  \n",
       "0         1           0           1  \n",
       "1         0           0           0  \n",
       "2         1           0           1  \n",
       "3         0           0           1  \n",
       "4         1           0           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Удаляем лишние столбцы\n",
    "DROP_COL = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "TARGET_COL = 'Survived'\n",
    "X_train = train_dummies.drop(DROP_COL + [TARGET_COL], axis=1)\n",
    "y_train = train_dummies[TARGET_COL]\n",
    "X_test = test_dummies.drop(DROP_COL, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тюнинг моделей. Зададим сетку параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "params_grid = { # параметры для RandomForest, которые будем тюнить\n",
    "    'n_estimators': [1, 2, 3, 10, 35],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тюнинг моделей. Способ 1\n",
    "\"В лоб\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training RandomForest with params: ', {'n_estimators': 1, 'min_samples_split': 2})\n",
      "('AUC: ', 0.75210960084529987)\n",
      "('Training RandomForest with params: ', {'n_estimators': 2, 'min_samples_split': 2})\n",
      "('AUC: ', 0.79340329270369825)\n",
      "('Training RandomForest with params: ', {'n_estimators': 3, 'min_samples_split': 2})\n",
      "('AUC: ', 0.80574959957490788)\n",
      "('Training RandomForest with params: ', {'n_estimators': 10, 'min_samples_split': 2})\n",
      "('AUC: ', 0.84571873998401959)\n",
      "('Training RandomForest with params: ', {'n_estimators': 35, 'min_samples_split': 2})\n",
      "('AUC: ', 0.86076202468700047)\n",
      "('Training RandomForest with params: ', {'n_estimators': 1, 'min_samples_split': 5})\n",
      "('AUC: ', 0.75914315567328317)\n",
      "('Training RandomForest with params: ', {'n_estimators': 2, 'min_samples_split': 5})\n",
      "('AUC: ', 0.8244216183712324)\n",
      "('Training RandomForest with params: ', {'n_estimators': 3, 'min_samples_split': 5})\n",
      "('AUC: ', 0.82958903644430793)\n",
      "('Training RandomForest with params: ', {'n_estimators': 10, 'min_samples_split': 5})\n",
      "('AUC: ', 0.85259364015117245)\n",
      "('Training RandomForest with params: ', {'n_estimators': 35, 'min_samples_split': 5})\n",
      "('AUC: ', 0.86555876017257172)\n",
      "('Training RandomForest with params: ', {'n_estimators': 1, 'min_samples_split': 10})\n",
      "('AUC: ', 0.80809085174144957)\n",
      "('Training RandomForest with params: ', {'n_estimators': 2, 'min_samples_split': 10})\n",
      "('AUC: ', 0.85430932883840971)\n",
      "('Training RandomForest with params: ', {'n_estimators': 3, 'min_samples_split': 10})\n",
      "('AUC: ', 0.84425840762115389)\n",
      "('Training RandomForest with params: ', {'n_estimators': 10, 'min_samples_split': 10})\n",
      "('AUC: ', 0.85939346282206663)\n",
      "('Training RandomForest with params: ', {'n_estimators': 35, 'min_samples_split': 10})\n",
      "('AUC: ', 0.8699303752068166)\n",
      "Best params:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 10, 'n_estimators': 35}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True) # Всегда делайте shuffle если обучаете не на последовательных данных!\n",
    "\n",
    "# Переберём все возможные комбинации параметров\n",
    "params = [{}]\n",
    "for parameter_name in params_grid:\n",
    "    parameter_values = params_grid[parameter_name]\n",
    "    new_params = []\n",
    "    for value in parameter_values:    \n",
    "        for param in params:\n",
    "            updated_param = param.copy()\n",
    "            updated_param[parameter_name] = value\n",
    "            new_params.append(updated_param)\n",
    "    params = new_params\n",
    "    \n",
    "# Выберем из всех вариаций параметров наилучшую\n",
    "best_params = {}\n",
    "best_auc = 0\n",
    "for param in params:\n",
    "    print(('Training RandomForest with params: ', param))\n",
    "    clf.set_params(**param)\n",
    "    \n",
    "    fold_aucs = []\n",
    "    for train_idx, test_idx in kf.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "        clf.fit(X_train_fold, y_train_fold)\n",
    "        preds = clf.predict_proba(X_test_fold)\n",
    "        auc = roc_auc_score(y_test_fold, preds[:, 1])\n",
    "        fold_aucs.append(auc)\n",
    "    auc = np.mean(fold_aucs)\n",
    "    print(('AUC: ', auc))\n",
    "    if auc > best_auc:\n",
    "        best_params = param\n",
    "        best_auc = auc\n",
    "\n",
    "print('Best params:')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тюнинг моделей. Способ 2\n",
    "Используем GridSearchCV cо своим KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "[CV] min_samples_split=2, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=1, score=0.7623318385650224, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=1, score=0.726457399103139, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=1, score=0.7623318385650224, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=1, score=0.7837837837837838, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=2, score=0.7802690582959642, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=2, score=0.7309417040358744, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=2, score=0.7892376681614349, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=2, score=0.8288288288288288, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=3, score=0.7354260089686099, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=3, score=0.757847533632287, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=3, score=0.7802690582959642, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=3, score=0.7882882882882883, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=2, n_estimators=10, score=0.8026905829596412, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=2, n_estimators=10, score=0.7668161434977578, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=2, n_estimators=10, score=0.8340807174887892, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=2, n_estimators=10, score=0.8153153153153153, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=35 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=2, n_estimators=35, score=0.7937219730941704, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=35 ............................\n",
      "[CV]  min_samples_split=2, n_estimators=35, score=0.7847533632286996, total=   0.1s\n",
      "[CV] min_samples_split=2, n_estimators=35 ............................\n",
      "[CV]  min_samples_split=2, n_estimators=35, score=0.8340807174887892, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=35 ............................\n",
      "[CV]  min_samples_split=2, n_estimators=35, score=0.8378378378378378, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=1, score=0.726457399103139, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=1, score=0.726457399103139, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=1, score=0.8116591928251121, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=1, score=0.7612612612612613, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=2, score=0.7892376681614349, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=2, score=0.7892376681614349, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=2, score=0.7847533632286996, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=2, score=0.7972972972972973, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=3, score=0.7847533632286996, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=3, score=0.7488789237668162, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=3, score=0.820627802690583, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=3, score=0.8108108108108109, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=10, score=0.7847533632286996, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=10, score=0.7802690582959642, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=10, score=0.8565022421524664, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=10, score=0.8513513513513513, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=35 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=35, score=0.8071748878923767, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=35 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=35, score=0.820627802690583, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=35 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=35, score=0.8565022421524664, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=35 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=35, score=0.8603603603603603, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=1 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=1, score=0.7623318385650224, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=1 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=1, score=0.7713004484304933, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=1 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=1, score=0.7982062780269058, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=1 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=1, score=0.7432432432432432, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=2 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=2, score=0.7847533632286996, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=2 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=2, score=0.7488789237668162, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=2 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=2, score=0.8251121076233184, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=2 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=2, score=0.8243243243243243, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=3 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=3, score=0.7668161434977578, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=3 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=3, score=0.7937219730941704, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=3 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=3, score=0.8161434977578476, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=3 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=3, score=0.8423423423423423, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=10, score=0.8071748878923767, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=10, score=0.7668161434977578, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=10, score=0.8161434977578476, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=10, score=0.8378378378378378, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=35 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=35, score=0.8295964125560538, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=35 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=35, score=0.8026905829596412, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=35 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=35, score=0.8475336322869955, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=35 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=35, score=0.8603603603603603, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=4, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=35, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [1, 2, 3, 10, 35], 'min_samples_split': [2, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "# функция, скор которой будет выводиться в гридсёче\n",
    "roc_scorer = make_scorer(lambda y_true, y_pred: roc_auc_score(y_true, y_pred[:, 1]), needs_proba=True)\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "gs = GridSearchCV(clf, param_grid=params_grid, verbose=5, scoring=\"accuracy\", cv=kf)\n",
    "# запуск гридсёча\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.83613916947250277, {'min_samples_split': 5, 'n_estimators': 35})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_, gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=35, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тюнинг моделей. Способ 3\n",
    "Ипользуем GridSearchCV со встроенным KFold и встроенной метрикой качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "[CV] min_samples_split=2, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=1, score=0.7366071428571429, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=1, score=0.7757847533632287, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=1, score=0.7432432432432432, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=1, score=0.7612612612612613, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=2, score=0.7366071428571429, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=2, score=0.8340807174887892, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=2, score=0.7612612612612613, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=2, score=0.7522522522522522, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=3, score=0.7544642857142857, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=3, score=0.8026905829596412, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=3, score=0.7702702702702703, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=2, n_estimators=3, score=0.7927927927927928, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=2, n_estimators=10, score=0.7589285714285714, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=2, n_estimators=10, score=0.8251121076233184, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=2, n_estimators=10, score=0.7972972972972973, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=2, n_estimators=10, score=0.7927927927927928, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=35 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=2, n_estimators=35, score=0.7767857142857143, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=35 ............................\n",
      "[CV]  min_samples_split=2, n_estimators=35, score=0.8385650224215246, total=   0.1s\n",
      "[CV] min_samples_split=2, n_estimators=35 ............................\n",
      "[CV]  min_samples_split=2, n_estimators=35, score=0.8108108108108109, total=   0.0s\n",
      "[CV] min_samples_split=2, n_estimators=35 ............................\n",
      "[CV]  min_samples_split=2, n_estimators=35, score=0.8108108108108109, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=1, score=0.7276785714285714, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=1, score=0.7399103139013453, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=1, score=0.8063063063063063, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=1 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=1, score=0.7297297297297297, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=2, score=0.7678571428571429, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=2, score=0.8295964125560538, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=2, score=0.7837837837837838, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=2 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=2, score=0.8063063063063063, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=3, score=0.7544642857142857, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=3, score=0.8430493273542601, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=3, score=0.8153153153153153, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=3 .............................\n",
      "[CV]  min_samples_split=5, n_estimators=3, score=0.8018018018018018, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=10, score=0.78125, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=10, score=0.8385650224215246, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=10, score=0.8288288288288288, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=10 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=10, score=0.8153153153153153, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=35 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=35, score=0.78125, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=35 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=35, score=0.8609865470852018, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=35 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=35, score=0.8198198198198198, total=   0.0s\n",
      "[CV] min_samples_split=5, n_estimators=35 ............................\n",
      "[CV]  min_samples_split=5, n_estimators=35, score=0.8333333333333334, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=1 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=1, score=0.71875, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=1 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=1, score=0.7847533632286996, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=1 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=1, score=0.7747747747747747, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=1 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=1, score=0.7792792792792793, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=2 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=2, score=0.7455357142857143, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=2 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=2, score=0.8161434977578476, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=2 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=2, score=0.7792792792792793, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=2 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=2, score=0.7837837837837838, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=3 ............................\n",
      "[CV] . min_samples_split=10, n_estimators=3, score=0.75, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=3 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=3, score=0.8385650224215246, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=3 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=3, score=0.7747747747747747, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=3 ............................\n",
      "[CV]  min_samples_split=10, n_estimators=3, score=0.7927927927927928, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=10, score=0.7589285714285714, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=10, score=0.852017937219731, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=10, score=0.8243243243243243, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=10 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=10, score=0.8378378378378378, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=35 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=35, score=0.7901785714285714, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=35 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=35, score=0.8430493273542601, total=   0.1s\n",
      "[CV] min_samples_split=10, n_estimators=35 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=35, score=0.8243243243243243, total=   0.0s\n",
      "[CV] min_samples_split=10, n_estimators=35 ...........................\n",
      "[CV]  min_samples_split=10, n_estimators=35, score=0.8423423423423423, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=35, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [1, 2, 3, 10, 35], 'min_samples_split': [2, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(clf, param_grid=params_grid, verbose=5, cv=4)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тюнинг моделей. Способ 4\n",
    "Используя OOB-score (работает только для НЕбустинговых ансамблей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training RandomForest with params: ', {'n_estimators': 1, 'min_samples_split': 2})\n",
      "('OOB: ', 0.66778900112233441)\n",
      "('Training RandomForest with params: ', {'n_estimators': 2, 'min_samples_split': 2})\n",
      "('OOB: ', 0.70145903479236815)\n",
      "('Training RandomForest with params: ', {'n_estimators': 3, 'min_samples_split': 2})\n",
      "('OOB: ', 0.72390572390572394)\n",
      "('Training RandomForest with params: ', {'n_estimators': 10, 'min_samples_split': 2})\n",
      "('OOB: ', 0.80246913580246915)\n",
      "('Training RandomForest with params: ', {'n_estimators': 35, 'min_samples_split': 2})\n",
      "('OOB: ', 0.81369248035914699)\n",
      "('Training RandomForest with params: ', {'n_estimators': 1, 'min_samples_split': 5})\n",
      "('OOB: ', 0.66442199775533106)\n",
      "('Training RandomForest with params: ', {'n_estimators': 2, 'min_samples_split': 5})\n",
      "('OOB: ', 0.73961840628507292)\n",
      "('Training RandomForest with params: ', {'n_estimators': 3, 'min_samples_split': 5})\n",
      "('OOB: ', 0.73737373737373735)\n",
      "('Training RandomForest with params: ', {'n_estimators': 10, 'min_samples_split': 5})\n",
      "('OOB: ', 0.78563411896745228)\n",
      "('Training RandomForest with params: ', {'n_estimators': 35, 'min_samples_split': 5})\n",
      "('OOB: ', 0.8271604938271605)\n",
      "('Training RandomForest with params: ', {'n_estimators': 1, 'min_samples_split': 10})\n",
      "('OOB: ', 0.67789001122334458)\n",
      "('Training RandomForest with params: ', {'n_estimators': 2, 'min_samples_split': 10})\n",
      "('OOB: ', 0.72166105499438837)\n",
      "('Training RandomForest with params: ', {'n_estimators': 3, 'min_samples_split': 10})\n",
      "('OOB: ', 0.75196408529741865)\n",
      "('Training RandomForest with params: ', {'n_estimators': 10, 'min_samples_split': 10})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('OOB: ', 0.80471380471380471)\n",
      "('Training RandomForest with params: ', {'n_estimators': 35, 'min_samples_split': 10})\n",
      "('OOB: ', 0.82379349046015715)\n",
      "Best params:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:453: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 5, 'n_estimators': 35}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True) # Всегда делайте shuffle если обучаете не на последовательных данных!\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "\n",
    "# Опять создадим всевозможные комбинации параметров модели\n",
    "params = [{}]\n",
    "for parameter_name in params_grid:\n",
    "    parameter_values = params_grid[parameter_name]\n",
    "    new_params = []\n",
    "    for value in parameter_values:    \n",
    "        for param in params:\n",
    "            updated_param = param.copy()\n",
    "            updated_param[parameter_name] = value\n",
    "            new_params.append(updated_param)\n",
    "    params = new_params\n",
    "    \n",
    "for param in params:\n",
    "    print(('Training RandomForest with params: ', param))\n",
    "    clf.set_params(**param)\n",
    "    clf.set_params(oob_score=True)\n",
    "    \n",
    "    # Это то, что нам требовалось делать раньше\n",
    "#     fold_aucs = []\n",
    "#     for train_idx, test_idx in kf.split(X_train):\n",
    "#         X_train_fold, X_test_fold = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "#         y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "#         clf.fit(X_train_fold, y_train_fold)\n",
    "#         preds = clf.predict_proba(X_test_fold)\n",
    "#         auc = roc_auc_score(y_test_fold, preds[:, 1])\n",
    "#         fold_aucs.append(auc)\n",
    "#     print(('AUC: ', np.mean(fold_aucs)))\n",
    "\n",
    "    # А это то, что мы можем делать сейчас без всех махинаций с KFold'ом выше\n",
    "    clf.fit(X_train, y_train)\n",
    "    oob_score = clf.oob_score_\n",
    "    \n",
    "    print(('OOB: ', oob_score))\n",
    "    if oob_score > best_score:\n",
    "        best_score = oob_score\n",
    "        best_params = param\n",
    "\n",
    "print('Best params:')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическое задание 1\n",
    "Используя понравившийся метод, попробуйте подобрать самые важные на ваш взгляд параметры для RandomForestClassifier и GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "[CV] min_samples_split=2 .............................................\n",
      "[CV] .... min_samples_split=2, score=0.7991071428571429, total=   0.1s\n",
      "[CV] min_samples_split=2 .............................................\n",
      "[CV] .... min_samples_split=2, score=0.8565022421524664, total=   0.1s\n",
      "[CV] min_samples_split=2 .............................................\n",
      "[CV] .... min_samples_split=2, score=0.8108108108108109, total=   0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] min_samples_split=2 .............................................\n",
      "[CV] .... min_samples_split=2, score=0.8378378378378378, total=   0.1s\n",
      "[CV] min_samples_split=3 .............................................\n",
      "[CV] .... min_samples_split=3, score=0.7991071428571429, total=   0.1s\n",
      "[CV] min_samples_split=3 .............................................\n",
      "[CV] .... min_samples_split=3, score=0.8565022421524664, total=   0.1s\n",
      "[CV] min_samples_split=3 .............................................\n",
      "[CV] .... min_samples_split=3, score=0.8153153153153153, total=   0.1s\n",
      "[CV] min_samples_split=3 .............................................\n",
      "[CV] .... min_samples_split=3, score=0.8378378378378378, total=   0.1s\n",
      "[CV] min_samples_split=4 .............................................\n",
      "[CV] .... min_samples_split=4, score=0.7946428571428571, total=   0.1s\n",
      "[CV] min_samples_split=4 .............................................\n",
      "[CV] .... min_samples_split=4, score=0.8565022421524664, total=   0.1s\n",
      "[CV] min_samples_split=4 .............................................\n",
      "[CV] .... min_samples_split=4, score=0.8153153153153153, total=   0.1s\n",
      "[CV] min_samples_split=4 .............................................\n",
      "[CV] .... min_samples_split=4, score=0.8378378378378378, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': [2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_estimator = GradientBoostingClassifier()\n",
    "gs = GridSearchCV(gb_estimator, param_grid={\"min_samples_split\" : [2,3,4]}, verbose=5, cv=4)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание моделей для стеккинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание моделей для стекинга. Способ 1\n",
    "\"В лоб\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\artem\\anaconda3\\envs\\lasagne2.7\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: assignment will raise an error in the future, most likely because your index result shape does not match the value array shape. You can use `arr.flat[index] = values` to keep the old behaviour.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def cross_val_predict_proba(estimator, X_train, y_train):\n",
    "    kfold = KFold(n_splits=4, shuffle=True, random_state=None)\n",
    "    estimator_scores = np.zeros_like(y_train)\n",
    "    for train_idx, test_idx in kfold.split(X_train):\n",
    "        X_train_fold, X_pred_fold = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "        y_train_fold, _ = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "        estimator.fit(X_train_fold, y_train_fold)\n",
    "        estimator_scores[test_idx] = estimator.predict_proba(X_test_fold)[:, 1]\n",
    "    return estimator_scores\n",
    "#     return cross_val_predict(estimator, X_train, y_train, cv=kfold, method='predict_proba')\n",
    "\n",
    "# инициализирем модели с подобранными гиперпараметрами\n",
    "rf_estimator = RandomForestClassifier()\n",
    "gb_estimator = GradientBoostingClassifier()\n",
    "\n",
    "# получаем предсказания вероятностей ансамблей на кросс-валидации для обучающей выборки\n",
    "rf_train_pred = cross_val_predict_proba(rf_estimator, X_train, y_train)\n",
    "gb_train_pred = cross_val_predict_proba(gb_estimator, X_train, y_train)\n",
    "\n",
    "X_train_stack = np.stack([rf_train_pred, gb_train_pred], axis=1)\n",
    "\n",
    "# получаем предсказания ансамблей для тестовой выборки\n",
    "rf_test_pred = rf_estimator.fit(X_train, y_train).predict_proba(X_test)\n",
    "gb_test_pred = gb_estimator.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "X_test_stack = np.stack([rf_test_pred[:,1], gb_test_pred[:,1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.04635935],\n",
       "       [ 0.3       ,  0.12779691],\n",
       "       [ 0.2       ,  0.13986669],\n",
       "       [ 0.4       ,  0.14068034],\n",
       "       [ 0.4       ,  0.4036792 ],\n",
       "       [ 0.1       ,  0.11170511],\n",
       "       [ 0.4       ,  0.24903108],\n",
       "       [ 0.        ,  0.28030803],\n",
       "       [ 0.9       ,  0.90190717],\n",
       "       [ 0.1       ,  0.08107034],\n",
       "       [ 0.        ,  0.09280331],\n",
       "       [ 0.        ,  0.07143607],\n",
       "       [ 1.        ,  0.933683  ],\n",
       "       [ 0.1       ,  0.12858014],\n",
       "       [ 1.        ,  0.86025295],\n",
       "       [ 1.        ,  0.9270053 ],\n",
       "       [ 0.        ,  0.07317554],\n",
       "       [ 0.7       ,  0.16838866],\n",
       "       [ 0.6       ,  0.53839304],\n",
       "       [ 0.5       ,  0.37241087],\n",
       "       [ 0.6       ,  0.28427084],\n",
       "       [ 0.6       ,  0.49216374],\n",
       "       [ 1.        ,  0.94539501],\n",
       "       [ 0.7       ,  0.40325586],\n",
       "       [ 0.9       ,  0.93250822],\n",
       "       [ 0.1       ,  0.04924125],\n",
       "       [ 1.        ,  0.95974208],\n",
       "       [ 0.7       ,  0.16838866],\n",
       "       [ 0.4       ,  0.43061574],\n",
       "       [ 0.        ,  0.17336078],\n",
       "       [ 0.        ,  0.05823568],\n",
       "       [ 0.2       ,  0.1923209 ],\n",
       "       [ 0.6       ,  0.50726612],\n",
       "       [ 0.1       ,  0.25099956],\n",
       "       [ 0.6       ,  0.53977726],\n",
       "       [ 0.7       ,  0.16838866],\n",
       "       [ 0.        ,  0.33989061],\n",
       "       [ 0.        ,  0.30641091],\n",
       "       [ 0.        ,  0.10705655],\n",
       "       [ 0.36833333,  0.51538584],\n",
       "       [ 0.2       ,  0.07686773],\n",
       "       [ 0.63166667,  0.42756762],\n",
       "       [ 0.        ,  0.06766657],\n",
       "       [ 1.        ,  0.89145109],\n",
       "       [ 1.        ,  0.95523579],\n",
       "       [ 0.1       ,  0.13276729],\n",
       "       [ 0.3       ,  0.17678256],\n",
       "       [ 0.13502747,  0.143781  ],\n",
       "       [ 1.        ,  0.95422915],\n",
       "       [ 0.8       ,  0.59789748],\n",
       "       [ 0.5       ,  0.25850309],\n",
       "       [ 0.        ,  0.12899341],\n",
       "       [ 1.        ,  0.86211146],\n",
       "       [ 0.8       ,  0.78778111],\n",
       "       [ 0.        ,  0.17316565],\n",
       "       [ 0.        ,  0.09133075],\n",
       "       [ 0.        ,  0.07749877],\n",
       "       [ 0.        ,  0.11049537],\n",
       "       [ 0.        ,  0.11898301],\n",
       "       [ 1.        ,  0.9740206 ],\n",
       "       [ 0.1       ,  0.09222655],\n",
       "       [ 0.5       ,  0.15863344],\n",
       "       [ 0.1       ,  0.09709363],\n",
       "       [ 0.9       ,  0.82838183],\n",
       "       [ 0.8       ,  0.60823808],\n",
       "       [ 0.9       ,  0.90368307],\n",
       "       [ 0.8       ,  0.74380762],\n",
       "       [ 0.        ,  0.10948046],\n",
       "       [ 0.1       ,  0.27698585],\n",
       "       [ 0.5       ,  0.89300695],\n",
       "       [ 0.69      ,  0.734608  ],\n",
       "       [ 0.1       ,  0.08830799],\n",
       "       [ 0.1       ,  0.48892562],\n",
       "       [ 0.        ,  0.40744847],\n",
       "       [ 1.        ,  0.9740206 ],\n",
       "       [ 0.5       ,  0.38905539],\n",
       "       [ 0.        ,  0.1226044 ],\n",
       "       [ 1.        ,  0.93709792],\n",
       "       [ 0.1       ,  0.11865336],\n",
       "       [ 0.69      ,  0.734608  ],\n",
       "       [ 0.8       ,  0.92718677],\n",
       "       [ 0.5       ,  0.08564878],\n",
       "       [ 0.        ,  0.24997971],\n",
       "       [ 0.        ,  0.09280331],\n",
       "       [ 0.        ,  0.14521253],\n",
       "       [ 0.2       ,  0.12149639],\n",
       "       [ 1.        ,  0.79078179],\n",
       "       [ 0.1       ,  0.32539677],\n",
       "       [ 0.85455628,  0.74675676],\n",
       "       [ 0.9       ,  0.93481995],\n",
       "       [ 0.3       ,  0.38076489],\n",
       "       [ 0.36666667,  0.09769756],\n",
       "       [ 0.9       ,  0.93138737],\n",
       "       [ 0.        ,  0.1226044 ],\n",
       "       [ 0.3       ,  0.21418987],\n",
       "       [ 0.2       ,  0.09298947],\n",
       "       [ 0.9       ,  0.8920993 ],\n",
       "       [ 0.46666667,  0.14632917],\n",
       "       [ 0.4       ,  0.49552482],\n",
       "       [ 0.        ,  0.14389292],\n",
       "       [ 1.        ,  0.9678034 ],\n",
       "       [ 0.1       ,  0.12652584],\n",
       "       [ 0.13502747,  0.143781  ],\n",
       "       [ 0.075     ,  0.12280274],\n",
       "       [ 0.6       ,  0.56405765],\n",
       "       [ 0.        ,  0.13176177],\n",
       "       [ 0.06190476,  0.14318713],\n",
       "       [ 0.13502747,  0.143781  ],\n",
       "       [ 0.1       ,  0.11835055],\n",
       "       [ 0.        ,  0.1038616 ],\n",
       "       [ 0.16666667,  0.05042036],\n",
       "       [ 0.9875    ,  0.74675676],\n",
       "       [ 0.9       ,  0.96727864],\n",
       "       [ 0.5       ,  0.87436889],\n",
       "       [ 1.        ,  0.96342488],\n",
       "       [ 0.3       ,  0.11984795],\n",
       "       [ 0.        ,  0.04662927],\n",
       "       [ 0.8       ,  0.9068569 ],\n",
       "       [ 0.3       ,  0.49606288],\n",
       "       [ 1.        ,  0.88589999],\n",
       "       [ 0.9       ,  0.90914033],\n",
       "       [ 0.11666667,  0.14598608],\n",
       "       [ 1.        ,  0.96407349],\n",
       "       [ 0.        ,  0.08041879],\n",
       "       [ 0.13502747,  0.143781  ],\n",
       "       [ 0.5       ,  0.56042575],\n",
       "       [ 0.2       ,  0.09298947],\n",
       "       [ 1.        ,  0.69484115],\n",
       "       [ 0.7       ,  0.11378152],\n",
       "       [ 0.        ,  0.11095555],\n",
       "       [ 0.54      ,  0.18867288],\n",
       "       [ 0.3       ,  0.14233578],\n",
       "       [ 0.        ,  0.12315287],\n",
       "       [ 0.1       ,  0.04742693],\n",
       "       [ 0.        ,  0.06425736],\n",
       "       [ 0.        ,  0.08830799],\n",
       "       [ 0.2       ,  0.29378586],\n",
       "       [ 0.        ,  0.13110257],\n",
       "       [ 0.4       ,  0.31500906],\n",
       "       [ 0.        ,  0.08161453],\n",
       "       [ 0.1       ,  0.06264714],\n",
       "       [ 1.        ,  0.95346884],\n",
       "       [ 0.3       ,  0.218996  ],\n",
       "       [ 0.03333333,  0.11775131],\n",
       "       [ 0.64166667,  0.42331732],\n",
       "       [ 0.1       ,  0.25376878],\n",
       "       [ 0.        ,  0.22236284],\n",
       "       [ 0.        ,  0.11095555],\n",
       "       [ 0.63166667,  0.42756762],\n",
       "       [ 0.1       ,  0.11445398],\n",
       "       [ 1.        ,  0.96721923],\n",
       "       [ 0.        ,  0.143781  ],\n",
       "       [ 0.        ,  0.05136264],\n",
       "       [ 0.8       ,  0.50017363],\n",
       "       [ 0.1       ,  0.10345066],\n",
       "       [ 0.3       ,  0.11049537],\n",
       "       [ 1.        ,  0.94224305],\n",
       "       [ 0.5       ,  0.4835994 ],\n",
       "       [ 0.64166667,  0.42331732],\n",
       "       [ 0.8       ,  0.5036295 ],\n",
       "       [ 0.98333333,  0.7597685 ],\n",
       "       [ 0.8       ,  0.83891285],\n",
       "       [ 0.85      ,  0.90200021],\n",
       "       [ 0.4       ,  0.04407746],\n",
       "       [ 0.7       ,  0.11378152],\n",
       "       [ 0.6       ,  0.51072093],\n",
       "       [ 0.4       ,  0.43680829],\n",
       "       [ 0.1       ,  0.21351988],\n",
       "       [ 1.        ,  0.94273852],\n",
       "       [ 0.        ,  0.39508006],\n",
       "       [ 0.025     ,  0.05895964],\n",
       "       [ 0.2       ,  0.29378586],\n",
       "       [ 0.        ,  0.10056546],\n",
       "       [ 0.16261905,  0.11943071],\n",
       "       [ 0.        ,  0.291471  ],\n",
       "       [ 1.        ,  0.93569837],\n",
       "       [ 0.9       ,  0.93418288],\n",
       "       [ 0.5       ,  0.41889695],\n",
       "       [ 1.        ,  0.94667032],\n",
       "       [ 1.        ,  0.91084708],\n",
       "       [ 0.1       ,  0.11865336],\n",
       "       [ 0.5       ,  0.46461641],\n",
       "       [ 1.        ,  0.93810256],\n",
       "       [ 0.13502747,  0.143781  ],\n",
       "       [ 1.        ,  0.9427918 ],\n",
       "       [ 0.        ,  0.11595692],\n",
       "       [ 1.        ,  0.90220398],\n",
       "       [ 0.3       ,  0.09332474],\n",
       "       [ 0.        ,  0.06357947],\n",
       "       [ 0.1       ,  0.11378152],\n",
       "       [ 0.        ,  0.13000345],\n",
       "       [ 0.        ,  0.1561529 ],\n",
       "       [ 0.8       ,  0.3335799 ],\n",
       "       [ 0.2       ,  0.04264624],\n",
       "       [ 0.9       ,  0.76142145],\n",
       "       [ 0.2       ,  0.07749877],\n",
       "       [ 1.        ,  0.94841182],\n",
       "       [ 0.1       ,  0.50972441],\n",
       "       [ 0.        ,  0.09538444],\n",
       "       [ 0.        ,  0.53290095],\n",
       "       [ 0.7       ,  0.77460833],\n",
       "       [ 0.9       ,  0.96157086],\n",
       "       [ 0.2       ,  0.19400841],\n",
       "       [ 1.        ,  0.93939264],\n",
       "       [ 0.        ,  0.09538444],\n",
       "       [ 0.1       ,  0.22502971],\n",
       "       [ 0.07142857,  0.32277869],\n",
       "       [ 0.        ,  0.09538444],\n",
       "       [ 0.9       ,  0.9016968 ],\n",
       "       [ 0.        ,  0.08830799],\n",
       "       [ 0.1       ,  0.20163091],\n",
       "       [ 0.        ,  0.04407746],\n",
       "       [ 0.1       ,  0.28947982],\n",
       "       [ 0.7       ,  0.84695714],\n",
       "       [ 0.5       ,  0.61687149],\n",
       "       [ 0.1       ,  0.22517728],\n",
       "       [ 1.        ,  0.74675676],\n",
       "       [ 0.5       ,  0.17852401],\n",
       "       [ 1.        ,  0.94286626],\n",
       "       [ 0.        ,  0.1226044 ],\n",
       "       [ 1.        ,  0.8304648 ],\n",
       "       [ 0.        ,  0.11095555],\n",
       "       [ 0.9       ,  0.8654484 ],\n",
       "       [ 0.7       ,  0.09298947],\n",
       "       [ 0.8       ,  0.84636558],\n",
       "       [ 0.4       ,  0.61674837],\n",
       "       [ 0.1       ,  0.09298947],\n",
       "       [ 0.85455628,  0.74675676],\n",
       "       [ 0.        ,  0.08995285],\n",
       "       [ 0.15      ,  0.13468658],\n",
       "       [ 0.1       ,  0.31723726],\n",
       "       [ 1.        ,  0.92537407],\n",
       "       [ 0.2       ,  0.07881553],\n",
       "       [ 0.0452381 ,  0.143781  ],\n",
       "       [ 0.5       ,  0.39149902],\n",
       "       [ 0.        ,  0.09222655],\n",
       "       [ 0.5       ,  0.14688554],\n",
       "       [ 0.8       ,  0.16838866],\n",
       "       [ 0.7       ,  0.86561107],\n",
       "       [ 1.        ,  0.97685684],\n",
       "       [ 0.6       ,  0.83009426],\n",
       "       [ 1.        ,  0.94387961],\n",
       "       [ 0.4       ,  0.60670985],\n",
       "       [ 0.        ,  0.09280331],\n",
       "       [ 0.        ,  0.11898301],\n",
       "       [ 0.        ,  0.21229444],\n",
       "       [ 0.8       ,  0.89338678],\n",
       "       [ 0.        ,  0.26154193],\n",
       "       [ 1.        ,  0.88589999],\n",
       "       [ 0.1       ,  0.48779785],\n",
       "       [ 0.8       ,  0.92382854],\n",
       "       [ 0.1       ,  0.13835926],\n",
       "       [ 0.5       ,  0.31283186],\n",
       "       [ 0.        ,  0.10705655],\n",
       "       [ 0.1       ,  0.18260381],\n",
       "       [ 0.025     ,  0.05895964],\n",
       "       [ 0.13502747,  0.143781  ],\n",
       "       [ 0.        ,  0.1226044 ],\n",
       "       [ 0.6       ,  0.87608409],\n",
       "       [ 0.075     ,  0.09298947],\n",
       "       [ 0.        ,  0.09349528],\n",
       "       [ 0.1       ,  0.08830799],\n",
       "       [ 1.        ,  0.90368307],\n",
       "       [ 0.9       ,  0.87106991],\n",
       "       [ 0.1       ,  0.07781196],\n",
       "       [ 0.        ,  0.09280331],\n",
       "       [ 0.        ,  0.04984001],\n",
       "       [ 0.025     ,  0.05895964],\n",
       "       [ 0.        ,  0.33989061],\n",
       "       [ 0.        ,  0.11170511],\n",
       "       [ 0.        ,  0.25967539],\n",
       "       [ 0.13502747,  0.143781  ],\n",
       "       [ 1.        ,  0.95071325],\n",
       "       [ 1.        ,  0.7648824 ],\n",
       "       [ 0.        ,  0.11943071],\n",
       "       [ 1.        ,  0.87913146],\n",
       "       [ 0.        ,  0.1055927 ],\n",
       "       [ 0.        ,  0.10452644],\n",
       "       [ 0.        ,  0.11445398],\n",
       "       [ 0.        ,  0.09538444],\n",
       "       [ 0.2       ,  0.30641091],\n",
       "       [ 1.        ,  0.96606185],\n",
       "       [ 0.85455628,  0.74675676],\n",
       "       [ 0.2       ,  0.61222716],\n",
       "       [ 0.7       ,  0.74673841],\n",
       "       [ 0.        ,  0.06354079],\n",
       "       [ 0.        ,  0.08041879],\n",
       "       [ 0.5       ,  0.29218307],\n",
       "       [ 0.16261905,  0.11943071],\n",
       "       [ 0.        ,  0.1226044 ],\n",
       "       [ 0.1       ,  0.22236284],\n",
       "       [ 0.2       ,  0.04643762],\n",
       "       [ 0.16261905,  0.11943071],\n",
       "       [ 0.2       ,  0.28875737],\n",
       "       [ 0.        ,  0.13901748],\n",
       "       [ 0.        ,  0.11681365],\n",
       "       [ 0.8       ,  0.95282152],\n",
       "       [ 0.        ,  0.17336078],\n",
       "       [ 0.        ,  0.23731504],\n",
       "       [ 0.        ,  0.09280331],\n",
       "       [ 0.3       ,  0.11680812],\n",
       "       [ 0.        ,  0.1035727 ],\n",
       "       [ 0.2       ,  0.09116075],\n",
       "       [ 0.        ,  0.10705655],\n",
       "       [ 0.85455628,  0.74675676],\n",
       "       [ 1.        ,  0.820862  ],\n",
       "       [ 0.7       ,  0.21234428],\n",
       "       [ 0.5       ,  0.88979569],\n",
       "       [ 0.3       ,  0.25145942],\n",
       "       [ 0.2       ,  0.24700638],\n",
       "       [ 0.        ,  0.11170511],\n",
       "       [ 0.7       ,  0.16838866],\n",
       "       [ 0.025     ,  0.05895964],\n",
       "       [ 0.07142857,  0.32856687],\n",
       "       [ 1.        ,  0.96183782],\n",
       "       [ 1.        ,  0.80689355],\n",
       "       [ 0.5       ,  0.36615647],\n",
       "       [ 0.6       ,  0.0995827 ],\n",
       "       [ 0.2       ,  0.11681365],\n",
       "       [ 0.2       ,  0.1923209 ],\n",
       "       [ 0.075     ,  0.12280274],\n",
       "       [ 0.125     ,  0.16838866],\n",
       "       [ 0.        ,  0.13110257],\n",
       "       [ 0.96666667,  0.48445859],\n",
       "       [ 1.        ,  0.95128763],\n",
       "       [ 0.        ,  0.06729135],\n",
       "       [ 1.        ,  0.89447865],\n",
       "       [ 0.        ,  0.25967539],\n",
       "       [ 0.2       ,  0.10616519],\n",
       "       [ 0.        ,  0.09950288],\n",
       "       [ 1.        ,  0.91019957],\n",
       "       [ 0.4       ,  0.20269902],\n",
       "       [ 0.        ,  0.11943071],\n",
       "       [ 0.5       ,  0.77906839],\n",
       "       [ 0.1       ,  0.11681365],\n",
       "       [ 0.1       ,  0.1676126 ],\n",
       "       [ 0.9       ,  0.15863344],\n",
       "       [ 0.2       ,  0.03624029],\n",
       "       [ 0.1       ,  0.26580871],\n",
       "       [ 0.16261905,  0.11943071],\n",
       "       [ 0.6       ,  0.0995827 ],\n",
       "       [ 0.3       ,  0.0710897 ],\n",
       "       [ 0.        ,  0.33329667],\n",
       "       [ 1.        ,  0.96689893],\n",
       "       [ 0.2       ,  0.08919559],\n",
       "       [ 0.8       ,  0.63349755],\n",
       "       [ 0.        ,  0.13110257],\n",
       "       [ 0.5       ,  0.46049764],\n",
       "       [ 0.        ,  0.09950288],\n",
       "       [ 0.9       ,  0.93463329],\n",
       "       [ 1.        ,  0.94972747],\n",
       "       [ 0.        ,  0.09538444],\n",
       "       [ 0.        ,  0.21282175],\n",
       "       [ 0.        ,  0.17553312],\n",
       "       [ 0.7       ,  0.89066072],\n",
       "       [ 0.        ,  0.08787451],\n",
       "       [ 1.        ,  0.95442674],\n",
       "       [ 0.        ,  0.09280331],\n",
       "       [ 0.13502747,  0.143781  ],\n",
       "       [ 0.8       ,  0.52678194],\n",
       "       [ 0.        ,  0.08507934],\n",
       "       [ 1.        ,  0.95080681],\n",
       "       [ 0.9       ,  0.93463329],\n",
       "       [ 0.4       ,  0.14068034],\n",
       "       [ 1.        ,  0.96965914],\n",
       "       [ 0.        ,  0.36163566],\n",
       "       [ 0.2       ,  0.12149639],\n",
       "       [ 0.4       ,  0.24744017],\n",
       "       [ 1.        ,  0.94972747],\n",
       "       [ 0.5       ,  0.30147238],\n",
       "       [ 0.2       ,  0.0895301 ],\n",
       "       [ 1.        ,  0.98060937],\n",
       "       [ 0.        ,  0.07103592],\n",
       "       [ 0.53333333,  0.08940349],\n",
       "       [ 1.        ,  0.94252762],\n",
       "       [ 1.        ,  0.96023829],\n",
       "       [ 0.        ,  0.21097936],\n",
       "       [ 0.1       ,  0.09950288],\n",
       "       [ 0.2       ,  0.11217123],\n",
       "       [ 0.4       ,  0.37286671],\n",
       "       [ 0.13502747,  0.143781  ],\n",
       "       [ 0.1452381 ,  0.18579748],\n",
       "       [ 0.7       ,  0.32234323],\n",
       "       [ 0.4       ,  0.4893615 ],\n",
       "       [ 0.33333333,  0.11009826],\n",
       "       [ 1.        ,  0.9220133 ],\n",
       "       [ 0.375     ,  0.09298947],\n",
       "       [ 0.1       ,  0.05996978],\n",
       "       [ 0.06190476,  0.14318713],\n",
       "       [ 0.3       ,  0.08305956],\n",
       "       [ 0.4       ,  0.32427697],\n",
       "       [ 1.        ,  0.92112937],\n",
       "       [ 0.6       ,  0.43683629],\n",
       "       [ 0.2       ,  0.05045418],\n",
       "       [ 0.        ,  0.03418965],\n",
       "       [ 1.        ,  0.92267003],\n",
       "       [ 0.        ,  0.16838866],\n",
       "       [ 1.        ,  0.95204363],\n",
       "       [ 0.075     ,  0.09298947],\n",
       "       [ 0.        ,  0.05942607],\n",
       "       [ 1.        ,  0.94667309],\n",
       "       [ 0.        ,  0.10038653],\n",
       "       [ 1.        ,  0.95974208],\n",
       "       [ 0.2       ,  0.21127663],\n",
       "       [ 0.1       ,  0.18378684],\n",
       "       [ 0.2       ,  0.14914084],\n",
       "       [ 0.        ,  0.08578511],\n",
       "       [ 0.2       ,  0.23161698],\n",
       "       [ 0.98333333,  0.64665111],\n",
       "       [ 0.7       ,  0.82498269],\n",
       "       [ 0.85455628,  0.74675676],\n",
       "       [ 1.        ,  0.9608066 ],\n",
       "       [ 0.1       ,  0.52602653],\n",
       "       [ 0.        ,  0.1226044 ],\n",
       "       [ 1.        ,  0.96513322],\n",
       "       [ 0.        ,  0.05537313],\n",
       "       [ 0.        ,  0.1226044 ],\n",
       "       [ 0.5       ,  0.20043982]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание моделей для стекинга. Способ 2\n",
    "Красивый с использованием метода cross_val_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "def cross_val_predict_proba(estimator, X_train, y_train):\n",
    "    kfold = KFold(n_splits=4, shuffle=True, random_state=None)\n",
    "    return cross_val_predict(estimator, X_train, y_train, cv=kfold, method='predict_proba')\n",
    "\n",
    "# TODO: подобрать гиперпараметры для ансамблей\n",
    "\n",
    "# инициализирем модели с подобранными гиперпараметрами\n",
    "rf_estimator = RandomForestClassifier()\n",
    "gb_estimator = GradientBoostingClassifier()\n",
    "\n",
    "# получаем предсказания вероятностей ансамблей на кросс-валидации для обучающей выборки\n",
    "rf_train_pred = cross_val_predict_proba(rf_estimator, X_train, y_train)\n",
    "gb_train_pred = cross_val_predict_proba(gb_estimator, X_train, y_train)\n",
    "\n",
    "X_train_stack = np.stack([rf_train_pred[:, 1], gb_train_pred[:, 1]], axis=1)\n",
    "\n",
    "# получаем предсказания ансамблей для тестовой выборки\n",
    "rf_test_pred = rf_estimator.fit(X_train, y_train).predict_proba(X_test)\n",
    "gb_test_pred = gb_estimator.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "X_test_stack = np.stack([rf_test_pred[:,1], gb_test_pred[:,1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.04635935],\n",
       "       [ 0.2       ,  0.12779691],\n",
       "       [ 0.        ,  0.13986669],\n",
       "       [ 0.9       ,  0.14068034],\n",
       "       [ 0.2       ,  0.4036792 ],\n",
       "       [ 0.1       ,  0.11170511],\n",
       "       [ 0.29166667,  0.24903108],\n",
       "       [ 0.        ,  0.28030803],\n",
       "       [ 0.7       ,  0.90190717],\n",
       "       [ 0.1       ,  0.08107034],\n",
       "       [ 0.        ,  0.09280331],\n",
       "       [ 0.2       ,  0.07143607],\n",
       "       [ 1.        ,  0.933683  ],\n",
       "       [ 0.        ,  0.12858014],\n",
       "       [ 1.        ,  0.86025295],\n",
       "       [ 0.8       ,  0.9270053 ],\n",
       "       [ 0.1       ,  0.07317554],\n",
       "       [ 0.9       ,  0.16838866],\n",
       "       [ 0.4       ,  0.53839304],\n",
       "       [ 0.7       ,  0.37241087],\n",
       "       [ 0.7       ,  0.28427084],\n",
       "       [ 0.6       ,  0.49216374],\n",
       "       [ 1.        ,  0.94539501],\n",
       "       [ 0.7       ,  0.40325586],\n",
       "       [ 0.9       ,  0.93250822],\n",
       "       [ 0.        ,  0.04924125],\n",
       "       [ 1.        ,  0.95974208],\n",
       "       [ 0.7       ,  0.16838866],\n",
       "       [ 0.4       ,  0.43061574],\n",
       "       [ 0.1       ,  0.17336078],\n",
       "       [ 0.        ,  0.05823568],\n",
       "       [ 0.2       ,  0.1923209 ],\n",
       "       [ 0.6       ,  0.50726612],\n",
       "       [ 0.1       ,  0.25099956],\n",
       "       [ 0.6       ,  0.53977726],\n",
       "       [ 0.8       ,  0.16838866],\n",
       "       [ 0.        ,  0.33989061],\n",
       "       [ 0.1       ,  0.30641091],\n",
       "       [ 0.        ,  0.10705655],\n",
       "       [ 0.5575    ,  0.51538584],\n",
       "       [ 0.1       ,  0.07686773],\n",
       "       [ 0.79666667,  0.42756762],\n",
       "       [ 0.3       ,  0.06766657],\n",
       "       [ 1.        ,  0.89145109],\n",
       "       [ 1.        ,  0.95523579],\n",
       "       [ 0.        ,  0.13276729],\n",
       "       [ 0.5       ,  0.17678256],\n",
       "       [ 0.09777778,  0.143781  ],\n",
       "       [ 0.8       ,  0.95422915],\n",
       "       [ 0.7       ,  0.59789748],\n",
       "       [ 0.675     ,  0.25850309],\n",
       "       [ 0.5       ,  0.12899341],\n",
       "       [ 0.8       ,  0.86211146],\n",
       "       [ 0.8       ,  0.78778111],\n",
       "       [ 0.2       ,  0.17316565],\n",
       "       [ 0.        ,  0.09133075],\n",
       "       [ 0.        ,  0.07749877],\n",
       "       [ 0.        ,  0.11049537],\n",
       "       [ 0.        ,  0.11898301],\n",
       "       [ 1.        ,  0.9740206 ],\n",
       "       [ 0.        ,  0.09222655],\n",
       "       [ 0.3       ,  0.15863344],\n",
       "       [ 0.        ,  0.09709363],\n",
       "       [ 0.7       ,  0.82838183],\n",
       "       [ 0.6       ,  0.60823808],\n",
       "       [ 0.7       ,  0.90368307],\n",
       "       [ 0.9       ,  0.74380762],\n",
       "       [ 0.        ,  0.10948046],\n",
       "       [ 0.1       ,  0.27698585],\n",
       "       [ 0.7       ,  0.89300695],\n",
       "       [ 0.8       ,  0.734608  ],\n",
       "       [ 0.        ,  0.08830799],\n",
       "       [ 0.        ,  0.48892562],\n",
       "       [ 0.1       ,  0.40744847],\n",
       "       [ 1.        ,  0.9740206 ],\n",
       "       [ 0.3       ,  0.38905539],\n",
       "       [ 0.        ,  0.1226044 ],\n",
       "       [ 0.9       ,  0.93709792],\n",
       "       [ 0.        ,  0.11865336],\n",
       "       [ 0.8       ,  0.734608  ],\n",
       "       [ 0.8       ,  0.92718677],\n",
       "       [ 0.3       ,  0.08564878],\n",
       "       [ 0.3       ,  0.24997971],\n",
       "       [ 0.        ,  0.09280331],\n",
       "       [ 0.21111111,  0.14521253],\n",
       "       [ 0.        ,  0.12149639],\n",
       "       [ 1.        ,  0.79078179],\n",
       "       [ 0.4       ,  0.32539677],\n",
       "       [ 0.86828283,  0.74675676],\n",
       "       [ 1.        ,  0.93481995],\n",
       "       [ 0.4       ,  0.38076489],\n",
       "       [ 0.53333333,  0.09769756],\n",
       "       [ 0.8       ,  0.93138737],\n",
       "       [ 0.        ,  0.1226044 ],\n",
       "       [ 0.6       ,  0.21418987],\n",
       "       [ 0.1       ,  0.09298947],\n",
       "       [ 0.7       ,  0.8920993 ],\n",
       "       [ 0.3       ,  0.14632917],\n",
       "       [ 0.4       ,  0.49552482],\n",
       "       [ 0.2       ,  0.14389292],\n",
       "       [ 1.        ,  0.9678034 ],\n",
       "       [ 0.1       ,  0.12652584],\n",
       "       [ 0.09777778,  0.143781  ],\n",
       "       [ 0.        ,  0.12280274],\n",
       "       [ 0.6       ,  0.56405765],\n",
       "       [ 0.        ,  0.13176177],\n",
       "       [ 0.24      ,  0.14318713],\n",
       "       [ 0.09777778,  0.143781  ],\n",
       "       [ 0.3       ,  0.11835055],\n",
       "       [ 0.        ,  0.1038616 ],\n",
       "       [ 0.1       ,  0.05042036],\n",
       "       [ 0.93333333,  0.74675676],\n",
       "       [ 1.        ,  0.96727864],\n",
       "       [ 0.5       ,  0.87436889],\n",
       "       [ 0.9       ,  0.96342488],\n",
       "       [ 0.3       ,  0.11984795],\n",
       "       [ 0.        ,  0.04662927],\n",
       "       [ 0.9       ,  0.9068569 ],\n",
       "       [ 0.7       ,  0.49606288],\n",
       "       [ 1.        ,  0.88589999],\n",
       "       [ 0.8       ,  0.90914033],\n",
       "       [ 0.01      ,  0.14598608],\n",
       "       [ 1.        ,  0.96407349],\n",
       "       [ 0.        ,  0.08041879],\n",
       "       [ 0.09777778,  0.143781  ],\n",
       "       [ 0.3       ,  0.56042575],\n",
       "       [ 0.        ,  0.09298947],\n",
       "       [ 1.        ,  0.69484115],\n",
       "       [ 0.44166667,  0.11378152],\n",
       "       [ 0.        ,  0.11095555],\n",
       "       [ 0.55      ,  0.18867288],\n",
       "       [ 0.1       ,  0.14233578],\n",
       "       [ 0.1       ,  0.13692394],\n",
       "       [ 0.        ,  0.04742693],\n",
       "       [ 0.2       ,  0.06425736],\n",
       "       [ 0.        ,  0.08830799],\n",
       "       [ 0.        ,  0.29378586],\n",
       "       [ 0.        ,  0.13110257],\n",
       "       [ 0.2       ,  0.31500906],\n",
       "       [ 0.        ,  0.08161453],\n",
       "       [ 0.1       ,  0.06264714],\n",
       "       [ 1.        ,  0.95346884],\n",
       "       [ 0.5       ,  0.218996  ],\n",
       "       [ 0.        ,  0.11775131],\n",
       "       [ 0.9       ,  0.42331732],\n",
       "       [ 0.1       ,  0.25376878],\n",
       "       [ 0.        ,  0.22236284],\n",
       "       [ 0.        ,  0.11095555],\n",
       "       [ 0.79666667,  0.42756762],\n",
       "       [ 0.2       ,  0.11445398],\n",
       "       [ 1.        ,  0.96721923],\n",
       "       [ 0.1       ,  0.143781  ],\n",
       "       [ 0.        ,  0.05136264],\n",
       "       [ 0.6       ,  0.50017363],\n",
       "       [ 0.1       ,  0.10345066],\n",
       "       [ 0.2       ,  0.11049537],\n",
       "       [ 1.        ,  0.94224305],\n",
       "       [ 0.4       ,  0.4835994 ],\n",
       "       [ 0.9       ,  0.42331732],\n",
       "       [ 0.8       ,  0.5036295 ],\n",
       "       [ 0.99166667,  0.7597685 ],\n",
       "       [ 0.8       ,  0.83891285],\n",
       "       [ 0.73333333,  0.90200021],\n",
       "       [ 0.4       ,  0.04407746],\n",
       "       [ 0.44166667,  0.11378152],\n",
       "       [ 0.5       ,  0.51072093],\n",
       "       [ 0.4       ,  0.43680829],\n",
       "       [ 0.1       ,  0.21351988],\n",
       "       [ 0.8       ,  0.94273852],\n",
       "       [ 0.1       ,  0.39508006],\n",
       "       [ 0.05      ,  0.05895964],\n",
       "       [ 0.        ,  0.29378586],\n",
       "       [ 0.        ,  0.10056546],\n",
       "       [ 0.17535714,  0.11943071],\n",
       "       [ 0.        ,  0.38623678],\n",
       "       [ 1.        ,  0.93569837],\n",
       "       [ 1.        ,  0.93418288],\n",
       "       [ 0.6       ,  0.41889695],\n",
       "       [ 1.        ,  0.94667032],\n",
       "       [ 0.7       ,  0.89660968],\n",
       "       [ 0.        ,  0.11865336],\n",
       "       [ 0.2       ,  0.46461641],\n",
       "       [ 1.        ,  0.93810256],\n",
       "       [ 0.09777778,  0.143781  ],\n",
       "       [ 0.8       ,  0.9427918 ],\n",
       "       [ 0.        ,  0.11595692],\n",
       "       [ 0.9       ,  0.90220398],\n",
       "       [ 0.375     ,  0.09332474],\n",
       "       [ 0.        ,  0.06357947],\n",
       "       [ 0.        ,  0.11378152],\n",
       "       [ 0.2       ,  0.13000345],\n",
       "       [ 0.175     ,  0.1561529 ],\n",
       "       [ 0.6       ,  0.3335799 ],\n",
       "       [ 0.        ,  0.04264624],\n",
       "       [ 0.9       ,  0.76142145],\n",
       "       [ 0.3       ,  0.07749877],\n",
       "       [ 0.7       ,  0.94841182],\n",
       "       [ 0.1       ,  0.50972441],\n",
       "       [ 0.06666667,  0.09538444],\n",
       "       [ 0.        ,  0.53290095],\n",
       "       [ 0.7       ,  0.77460833],\n",
       "       [ 1.        ,  0.96157086],\n",
       "       [ 0.4       ,  0.19400841],\n",
       "       [ 1.        ,  0.93939264],\n",
       "       [ 0.06666667,  0.09538444],\n",
       "       [ 0.3       ,  0.22502971],\n",
       "       [ 0.45328283,  0.32277869],\n",
       "       [ 0.06666667,  0.09538444],\n",
       "       [ 0.8       ,  0.9016968 ],\n",
       "       [ 0.        ,  0.08830799],\n",
       "       [ 0.15      ,  0.20163091],\n",
       "       [ 0.        ,  0.04407746],\n",
       "       [ 0.1       ,  0.28947982],\n",
       "       [ 0.6       ,  0.84695714],\n",
       "       [ 0.6       ,  0.61524426],\n",
       "       [ 0.1       ,  0.22517728],\n",
       "       [ 1.        ,  0.74675676],\n",
       "       [ 0.4       ,  0.17852401],\n",
       "       [ 0.9       ,  0.94286626],\n",
       "       [ 0.        ,  0.1226044 ],\n",
       "       [ 1.        ,  0.8304648 ],\n",
       "       [ 0.        ,  0.11095555],\n",
       "       [ 0.9       ,  0.8654484 ],\n",
       "       [ 0.4       ,  0.09298947],\n",
       "       [ 0.5       ,  0.84636558],\n",
       "       [ 0.4       ,  0.61674837],\n",
       "       [ 0.        ,  0.09298947],\n",
       "       [ 0.86828283,  0.74675676],\n",
       "       [ 0.        ,  0.08995285],\n",
       "       [ 0.04285714,  0.13468658],\n",
       "       [ 0.3       ,  0.31723726],\n",
       "       [ 1.        ,  0.92537407],\n",
       "       [ 0.1       ,  0.07881553],\n",
       "       [ 0.01111111,  0.143781  ],\n",
       "       [ 0.6       ,  0.39149902],\n",
       "       [ 0.        ,  0.09222655],\n",
       "       [ 0.6       ,  0.14688554],\n",
       "       [ 0.9       ,  0.16838866],\n",
       "       [ 0.83333333,  0.86561107],\n",
       "       [ 1.        ,  0.97685684],\n",
       "       [ 0.3       ,  0.83009426],\n",
       "       [ 1.        ,  0.94387961],\n",
       "       [ 0.3       ,  0.60670985],\n",
       "       [ 0.        ,  0.09280331],\n",
       "       [ 0.1       ,  0.11898301],\n",
       "       [ 0.1       ,  0.21229444],\n",
       "       [ 0.7       ,  0.89338678],\n",
       "       [ 0.3       ,  0.26154193],\n",
       "       [ 1.        ,  0.88589999],\n",
       "       [ 0.1       ,  0.48779785],\n",
       "       [ 1.        ,  0.92382854],\n",
       "       [ 0.        ,  0.13835926],\n",
       "       [ 0.5       ,  0.31283186],\n",
       "       [ 0.        ,  0.10705655],\n",
       "       [ 0.45      ,  0.18260381],\n",
       "       [ 0.05      ,  0.05895964],\n",
       "       [ 0.09777778,  0.143781  ],\n",
       "       [ 0.        ,  0.1226044 ],\n",
       "       [ 0.43333333,  0.87608409],\n",
       "       [ 0.        ,  0.09298947],\n",
       "       [ 0.        ,  0.09349528],\n",
       "       [ 0.1       ,  0.08830799],\n",
       "       [ 1.        ,  0.90368307],\n",
       "       [ 0.9       ,  0.87106991],\n",
       "       [ 0.1       ,  0.07781196],\n",
       "       [ 0.        ,  0.09280331],\n",
       "       [ 0.        ,  0.04984001],\n",
       "       [ 0.05      ,  0.05895964],\n",
       "       [ 0.        ,  0.33989061],\n",
       "       [ 0.        ,  0.11170511],\n",
       "       [ 0.5       ,  0.25967539],\n",
       "       [ 0.09777778,  0.143781  ],\n",
       "       [ 0.9       ,  0.95071325],\n",
       "       [ 1.        ,  0.7648824 ],\n",
       "       [ 0.        ,  0.11943071],\n",
       "       [ 0.9       ,  0.87913146],\n",
       "       [ 0.06666667,  0.1055927 ],\n",
       "       [ 0.1       ,  0.10452644],\n",
       "       [ 0.2       ,  0.11445398],\n",
       "       [ 0.06666667,  0.09538444],\n",
       "       [ 0.        ,  0.30641091],\n",
       "       [ 1.        ,  0.96606185],\n",
       "       [ 0.86828283,  0.74675676],\n",
       "       [ 0.5       ,  0.61222716],\n",
       "       [ 0.9       ,  0.74673841],\n",
       "       [ 0.        ,  0.06354079],\n",
       "       [ 0.        ,  0.08041879],\n",
       "       [ 0.6       ,  0.29218307],\n",
       "       [ 0.17535714,  0.11943071],\n",
       "       [ 0.        ,  0.1226044 ],\n",
       "       [ 0.3       ,  0.22236284],\n",
       "       [ 0.3       ,  0.04643762],\n",
       "       [ 0.17535714,  0.11943071],\n",
       "       [ 0.1       ,  0.28875737],\n",
       "       [ 0.3       ,  0.13901748],\n",
       "       [ 0.        ,  0.11681365],\n",
       "       [ 1.        ,  0.95282152],\n",
       "       [ 0.1       ,  0.17336078],\n",
       "       [ 0.        ,  0.23731504],\n",
       "       [ 0.1       ,  0.09280331],\n",
       "       [ 0.1       ,  0.11680812],\n",
       "       [ 0.2       ,  0.1035727 ],\n",
       "       [ 0.1       ,  0.09116075],\n",
       "       [ 0.3       ,  0.10705655],\n",
       "       [ 0.86828283,  0.74675676],\n",
       "       [ 0.9       ,  0.79962322],\n",
       "       [ 0.9       ,  0.21234428],\n",
       "       [ 0.9       ,  0.88979569],\n",
       "       [ 0.3       ,  0.25145942],\n",
       "       [ 0.        ,  0.24700638],\n",
       "       [ 0.1       ,  0.11170511],\n",
       "       [ 0.7       ,  0.16838866],\n",
       "       [ 0.05      ,  0.05895964],\n",
       "       [ 0.45328283,  0.32856687],\n",
       "       [ 0.8       ,  0.96183782],\n",
       "       [ 0.7       ,  0.80689355],\n",
       "       [ 0.5       ,  0.36615647],\n",
       "       [ 0.3       ,  0.0995827 ],\n",
       "       [ 0.2       ,  0.11681365],\n",
       "       [ 0.2       ,  0.1923209 ],\n",
       "       [ 0.        ,  0.12280274],\n",
       "       [ 0.        ,  0.16838866],\n",
       "       [ 0.        ,  0.13110257],\n",
       "       [ 0.9       ,  0.48445859],\n",
       "       [ 1.        ,  0.95128763],\n",
       "       [ 0.        ,  0.06729135],\n",
       "       [ 1.        ,  0.89447865],\n",
       "       [ 0.1       ,  0.25967539],\n",
       "       [ 0.2       ,  0.10616519],\n",
       "       [ 0.        ,  0.09950288],\n",
       "       [ 1.        ,  0.91019957],\n",
       "       [ 0.7       ,  0.20269902],\n",
       "       [ 0.        ,  0.11943071],\n",
       "       [ 0.5       ,  0.77906839],\n",
       "       [ 0.1       ,  0.11681365],\n",
       "       [ 0.2       ,  0.1676126 ],\n",
       "       [ 0.5       ,  0.15863344],\n",
       "       [ 0.        ,  0.03624029],\n",
       "       [ 0.        ,  0.26580871],\n",
       "       [ 0.17535714,  0.11943071],\n",
       "       [ 0.16666667,  0.0995827 ],\n",
       "       [ 0.1       ,  0.0710897 ],\n",
       "       [ 0.        ,  0.24630743],\n",
       "       [ 1.        ,  0.96689893],\n",
       "       [ 0.3       ,  0.08919559],\n",
       "       [ 0.7       ,  0.63349755],\n",
       "       [ 0.        ,  0.13110257],\n",
       "       [ 0.7       ,  0.46049764],\n",
       "       [ 0.        ,  0.09950288],\n",
       "       [ 0.9       ,  0.93463329],\n",
       "       [ 0.9       ,  0.94972747],\n",
       "       [ 0.06666667,  0.09538444],\n",
       "       [ 0.1       ,  0.21282175],\n",
       "       [ 0.4       ,  0.17553312],\n",
       "       [ 0.6       ,  0.89066072],\n",
       "       [ 0.3       ,  0.08787451],\n",
       "       [ 0.8       ,  0.95442674],\n",
       "       [ 0.        ,  0.09280331],\n",
       "       [ 0.09777778,  0.143781  ],\n",
       "       [ 0.8       ,  0.52678194],\n",
       "       [ 0.        ,  0.08507934],\n",
       "       [ 0.9       ,  0.95080681],\n",
       "       [ 0.9       ,  0.93463329],\n",
       "       [ 0.9       ,  0.14068034],\n",
       "       [ 0.9       ,  0.96965914],\n",
       "       [ 0.3       ,  0.27024817],\n",
       "       [ 0.        ,  0.12149639],\n",
       "       [ 0.1       ,  0.24744017],\n",
       "       [ 0.9       ,  0.94972747],\n",
       "       [ 0.4       ,  0.30147238],\n",
       "       [ 0.1       ,  0.0895301 ],\n",
       "       [ 1.        ,  0.98060937],\n",
       "       [ 0.1       ,  0.07103592],\n",
       "       [ 0.39166667,  0.08940349],\n",
       "       [ 0.9       ,  0.94252762],\n",
       "       [ 1.        ,  0.96023829],\n",
       "       [ 0.        ,  0.21097936],\n",
       "       [ 0.13333333,  0.09950288],\n",
       "       [ 0.1       ,  0.11217123],\n",
       "       [ 0.2       ,  0.37286671],\n",
       "       [ 0.09777778,  0.143781  ],\n",
       "       [ 0.1       ,  0.18579748],\n",
       "       [ 0.2       ,  0.32234323],\n",
       "       [ 0.4       ,  0.4893615 ],\n",
       "       [ 0.45833333,  0.11009826],\n",
       "       [ 1.        ,  0.9220133 ],\n",
       "       [ 0.2       ,  0.09298947],\n",
       "       [ 0.        ,  0.05996978],\n",
       "       [ 0.27333333,  0.14318713],\n",
       "       [ 0.1       ,  0.08305956],\n",
       "       [ 0.2       ,  0.32427697],\n",
       "       [ 1.        ,  0.92112937],\n",
       "       [ 0.3       ,  0.43683629],\n",
       "       [ 0.05      ,  0.05045418],\n",
       "       [ 0.        ,  0.03418965],\n",
       "       [ 1.        ,  0.92267003],\n",
       "       [ 0.        ,  0.16838866],\n",
       "       [ 1.        ,  0.95204363],\n",
       "       [ 0.        ,  0.09298947],\n",
       "       [ 0.        ,  0.05942607],\n",
       "       [ 1.        ,  0.94667309],\n",
       "       [ 0.        ,  0.10038653],\n",
       "       [ 1.        ,  0.95974208],\n",
       "       [ 0.        ,  0.21127663],\n",
       "       [ 0.3       ,  0.18378684],\n",
       "       [ 0.5       ,  0.14914084],\n",
       "       [ 0.1       ,  0.08578511],\n",
       "       [ 0.4       ,  0.23161698],\n",
       "       [ 0.89166667,  0.64665111],\n",
       "       [ 0.8       ,  0.82498269],\n",
       "       [ 0.86828283,  0.74675676],\n",
       "       [ 1.        ,  0.9608066 ],\n",
       "       [ 0.1       ,  0.52602653],\n",
       "       [ 0.        ,  0.1226044 ],\n",
       "       [ 1.        ,  0.96513322],\n",
       "       [ 0.        ,  0.05537313],\n",
       "       [ 0.        ,  0.1226044 ],\n",
       "       [ 0.        ,  0.20043982]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединяем предсказания ансамблей с помощью логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# TODO: подобрать гиперпараметры LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression().fit(X_train_stack, y_train)\n",
    "predicted = logreg.predict(X_test_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем файл для отправки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission.txt', 'w') as out:\n",
    "    out.write('PassengerId,Survived\\n')\n",
    "    for passenger, y in zip(test['PassengerId'], predicted):\n",
    "        out.write('%s,%s\\n' % (passenger, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
