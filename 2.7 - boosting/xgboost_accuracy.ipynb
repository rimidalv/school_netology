{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные из файлов\n",
    "X_train = pd.read_csv('./titanic/titanic_cleaned_train.csv')\n",
    "y_train = pd.read_csv('./titanic/titanic_cleaned_train_y.csv', header=None)\n",
    "X_test = pd.read_csv('./titanic/titanic_cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Age_0.0</th>\n",
       "      <th>Age_1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>Fare_2</th>\n",
       "      <th>Fare_3</th>\n",
       "      <th>Title_1</th>\n",
       "      <th>Title_2</th>\n",
       "      <th>Title_3</th>\n",
       "      <th>Title_4</th>\n",
       "      <th>Title_5</th>\n",
       "      <th>clusters_0</th>\n",
       "      <th>clusters_1</th>\n",
       "      <th>clusters_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SibSp  Parch  Has_Cabin  FamilySize  IsAlone  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0    1.0    0.0        0.0         2.0      0.0       0.0       0.0       1.0   \n",
       "1    1.0    0.0        1.0         2.0      0.0       1.0       0.0       0.0   \n",
       "2    0.0    0.0        0.0         1.0      1.0       0.0       0.0       1.0   \n",
       "3    1.0    0.0        1.0         2.0      0.0       1.0       0.0       0.0   \n",
       "4    0.0    0.0        0.0         1.0      1.0       0.0       0.0       1.0   \n",
       "\n",
       "   Age_0.0  Age_1.0     ...      Fare_2  Fare_3  Title_1  Title_2  Title_3  \\\n",
       "0      0.0      1.0     ...         0.0     0.0      1.0      0.0      0.0   \n",
       "1      0.0      0.0     ...         0.0     1.0      0.0      0.0      1.0   \n",
       "2      0.0      1.0     ...         0.0     0.0      0.0      1.0      0.0   \n",
       "3      0.0      0.0     ...         0.0     1.0      0.0      0.0      1.0   \n",
       "4      0.0      0.0     ...         0.0     0.0      1.0      0.0      0.0   \n",
       "\n",
       "   Title_4  Title_5  clusters_0  clusters_1  clusters_2  \n",
       "0      0.0      0.0           0           1           0  \n",
       "1      0.0      0.0           0           1           0  \n",
       "2      0.0      0.0           0           0           1  \n",
       "3      0.0      0.0           0           1           0  \n",
       "4      0.0      0.0           0           0           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop([\"clusters_0\",\"clusters_2\", \"IsAlone\"], inplace=True, axis=1) #\"clusters_0\",  \"Parch\", \"Miss\",\"Ms\", \"Mrs\"\n",
    "X_test.drop([ \"clusters_0\",\"clusters_2\", \"IsAlone\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[\"AgeFare\"] = X_train.Age * X_train.Fare\n",
    "# X_test[\"AgeFare\"] = X_test.Age * X_test.Fare\n",
    "# X_train[\"AgeMale\"] = X_train.Age * X_train.isMale\n",
    "# X_test[\"AgeMale\"] = X_test.Age * X_test.isMale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "**Основные параметры**\n",
    "\n",
    "| Параметр          | Тип                | Описание                                                                                                                                     | Диапазон значений      |\n",
    "|-------------------|--------------------|----------------------------------------------------------------------------------------------------------------------------------------------|------------------------|\n",
    "| **max_depth**         | int                | Максимальная глубина каждого дерева                                                                                                          | 3-10                   |\n",
    "| **learning_rate**     | float              | Шаг градиентного бустинга                                                                                                                    | 0.01-0.2               |\n",
    "| **n_estimators**      | int                | Размер ансамбля                                                                                                                              | 100-1000               |\n",
    "| **objective**         | string or callable | Оптмизируемый функционал. В отличие от метрики качества, должен быть всюду дифференцируем                                                    |                        |\n",
    "| **booster**           | string             | Какой бустинг использовать                                                                                                                   | [gbtree,gblinear,dart] |\n",
    "| **nthread**           | int                | Количество потоков, в котором будет обучаться XGBoost                                                                                        |                        |\n",
    "| **n_jobs**            | int                | -//-                                                                                                                                         |                        |\n",
    "| **gamma**             | float              |  Минимальный прирост качества функционала ошибки, при котором лист дерева будет поделён на поддеревья. Минимальный критерий ветвления дерева |                        |\n",
    "| **min_child_weight**  | float              | Минимальная сумма весов в листе дерева для того, чтобы его не выкинуть                                                                       |                        |\n",
    "| **max_delta_step**    | int                | Максимальный шаг, с которым можно обновлять веса деревьев                                                                                    |                        |\n",
    "| **subsample**         | float              | На какой случайной доли обучающей выборки будет обучаться каждое дерево                                                                      |                        |\n",
    "| **colsample_bytree**  | float              | На какой случайной доли признаков будет обучаться каждое дерево                                                                              | [0.5-1]                |\n",
    "| **colsample_bylevel** | float              | Какая доля признаков пойдёт в каждое поддерево                                                                                               |                        |\n",
    "| **reg_alpha**         | float              | L1-регуляризация для листьев дерева                                                                                                          |                        |\n",
    "| **reg_lambda**        | float              | L2-регуляризация для листьев дерева                                                                                                          |                        |\n",
    "| **scale_pos_weight**  | float              | Какой вес придадим второму классу объектов (1) по сравнению с первым (0). Используется при сильно несбалансированной выборке                 |                        |\n",
    "| **base_score**        | float              |  До какого скора объекты будут отнесену к первому классу (0) и с какого ко второму (1). По умолчанию 0.5. Обычно не тюнят                    |                        |\n",
    "| **seed**              | int                | Начальная точка для генератора случайных чисел                                                                                               |                        |\n",
    "| **random_state**      | int                | -//-                                                                                                                                         |                        |\n",
    "| **missing**           | float (optional)   | Что принимать за пропущенные значения. По умолчанию np.nan.                                                                                  |                        |\n",
    "| **silent**            | boolean            | Если True, то выводить всю информацию об обучении                                                                                            |                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Упражнение 1\n",
    "Используя текущее описание параметров и предыдущее упражнение, произведите базовый подбор параметров XGBoost'a, используя метрику **AUC**. Сравните полученное качество (**AUC**) с полученным ранее на RandomForest и GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "[CV] learning_rate=0.01, n_estimators=2 ..............................\n",
      "[CV]  learning_rate=0.01, n_estimators=2, score=0.8348214285714286, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=2 ..............................\n",
      "[CV]  learning_rate=0.01, n_estimators=2, score=0.8071748878923767, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=2 ..............................\n",
      "[CV]  learning_rate=0.01, n_estimators=2, score=0.8063063063063063, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=2 ..............................\n",
      "[CV]  learning_rate=0.01, n_estimators=2, score=0.8378378378378378, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=5 ..............................\n",
      "[CV]  learning_rate=0.01, n_estimators=5, score=0.8348214285714286, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=5 ..............................\n",
      "[CV]  learning_rate=0.01, n_estimators=5, score=0.8071748878923767, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=5 ..............................\n",
      "[CV]  learning_rate=0.01, n_estimators=5, score=0.8063063063063063, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=5 ..............................\n",
      "[CV]  learning_rate=0.01, n_estimators=5, score=0.8378378378378378, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=10 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=10, score=0.8348214285714286, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=10 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=10, score=0.8071748878923767, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=10 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=10, score=0.8063063063063063, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=10 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=10, score=0.8378378378378378, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=15 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=15, score=0.8348214285714286, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=15 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=15, score=0.8071748878923767, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=15 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=15, score=0.8063063063063063, total=   0.0s\n",
      "[CV] learning_rate=0.01, n_estimators=15 .............................\n",
      "[CV]  learning_rate=0.01, n_estimators=15, score=0.8378378378378378, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.01, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=2, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = xgboost.XGBClassifier()\n",
    "\n",
    "## TODO: ваш GridSearch\n",
    "gs = GridSearchCV(clf, param_grid={\"n_estimators\" : [2,5,10, 15], \"learning_rate\" : [0.01]}, verbose=5, cv=4)\n",
    "gs.fit(X_train, y_train)\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82154882154882158"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Более умный и последовательный тюнинг\n",
    "Взято [отсюда](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/). Это наиболее полный и часто используемый мануал для тюнинга XGBoost.\n",
    "**Алгоритм:**\n",
    "1. Choose a relatively high learning rate. Generally a learning rate of 0.1 works but somewhere between 0.05 to 0.3 should work for different problems. Determine the optimum number of trees for this learning rate. XGBoost has a very useful function called as “cv” which performs cross-validation at each boosting iteration and thus returns the optimum number of trees required.\n",
    "2. Tune tree-specific parameters ( max_depth, min_child_weight, gamma, subsample, colsample_bytree) for decided learning rate and number of trees. Note that we can choose different parameters to define a tree and I’ll take up an example here.\n",
    "3. Tune regularization parameters (lambda, alpha) for xgboost which can help reduce model complexity and enhance performance.\n",
    "4. Lower the learning rate and decide the optimal parameters ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1: Зафиксируем learning_rate и параметры дерева и подберём n_estimators\n",
    "\n",
    "Параметры:\n",
    "\n",
    "* **max_depth**. Как указанов в таблице выше, обычно варьируется в интервале от 3 до 10 (но от задачи к задаче значения могут меняться). В качестве начального значения обычно используют 5\n",
    "* **min_child_weight**. Если выборка сильно несбалансирована, то лучше выбрать значение \"1\". Иначе лучше выбрать значение \"2\" и зафиксировать\n",
    "* **gamma**. Обычно выставляют значение в интервале от 0 до 0.2 и фиксируют. В дальнейшем этот параметр всегда можно затюнить отдельно\n",
    "* **subsample, colsample_bytree**. Выставим 0.8 и зафиксируем. Можно также проварьировать в интервале 0.5-0.9.\n",
    "* **scale_pos_weight**. Выставляется в зафисимости от соотношения классов в выборке и фиксируется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (AUC):  0.824915824916\n",
      "Best params: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 2,\n",
       " 'missing': None,\n",
       " 'n_estimators': 390,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 1.0,\n",
       " 'scale_pos_weight': 1.0,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ones_ratio = y_train[y_train == 1].shape[0] * 1.0 / y_train[y_train == 0].shape[0] # посчитаем соотношение между классами\n",
    "\n",
    "param_grid = {\n",
    "    # параметры ансамбля\n",
    "    'n_estimators': list(np.arange(10, 1000, 10)),#[10, 30, 50, 100, 200, 400, 600, 1000],\n",
    "    'learning_rate': [0.01],\n",
    "    \n",
    "    # параметры дерева\n",
    "    'max_depth': [5],\n",
    "    'min_child_weight': [2],\n",
    "    'gamma': [0.1],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'scale_pos_weight': [ones_ratio],\n",
    "    \n",
    "    # параметры регуляризации\n",
    "    'reg_alpha': [0.0],\n",
    "    'reg_lambda': [1.0]\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=4, shuffle=True)\n",
    "\n",
    "clf = xgboost.XGBClassifier()\n",
    "gs = GridSearchCV(clf, param_grid, scoring='accuracy', cv=cv, verbose=0)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2. Подбираем параметры дерева\n",
    "* **max_depth** - будем варьировать от 3 до 10 с шагом 2\n",
    "* **min_child_weight** - от 1 до 6 с шагом 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (AUC):  0.835016835017\n",
      "Best params: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 390,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 1.0,\n",
       " 'scale_pos_weight': 1.0,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': range(3, 10, 2),\n",
    "    'min_child_weight': range(1, 6, 2)\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params) # в качестве отправной точки возьмём модель с наилучшими параметрами предыдущего шага\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid, scoring='accuracy', cv=cv, verbose=0)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 3. Подбираем gamma (критерий создания поддерева)\n",
    "* **gamma** - от 0 до 0.5 с шагом 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (AUC):  0.832772166105\n",
      "Best params: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'gamma': 0.5,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 390,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 1.0,\n",
       " 'scale_pos_weight': 1.0,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'gamma': [0.1*i for i in range(6)]\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params)\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid, scoring='accuracy', cv=cv, verbose=0)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 4. Затюним subsample и colsample_bytree\n",
    "* **subsample** - от 0.5 до 1.0 с шагом 0.1\n",
    "* **colsample_bytree** - от 0.5 до 1.0 с шагом 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (AUC):  0.832772166105\n",
      "Best params: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.6,\n",
       " 'gamma': 0.5,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 390,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 1.0,\n",
       " 'scale_pos_weight': 1.0,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'subsample': [0.5 + 0.1*i for i in range(6)],\n",
    "    'colsample_bytree': [0.5 + 0.1*i for i in range(6)]\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params)\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid, scoring='accuracy', cv=cv, verbose=0)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 5. Регуляризация\n",
    "* **reg_alpha** [1e-5, 1e-2, 0.1, 1, 100]\n",
    "* **reg_lambda** [1e-5, 1e-2, 0.1, 1, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (AUC):  0.83164983165\n",
      "Best params: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.6,\n",
       " 'gamma': 0.5,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 390,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 1e-05,\n",
       " 'reg_lambda': 1e-05,\n",
       " 'scale_pos_weight': 1.0,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'reg_alpha': [1e-5, 1e-2, 0.1, 1, 100],\n",
    "    'reg_lambda': [1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params)\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid, scoring='accuracy', cv=cv, verbose=0)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 6. Learning rate\n",
    "Чем меньше у нас **n_estimators** в ансамбле, тем быстрее нам нужно двигаться с каждым шагом (добавлением нового классификатора), т.е. делать больший **learning_rate**. Обычно **learning rate** варьируют так, чтобы произведение **n_estimators** x **learning_rate** оставалось инвариантным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (AUC):  0.882882882883\n",
      "Best params: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.6,\n",
       " 'gamma': 0.5,\n",
       " 'learning_rate': 0.0061904761904761907,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 630,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 1e-05,\n",
       " 'reg_lambda': 1e-05,\n",
       " 'scale_pos_weight': 1.0,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params)\n",
    "best_n_estimators = clf.get_params()['n_estimators'] # возьмём наилучшие значения n_estimators с предыдущего шага\n",
    "best_learning_rate = best_params['learning_rate'] # аналогичная запись\n",
    "invariant_composition = best_n_estimators * best_learning_rate\n",
    "n_estimators_range = np.arange(10, 1000, 10)#[10, 30, 100, 200, 400, 600, 800, 1000]\n",
    "\n",
    "best_score = gs.best_score_ # возьмём наилучшее качество с предыдущего шага\n",
    "\n",
    "for n_estimators in n_estimators_range:\n",
    "    learning_rate = invariant_composition / n_estimators\n",
    "    clf.set_params(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "    aucs = []\n",
    "    for train_idx, test_idx in cv.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "        clf.fit(X_train_fold, y_train_fold, verbose=0)\n",
    "        preds = clf.predict(X_test_fold)\n",
    "#         print(preds)\n",
    "        auc = accuracy_score(y_test_fold, preds)\n",
    "        aucs.append(auc)\n",
    "    auc = np.mean(auc)\n",
    "    if auc > best_score:\n",
    "        best_n_estimators = n_estimators\n",
    "        best_learning_rate = learning_rate\n",
    "        best_score = auc\n",
    "        \n",
    "best_params['n_estimators'] = best_n_estimators\n",
    "best_params['learning_rate'] = best_learning_rate\n",
    "\n",
    "print('Best score (AUC): ', best_score)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выведем важность признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: \"SibSp\"\tFeature importance: 0.0642\n",
      "Feature: \"Parch\"\tFeature importance: 0.0595\n",
      "Feature: \"Has_Cabin\"\tFeature importance: 0.0540\n",
      "Feature: \"FamilySize\"\tFeature importance: 0.1211\n",
      "Feature: \"Pclass_1\"\tFeature importance: 0.0449\n",
      "Feature: \"Pclass_2\"\tFeature importance: 0.0415\n",
      "Feature: \"Pclass_3\"\tFeature importance: 0.0568\n",
      "Feature: \"Age_0.0\"\tFeature importance: 0.0392\n",
      "Feature: \"Age_1.0\"\tFeature importance: 0.0625\n",
      "Feature: \"Age_2.0\"\tFeature importance: 0.0482\n",
      "Feature: \"Age_3.0\"\tFeature importance: 0.0461\n",
      "Feature: \"Age_4.0\"\tFeature importance: 0.0032\n",
      "Feature: \"Fare_0\"\tFeature importance: 0.0387\n",
      "Feature: \"Fare_1\"\tFeature importance: 0.0362\n",
      "Feature: \"Fare_2\"\tFeature importance: 0.0450\n",
      "Feature: \"Fare_3\"\tFeature importance: 0.0560\n",
      "Feature: \"Title_1\"\tFeature importance: 0.0421\n",
      "Feature: \"Title_2\"\tFeature importance: 0.0309\n",
      "Feature: \"Title_3\"\tFeature importance: 0.0274\n",
      "Feature: \"Title_4\"\tFeature importance: 0.0223\n",
      "Feature: \"Title_5\"\tFeature importance: 0.0342\n",
      "Feature: \"clusters_1\"\tFeature importance: 0.0259\n"
     ]
    }
   ],
   "source": [
    "for feature_name, feature_importance in zip(X_train.columns, clf.feature_importances_):\n",
    "    print('Feature: \"%s\"\\tFeature importance: %.4f' % (feature_name, feature_importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hyperopt\n",
    "# !pip install networkx==1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params : \n",
      "{'colsample_bytree': 0.8, 'gamma': 0.75, 'learning_rate': 0.07500000000000001, 'max_depth': 2.0, 'min_child_weight': 3.0, 'n_estimators': 115.0, 'objective': 'reg:linear', 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'scale_pos_weight': 3.5, 'silent': 1, 'subsample': 0.65}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [223, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-391-98e6ec4dbd39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-391-98e6ec4dbd39>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(trials)\u001b[0m\n\u001b[1;32m     40\u001b[0m              }\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-391-98e6ec4dbd39>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0maucs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [223, 2]"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "# в этой функции мы проверяем, как ведёт себя модель при заданных параметрах\n",
    "def score(params):\n",
    "    print(\"Training with params : \")\n",
    "    print(params)\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    model = xgboost.XGBClassifier(**params)\n",
    "    aucs = []\n",
    "    # Для оценки качества используем KFold, который определили выше\n",
    "    for train_idx, test_idx in cv.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "        clf.fit(X_train_fold, y_train_fold)\n",
    "        preds = clf.predict_proba(X_test_fold)\n",
    "        auc = accuracy_score(y_test_fold, preds[1])\n",
    "        aucs.append(auc)\n",
    "    auc = np.mean(auc)\n",
    "    result = {'loss': auc, 'status': STATUS_OK}\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "# это наша главная функция, в которой мы задаём параметры\n",
    "def optimize(trials):\n",
    "    space = {\n",
    "             'n_estimators' : hp.quniform('n_estimators', 100, 1000, 5), # (название параметра, от, до, шаг)\n",
    "             'learning_rate' : hp.quniform('learning_rate', 0.025, 0.5, 0.025),\n",
    "             'max_depth' : hp.quniform('max_depth', 1, 10, 1),\n",
    "             'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n",
    "             'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "             'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "             'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "             'objective': 'reg:linear',\n",
    "             'silent' : 1,\n",
    "             'scale_pos_weight': hp.quniform('scale_pos_weight', 0.5, 10., 0.5),\n",
    "             'reg_alpha': 0.0,\n",
    "             'reg_lambda': 1.0\n",
    "             }\n",
    "\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n",
    "    print('Best: ')\n",
    "    print(best)\n",
    "\n",
    "#сюда будет записана\n",
    "trials = Trials()\n",
    "\n",
    "optimize(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Best: \n",
    "{'colsample_bytree': 0.8500000000000001, 'gamma': 0.9500000000000001, 'learning_rate': 0.025, 'max_depth': 9.0, 'min_child_weight': 6.0, 'n_estimators': 310.0, 'scale_pos_weight': 3.0, 'subsample': 0.8}\n",
    "\n",
    "\n",
    "{'colsample_bytree': 0.5, 'gamma': 0.8500000000000001, 'learning_rate': 0.275, 'max_depth': 5.0, 'min_child_weight': 1.0, 'n_estimators': 485.0, 'scale_pos_weight': 7.0, 'subsample': 0.8}\n",
    "\n",
    "{'colsample_bytree': 1.0, 'gamma': 0.8, 'learning_rate': 0.5, 'max_depth': 4.0, 'min_child_weight': 5.0, 'n_estimators': 1000.0, 'scale_pos_weight': 5.0, 'subsample': 0.55}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'base_score': 0.5,\n",
    " 'colsample_bylevel': 1,\n",
    " 'colsample_bytree': 0.6,\n",
    " 'gamma': 0.5,\n",
    " 'learning_rate': 0.0061904761904761907,\n",
    " 'max_delta_step': 0,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 1,\n",
    " 'missing': None,\n",
    " 'n_estimators': 630,\n",
    " 'nthread': -1,\n",
    " 'objective': 'binary:logistic',\n",
    " 'reg_alpha': 1e-05,\n",
    " 'reg_lambda': 1e-05,\n",
    " 'scale_pos_weight': 1.0,\n",
    " 'seed': 0,\n",
    " 'silent': True,\n",
    " 'subsample': 0.9}\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params)\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (accuracy):  0.882882882883\n",
      "Best params: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.6,\n",
       " 'gamma': 0.5,\n",
       " 'learning_rate': 0.0061904761904761907,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 630,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 1e-05,\n",
       " 'reg_lambda': 1e-05,\n",
       " 'scale_pos_weight': 1.0,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs = []\n",
    "for train_idx, test_idx in cv.split(X_train):\n",
    "    X_train_fold, X_test_fold = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "    clf.fit(X_train_fold, y_train_fold, verbose=0)\n",
    "    preds = clf.predict(X_test_fold)\n",
    "#         print(preds)\n",
    "    auc = accuracy_score(y_test_fold, preds)\n",
    "    aucs.append(auc)\n",
    "auc = np.mean(auc)\n",
    "if auc > best_score:\n",
    "    best_n_estimators = n_estimators\n",
    "    best_learning_rate = learning_rate\n",
    "    best_score = auc\n",
    "\n",
    "best_params['n_estimators'] = best_n_estimators\n",
    "best_params['learning_rate'] = best_learning_rate\n",
    "\n",
    "\n",
    "\n",
    "print('Best score (accuracy): ', best_score)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "submussion = 'PassengerId,Survived\\n'\n",
    "submussion += \"\\n\".join([\"{},{}\".format(pid, prediction) for pid, prediction in zip(test.PassengerId, predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission.txt', 'w') as file:\n",
    "    file.write(submussion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
