{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score , roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные из файлов\n",
    "X_train = pd.read_csv('./titanic/titanic_cleaned_train.csv')\n",
    "y_train = pd.read_csv('./titanic/titanic_cleaned_train_y.csv', header=None)\n",
    "X_test = pd.read_csv('./titanic/titanic_cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Age_0.0</th>\n",
       "      <th>Age_1.0</th>\n",
       "      <th>Age_2.0</th>\n",
       "      <th>...</th>\n",
       "      <th>FamilySize_2</th>\n",
       "      <th>FamilySize_3</th>\n",
       "      <th>FamilySize_4</th>\n",
       "      <th>FamilySize_5</th>\n",
       "      <th>FamilySize_6</th>\n",
       "      <th>FamilySize_7</th>\n",
       "      <th>FamilySize_8</th>\n",
       "      <th>FamilySize_11</th>\n",
       "      <th>clusters_0</th>\n",
       "      <th>clusters_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SibSp  Parch  Has_Cabin  IsAlone  Pclass_1  Pclass_2  Pclass_3  Age_0.0  \\\n",
       "0    1.0    0.0        0.0      0.0       0.0       0.0       1.0      0.0   \n",
       "1    1.0    0.0        1.0      0.0       1.0       0.0       0.0      0.0   \n",
       "2    0.0    0.0        0.0      1.0       0.0       0.0       1.0      0.0   \n",
       "3    1.0    0.0        1.0      0.0       1.0       0.0       0.0      0.0   \n",
       "4    0.0    0.0        0.0      1.0       0.0       0.0       1.0      0.0   \n",
       "\n",
       "   Age_1.0  Age_2.0     ...      FamilySize_2  FamilySize_3  FamilySize_4  \\\n",
       "0      1.0      0.0     ...               1.0           0.0           0.0   \n",
       "1      0.0      1.0     ...               1.0           0.0           0.0   \n",
       "2      1.0      0.0     ...               0.0           0.0           0.0   \n",
       "3      0.0      1.0     ...               1.0           0.0           0.0   \n",
       "4      0.0      1.0     ...               0.0           0.0           0.0   \n",
       "\n",
       "   FamilySize_5  FamilySize_6  FamilySize_7  FamilySize_8  FamilySize_11  \\\n",
       "0           0.0           0.0           0.0           0.0            0.0   \n",
       "1           0.0           0.0           0.0           0.0            0.0   \n",
       "2           0.0           0.0           0.0           0.0            0.0   \n",
       "3           0.0           0.0           0.0           0.0            0.0   \n",
       "4           0.0           0.0           0.0           0.0            0.0   \n",
       "\n",
       "   clusters_0  clusters_1  \n",
       "0           0           1  \n",
       "1           0           1  \n",
       "2           1           0  \n",
       "3           0           1  \n",
       "4           1           0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_drop = [\"clusters_0\", \n",
    "            \"clusters_1\" ,\n",
    "            \"IsAlone\" ,\n",
    "            \"Age_4.0\", \n",
    "            \"FamilySize_7\", \n",
    "            \"FamilySize_8\",\n",
    "            \"FamilySize_11\",\n",
    "            \"Pclass_2\",\n",
    "            \"FamilySize_2\", \n",
    "            \"Title_3\",\n",
    "            \"FamilySize_3\",\n",
    "            \"Title_2\",\n",
    "            \"Title_4\",\n",
    "            \"FamilySize_1\",\n",
    "            \"FamilySize_4\",]\n",
    "for_drop = []\n",
    "X_train.drop(for_drop, inplace=True, axis=1) #\"clusters_0\",  \"Parch\", \"Miss\",\"Ms\", \"Mrs\"\n",
    "X_test.drop(for_drop, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1: Зафиксируем learning_rate и параметры дерева и подберём n_estimators\n",
    "\n",
    "Параметры:\n",
    "\n",
    "* **max_depth**. Как указанов в таблице выше, обычно варьируется в интервале от 3 до 10 (но от задачи к задаче значения могут меняться). В качестве начального значения обычно используют 5\n",
    "* **min_child_weight**. Если выборка сильно несбалансирована, то лучше выбрать значение \"1\". Иначе лучше выбрать значение \"2\" и зафиксировать\n",
    "* **gamma**. Обычно выставляют значение в интервале от 0 до 0.2 и фиксируют. В дальнейшем этот параметр всегда можно затюнить отдельно\n",
    "* **subsample, colsample_bytree**. Выставим 0.8 и зафиксируем. Можно также проварьировать в интервале 0.5-0.9.\n",
    "* **scale_pos_weight**. Выставляется в зафисимости от соотношения классов в выборке и фиксируется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (AUC):  0.87149426617\n",
      "Best params: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 2,\n",
       " 'missing': None,\n",
       " 'n_estimators': 260,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 1.0,\n",
       " 'scale_pos_weight': 1.0,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ones_ratio = y_train[y_train == 1].shape[0] * 1.0 / y_train[y_train == 0].shape[0] # посчитаем соотношение между классами\n",
    "\n",
    "param_grid = {\n",
    "    # параметры ансамбля\n",
    "    'n_estimators': list(np.arange(10, 1000, 50)),#[10, 30, 50, 100, 200, 400, 600, 1000],\n",
    "    'learning_rate': [0.01],\n",
    "    \n",
    "    # параметры дерева\n",
    "    'max_depth': [5],\n",
    "    'min_child_weight': [2],\n",
    "    'gamma': [0.1],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'scale_pos_weight': [ones_ratio],\n",
    "    \n",
    "    # параметры регуляризации\n",
    "    'reg_alpha': [0.0],\n",
    "    'reg_lambda': [1.0]\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=4, shuffle=True)\n",
    "\n",
    "clf = xgboost.XGBClassifier()\n",
    "gs = GridSearchCV(clf, param_grid, scoring='roc_auc', cv=cv, verbose=0)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2. Подбираем параметры дерева\n",
    "* **max_depth** - будем варьировать от 3 до 10 с шагом 2\n",
    "* **min_child_weight** - от 1 до 6 с шагом 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (AUC):  0.886448872502\n",
      "Best params: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'gamma': 0.2,\n",
       " 'learning_rate': 0.00392156862745098,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 510,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0.01,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1.0,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': range(3, 10, 2),\n",
    "    'min_child_weight': range(1, 6, 2)\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params) # в качестве отправной точки возьмём модель с наилучшими параметрами предыдущего шага\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid, scoring='roc_auc', cv=cv, verbose=0)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 3. Подбираем gamma (критерий создания поддерева)\n",
    "* **gamma** - от 0 до 0.5 с шагом 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (AUC):  0.877153314647\n",
      "Best params: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.00392156862745098,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 510,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0.01,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1.0,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'gamma': [0.1*i for i in range(12)]\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params)\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid, scoring='roc_auc', cv=cv, verbose=0)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 4. Затюним subsample и colsample_bytree\n",
    "* **subsample** - от 0.5 до 1.0 с шагом 0.1\n",
    "* **colsample_bytree** - от 0.5 до 1.0 с шагом 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (AUC):  0.878848928102\n",
      "Best params: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.00392156862745098,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 510,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0.01,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1.0,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'subsample': [0.5 + 0.1*i for i in range(6)],\n",
    "    'colsample_bytree': [0.5 + 0.1*i for i in range(6)]\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params)\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid, scoring='roc_auc', cv=cv, verbose=0)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 5. Регуляризация\n",
    "* **reg_alpha** [1e-5, 1e-2, 0.1, 1, 100]\n",
    "* **reg_lambda** [1e-5, 1e-2, 0.1, 1, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (AUC):  0.875423850025\n",
      "Best params: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.00392156862745098,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 510,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0.2,\n",
       " 'reg_lambda': 0.3,\n",
       " 'scale_pos_weight': 1.0,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'reg_alpha': [1e-5, 1e-2, 0.1, 0.2, 0.3, 0.5, 1, 2, 3],\n",
    "    'reg_lambda': [1e-5, 1e-2, 0.1, 0.2, 0.3, 0.5, 1, 2, 3]\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params)\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid, scoring='roc_auc', cv=cv, verbose=0)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 6. Learning rate\n",
    "Чем меньше у нас **n_estimators** в ансамбле, тем быстрее нам нужно двигаться с каждым шагом (добавлением нового классификатора), т.е. делать больший **learning_rate**. Обычно **learning rate** варьируют так, чтобы произведение **n_estimators** x **learning_rate** оставалось инвариантным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score (AUC):  0.935079225352\n",
      "Best params: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'gamma': 0.1,\n",
       " 'learning_rate': 0.0076923076923076927,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 260,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0.2,\n",
       " 'reg_lambda': 0.3,\n",
       " 'scale_pos_weight': 1.0,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params)\n",
    "best_n_estimators = clf.get_params()['n_estimators'] # возьмём наилучшие значения n_estimators с предыдущего шага\n",
    "best_learning_rate = best_params['learning_rate'] # аналогичная запись\n",
    "invariant_composition = best_n_estimators * best_learning_rate\n",
    "n_estimators_range = np.arange(10, 1000, 50)#[10, 30, 100, 200, 400, 600, 800, 1000]\n",
    "\n",
    "best_score = gs.best_score_ # возьмём наилучшее качество с предыдущего шага\n",
    "\n",
    "for n_estimators in n_estimators_range:\n",
    "    learning_rate = invariant_composition / n_estimators\n",
    "    clf.set_params(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "    aucs = []\n",
    "    for train_idx, test_idx in cv.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "        clf.fit(X_train_fold, y_train_fold, verbose=0)\n",
    "        preds = clf.predict_proba(X_test_fold)\n",
    "        auc = roc_auc_score(y_test_fold, preds[:, 1])\n",
    "        aucs.append(auc)\n",
    "    auc = np.mean(auc)\n",
    "    if auc > best_score:\n",
    "        best_n_estimators = n_estimators\n",
    "        best_learning_rate = learning_rate\n",
    "        best_score = auc\n",
    "        \n",
    "best_params['n_estimators'] = best_n_estimators\n",
    "best_params['learning_rate'] = best_learning_rate\n",
    "\n",
    "print('Best score (AUC): ', best_score)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выведем важность признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: \"Fare_3\"\tFeature importance: 0.0942\n",
      "Feature: \"Has_Cabin\"\tFeature importance: 0.0746\n",
      "Feature: \"SibSp\"\tFeature importance: 0.0743\n",
      "Feature: \"Pclass_3\"\tFeature importance: 0.0698\n",
      "Feature: \"IsAlone\"\tFeature importance: 0.0629\n",
      "Feature: \"Pclass_1\"\tFeature importance: 0.0579\n",
      "Feature: \"Title_1\"\tFeature importance: 0.0504\n",
      "Feature: \"Fare_0\"\tFeature importance: 0.0482\n",
      "Feature: \"Age_1.0\"\tFeature importance: 0.0478\n",
      "Feature: \"Title_5\"\tFeature importance: 0.0438\n",
      "Feature: \"Fare_1\"\tFeature importance: 0.0400\n",
      "Feature: \"FamilySize_7\"\tFeature importance: 0.0362\n",
      "Feature: \"Age_3.0\"\tFeature importance: 0.0362\n",
      "Feature: \"FamilySize_4\"\tFeature importance: 0.0357\n",
      "Feature: \"Title_2\"\tFeature importance: 0.0346\n",
      "Feature: \"Fare_2\"\tFeature importance: 0.0344\n",
      "Feature: \"Age_0.0\"\tFeature importance: 0.0296\n",
      "Feature: \"Parch\"\tFeature importance: 0.0185\n",
      "Feature: \"Title_4\"\tFeature importance: 0.0182\n",
      "Feature: \"FamilySize_2\"\tFeature importance: 0.0170\n",
      "Feature: \"Age_2.0\"\tFeature importance: 0.0167\n",
      "Feature: \"FamilySize_6\"\tFeature importance: 0.0134\n",
      "Feature: \"Pclass_2\"\tFeature importance: 0.0109\n",
      "Feature: \"Title_3\"\tFeature importance: 0.0097\n",
      "Feature: \"FamilySize_3\"\tFeature importance: 0.0087\n",
      "Feature: \"FamilySize_1\"\tFeature importance: 0.0078\n",
      "Feature: \"FamilySize_5\"\tFeature importance: 0.0077\n",
      "Feature: \"clusters_0\"\tFeature importance: 0.0008\n",
      "Feature: \"Age_4.0\"\tFeature importance: 0.0002\n",
      "Feature: \"FamilySize_8\"\tFeature importance: 0.0000\n",
      "Feature: \"FamilySize_11\"\tFeature importance: 0.0000\n",
      "Feature: \"clusters_1\"\tFeature importance: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "z = sorted(zip(X_train.columns, clf.feature_importances_), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "for feature_name, feature_importance in z:\n",
    "    print('Feature: \"%s\"\\tFeature importance: %.4f' % (feature_name, feature_importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучим модель с лучшими параметрами и отправим на kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'base_score': 0.5,\n",
    " 'colsample_bylevel': 1,\n",
    " 'colsample_bytree': 0.9,\n",
    " 'gamma': 0.1,\n",
    " 'learning_rate': 0.0076923076923076927,\n",
    " 'max_delta_step': 0,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 1,\n",
    " 'missing': None,\n",
    " 'n_estimators': 260,\n",
    " 'nthread': -1,\n",
    " 'objective': 'binary:logistic',\n",
    " 'reg_alpha': 0.2,\n",
    " 'reg_lambda': 0.3,\n",
    " 'scale_pos_weight': 1.0,\n",
    " 'seed': 0,\n",
    " 'silent': True,\n",
    " 'subsample': 1.0}\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.9,\n",
       "       gamma=0.1, learning_rate=0.007692307692307693, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=260,\n",
       "       nthread=-1, objective='binary:logistic', reg_alpha=0.2,\n",
       "       reg_lambda=0.3, scale_pos_weight=1.0, seed=0, silent=True,\n",
       "       subsample=1.0)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "submussion = 'PassengerId,Survived\\n'\n",
    "submussion += \"\\n\".join([\"{},{}\".format(pid, prediction) for pid, prediction in zip(test.PassengerId, predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission.txt', 'w') as file:\n",
    "    file.write(submussion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
