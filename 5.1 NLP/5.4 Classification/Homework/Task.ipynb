{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание по обработке текстов\n",
    "\n",
    "## Предсказание цены акции по экономическим новостям\n",
    "\n",
    "Входные данные:\n",
    "* Новости о компании \"Газпром\", начиная с 2010 года\n",
    "* Стоимость акций компании \"Газпром\" на ММВБ, начиная с 2010 года\n",
    "    * цена открытия (Open)\n",
    "    * цена закрытия (ClosingPrice)\n",
    "    * максимальная цена за день (DailyHigh)\n",
    "    * минимальная цена за день (DailyLow) \n",
    "    * объем бумаг (VolumePcs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09.11.2017</td>\n",
       "      <td>Компания рассчитывает на решение по газовому с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08.11.2017</td>\n",
       "      <td>Как и предполагал “Ъ”, «Газпром», воспользова...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.11.2017</td>\n",
       "      <td>Новая редакция американских санкций ставит по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.10.2017</td>\n",
       "      <td>Как стало известно “Ъ”, известный на рынке ри...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.10.2017</td>\n",
       "      <td>НОВАТЭК, который через пять лет собирается за...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text\n",
       "0  09.11.2017  Компания рассчитывает на решение по газовому с...\n",
       "1  08.11.2017   Как и предполагал “Ъ”, «Газпром», воспользова...\n",
       "2  01.11.2017   Новая редакция американских санкций ставит по...\n",
       "3  30.10.2017   Как стало известно “Ъ”, известный на рынке ри...\n",
       "4  23.10.2017   НОВАТЭК, который через пять лет собирается за..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('texts.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08.12.2017</td>\n",
       "      <td>133,43000</td>\n",
       "      <td>132,60000</td>\n",
       "      <td>133,90000</td>\n",
       "      <td>132,00000</td>\n",
       "      <td>16037970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07.12.2017</td>\n",
       "      <td>133,70000</td>\n",
       "      <td>133,02000</td>\n",
       "      <td>133,87000</td>\n",
       "      <td>132,81000</td>\n",
       "      <td>18198430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06.12.2017</td>\n",
       "      <td>133,33000</td>\n",
       "      <td>134,00000</td>\n",
       "      <td>134,29000</td>\n",
       "      <td>132,91000</td>\n",
       "      <td>14641730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05.12.2017</td>\n",
       "      <td>133,48000</td>\n",
       "      <td>133,65000</td>\n",
       "      <td>133,99000</td>\n",
       "      <td>132,78000</td>\n",
       "      <td>12684800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04.12.2017</td>\n",
       "      <td>133,01000</td>\n",
       "      <td>133,77000</td>\n",
       "      <td>134,00000</td>\n",
       "      <td>131,93000</td>\n",
       "      <td>17818980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open ClosingPrice  DailyHigh   DailyLow  VolumePcs\n",
       "0  08.12.2017  133,43000    132,60000  133,90000  132,00000   16037970\n",
       "1  07.12.2017  133,70000    133,02000  133,87000  132,81000   18198430\n",
       "2  06.12.2017  133,33000    134,00000  134,29000  132,91000   14641730\n",
       "3  05.12.2017  133,48000    133,65000  133,99000  132,78000   12684800\n",
       "4  04.12.2017  133,01000    133,77000  134,00000  131,93000   17818980"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_all = pd.read_csv('gazprom_prices.csv', sep=';')\n",
    "pr_all.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1. Вводная\n",
    "\n",
    "Проведите предобработку текстов: если считаете нужным, выполните токенизацию, приведение к нижнему регистру, лемматизацию и/или стемминг. Ответьте на следующие вопросы:\n",
    "* Есть ли корреляция между средней длинной текста за день и ценой закрытия?\n",
    "* Есть ли корреляция между количеством упоминаний Алексея Миллера  и ценой закрытия? Учтите разные варианты написания имени.\n",
    "* Упоминаний какого газопровода в статьях больше: \n",
    "    * \"северный поток\"\n",
    "    * \"турецкий поток\"?\n",
    "* О каких санкциях пишут в статьях?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовим данные. Приведем числа к нужному виду и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1988 entries, 0 to 1987\n",
      "Data columns (total 6 columns):\n",
      "Date            1988 non-null object\n",
      "Open            1964 non-null object\n",
      "ClosingPrice    1988 non-null object\n",
      "DailyHigh       1986 non-null object\n",
      "DailyLow        1986 non-null object\n",
      "VolumePcs       1988 non-null int64\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 93.3+ KB\n"
     ]
    }
   ],
   "source": [
    "pr_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_all.Open = pr_all.Open.astype(str).apply(lambda x: x.replace(',','.')).astype(np.double)\n",
    "pr_all.ClosingPrice = pr_all.ClosingPrice.astype(str).apply(lambda x: x.replace(',','.')).astype(np.double)\n",
    "pr_all.DailyHigh = pr_all.DailyHigh.astype(str).apply(lambda x: x.replace(',','.')).astype(np.double)\n",
    "pr_all.DailyLow = pr_all.DailyLow.astype(str).apply(lambda x: x.replace(',','.')).astype(np.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08.12.2017</td>\n",
       "      <td>133.43</td>\n",
       "      <td>132.60</td>\n",
       "      <td>133.90</td>\n",
       "      <td>132.00</td>\n",
       "      <td>16037970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07.12.2017</td>\n",
       "      <td>133.70</td>\n",
       "      <td>133.02</td>\n",
       "      <td>133.87</td>\n",
       "      <td>132.81</td>\n",
       "      <td>18198430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06.12.2017</td>\n",
       "      <td>133.33</td>\n",
       "      <td>134.00</td>\n",
       "      <td>134.29</td>\n",
       "      <td>132.91</td>\n",
       "      <td>14641730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05.12.2017</td>\n",
       "      <td>133.48</td>\n",
       "      <td>133.65</td>\n",
       "      <td>133.99</td>\n",
       "      <td>132.78</td>\n",
       "      <td>12684800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04.12.2017</td>\n",
       "      <td>133.01</td>\n",
       "      <td>133.77</td>\n",
       "      <td>134.00</td>\n",
       "      <td>131.93</td>\n",
       "      <td>17818980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open  ClosingPrice  DailyHigh  DailyLow  VolumePcs\n",
       "0  08.12.2017  133.43        132.60     133.90    132.00   16037970\n",
       "1  07.12.2017  133.70        133.02     133.87    132.81   18198430\n",
       "2  06.12.2017  133.33        134.00     134.29    132.91   14641730\n",
       "3  05.12.2017  133.48        133.65     133.99    132.78   12684800\n",
       "4  04.12.2017  133.01        133.77     134.00    131.93   17818980"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Токенизируем тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Компания рассчитывает на решение по газовому спору с Украиной до конца декабря Газпром ожидает решения Стокгольмского арбитража по транзитному спору с украинским Нафтогазом не позднее февраля года хотя раньше компания прогнозировала что это произойдет до ноября Решение по взаимным искам об условиях поставок газа на Украину по мнению монополии суд может принять на месяц раньше до декабря года'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "regex = re.compile(\"[А-Яа-я----]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    return \" \".join(regex.findall(text))\n",
    "\n",
    "df_tok = df.copy()\n",
    "df_tok.text = df.text.str.lower()\n",
    "df_tok.text = df.text.apply(words_only)\n",
    "df_tok.loc[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лемматизируем тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'компания рассчитывать на решение по газовый спор с украина до конец декабрь газпром ожидать решение стокгольмский арбитраж по транзитный спор с украинский нафтогаз не поздно февраль год хотя рано компания прогнозировать что это происходить до ноябрь решение по взаимный иск об условие поставка газ на украина по мнение монополия суд мочь принимать на месяц рано до декабрь год'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "\n",
    "df_lem = df.copy()\n",
    "m = Mystem()\n",
    "def lemmatize(text, mystem=m):\n",
    "    try:\n",
    "        return \"\".join(m.lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "df_lem.text = df_tok.text.apply(lemmatize)\n",
    "df_lem.loc[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Удалим стоп слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'компания рассчитывать решение газовый спор украина конец декабрь газпром ожидать решение стокгольмский арбитраж транзитный спор украинский нафтогаз поздно февраль хотя рано компания прогнозировать происходить ноябрь решение взаимный иск об условие поставка газ украина мнение монополия суд принимать месяц рано декабрь'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleared = df.copy()\n",
    "mystoplemmas = [\n",
    "\"алтухов\",\"большой\",\"бы\",\"быть\",\"в\",\"весь\",\"вот\",\"все\",\"всей\",\"вы\",\"говорить\",\"год\",\"да\",\"для\",\"до\",\"еще\",\"же\",\"знать\",\"и\",\"из\",\"к\",\"как\",\"который\",\"мочь\",\"мы\",\"на\",\"наш\",\"не\",\"него\",\"нее\",\"нет\",\"них\",\"но\",\"о\",\"один\",\"она\",\"они\",\"оно\",\"оный\",\"от\",\"ото\",\"по\",\"с\",\"свой\",\"себя\",\"сказать\",\"та\",\"такой\",\"только\",\"тот\",\"ты\",\"у\",\"что\",\"это\",\"этот\",\"я\"\n",
    "]\n",
    "def  remove_stoplemmas(text, mystoplemmas = mystoplemmas):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in mystoplemmas])\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "df_cleared.text = df_lem.text.apply(remove_stoplemmas) \n",
    "df_cleared.loc[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оставим только те дни, в которые были новости "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим таблицы с новостями и с котировками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09.11.2017</td>\n",
       "      <td>компания рассчитывать решение газовый спор укр...</td>\n",
       "      <td>132.31</td>\n",
       "      <td>131.50</td>\n",
       "      <td>132.82</td>\n",
       "      <td>131.14</td>\n",
       "      <td>33869650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08.11.2017</td>\n",
       "      <td>предполагать Ъ газпром воспользоваться жалоба ...</td>\n",
       "      <td>132.00</td>\n",
       "      <td>132.30</td>\n",
       "      <td>133.94</td>\n",
       "      <td>131.58</td>\n",
       "      <td>39381960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.11.2017</td>\n",
       "      <td>новый редакция американский санкция ставить по...</td>\n",
       "      <td>126.40</td>\n",
       "      <td>126.50</td>\n",
       "      <td>126.89</td>\n",
       "      <td>125.97</td>\n",
       "      <td>18232550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.10.2017</td>\n",
       "      <td>становиться известно Ъ известный рынок риск-ме...</td>\n",
       "      <td>125.96</td>\n",
       "      <td>125.98</td>\n",
       "      <td>126.93</td>\n",
       "      <td>125.53</td>\n",
       "      <td>19263340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.10.2017</td>\n",
       "      <td>новатэк через пять собираться запускать камчат...</td>\n",
       "      <td>127.05</td>\n",
       "      <td>126.80</td>\n",
       "      <td>127.47</td>\n",
       "      <td>126.37</td>\n",
       "      <td>17308800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text    Open  \\\n",
       "0  09.11.2017  компания рассчитывать решение газовый спор укр...  132.31   \n",
       "1  08.11.2017  предполагать Ъ газпром воспользоваться жалоба ...  132.00   \n",
       "2  01.11.2017  новый редакция американский санкция ставить по...  126.40   \n",
       "3  30.10.2017  становиться известно Ъ известный рынок риск-ме...  125.96   \n",
       "4  23.10.2017  новатэк через пять собираться запускать камчат...  127.05   \n",
       "\n",
       "   ClosingPrice  DailyHigh  DailyLow  VolumePcs  \n",
       "0        131.50     132.82    131.14   33869650  \n",
       "1        132.30     133.94    131.58   39381960  \n",
       "2        126.50     126.89    125.97   18232550  \n",
       "3        125.98     126.93    125.53   19263340  \n",
       "4        126.80     127.47    126.37   17308800  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.merge(df_cleared, pr_all, left_on='date', right_on='Date').drop('Date', axis=1)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим столбец с оригинальными длинами текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>len_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09.11.2017</td>\n",
       "      <td>компания рассчитывать решение газовый спор укр...</td>\n",
       "      <td>132.31</td>\n",
       "      <td>131.50</td>\n",
       "      <td>132.82</td>\n",
       "      <td>131.14</td>\n",
       "      <td>33869650</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08.11.2017</td>\n",
       "      <td>предполагать Ъ газпром воспользоваться жалоба ...</td>\n",
       "      <td>132.00</td>\n",
       "      <td>132.30</td>\n",
       "      <td>133.94</td>\n",
       "      <td>131.58</td>\n",
       "      <td>39381960</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.11.2017</td>\n",
       "      <td>новый редакция американский санкция ставить по...</td>\n",
       "      <td>126.40</td>\n",
       "      <td>126.50</td>\n",
       "      <td>126.89</td>\n",
       "      <td>125.97</td>\n",
       "      <td>18232550</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.10.2017</td>\n",
       "      <td>становиться известно Ъ известный рынок риск-ме...</td>\n",
       "      <td>125.96</td>\n",
       "      <td>125.98</td>\n",
       "      <td>126.93</td>\n",
       "      <td>125.53</td>\n",
       "      <td>19263340</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.10.2017</td>\n",
       "      <td>новатэк через пять собираться запускать камчат...</td>\n",
       "      <td>127.05</td>\n",
       "      <td>126.80</td>\n",
       "      <td>127.47</td>\n",
       "      <td>126.37</td>\n",
       "      <td>17308800</td>\n",
       "      <td>1270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text    Open  \\\n",
       "0  09.11.2017  компания рассчитывать решение газовый спор укр...  132.31   \n",
       "1  08.11.2017  предполагать Ъ газпром воспользоваться жалоба ...  132.00   \n",
       "2  01.11.2017  новый редакция американский санкция ставить по...  126.40   \n",
       "3  30.10.2017  становиться известно Ъ известный рынок риск-ме...  125.96   \n",
       "4  23.10.2017  новатэк через пять собираться запускать камчат...  127.05   \n",
       "\n",
       "   ClosingPrice  DailyHigh  DailyLow  VolumePcs  len_orig  \n",
       "0        131.50     132.82    131.14   33869650       419  \n",
       "1        132.30     133.94    131.58   39381960       624  \n",
       "2        126.50     126.89    125.97   18232550       834  \n",
       "3        125.98     126.93    125.53   19263340       436  \n",
       "4        126.80     127.47    126.37   17308800      1270  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"len_orig\"] = df.text.apply(len)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1159.000000\n",
       "mean      769.454702\n",
       "std       545.009405\n",
       "min        85.000000\n",
       "25%       405.500000\n",
       "50%       581.000000\n",
       "75%      1002.000000\n",
       "max      4111.000000\n",
       "Name: len_orig, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"len_orig\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10a30a860>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXpIqZ9FLUuUsekmq3P8CBzE2LGOrsm0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a2d1ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_merged[\"len_orig\"][df_merged[\"len_orig\"] < 2000].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Определим коэффициент корреляции Пирсона между длинной текста и ценой закрытия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024107054173230204"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"len_orig\"].corr(df_merged[\"ClosingPrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из чего можно сделать вывод что корреляция отсутствует"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Есть ли корреляция между количеством упоминаний Алексея Миллера и ценой закрытия?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'украина обязывать -летний контракт российский газпром ежегодно покупать определенный объем газ готовый продавать газ собственный добыча спотовый европейский рынок если россия заставлять киев купить объем газ превышать потребность страна если российский партнер предлагать закупать много газ чем нужно экономика просто взять газ сюда страна а газ перепродавать спот - министр энергетика угольный промышленность юрий бойко уточнять сомневаться газпром довольный появление конкурент европейский рынок оао газпром намерен инвестировать значительный сумма разведка нефть газ киргизия заявлять председатель правление российский газовый холдинг алексей миллер среда итог переговоры премьер-министр киргизия алмазбек атамбаев планировать объем инвестиция геологоразведка составлять первый этап менее млрд руб - он журналист руководство аэропорт кольцово екатеринбург направлять росрезерв официальный обращение выделение авиакеросин госрезерв сообщать пресс-служба авиапредприятие иметься запас авиакеросин обеспечивать бесперебойный работа аэропорт течение - день данный момент законтрактовывать уже т т необходимый сентябрь - говориться пресс-релиз оао газпром нефть подтвердить дополнительный заявка ТЗК кольцово поставка т авиакеросин сентябрь руководство аэропорт кольцово екатеринбург направлять росрезерв официальный обращение выделение авиакеросин госрезерв сообщать пресс-служба авиапредприятие иметься запас авиакеросин обеспечивать бесперебойный работа аэропорт течение - день данный момент законтрактовывать уже т т необходимый сентябрь - говориться пресс-релиз оао газпром нефть подтвердить дополнительный заявка ТЗК кольцово поставка т авиакеросин сентябрь газпром итальянский наконец договариваться распределение доля новый участник проект строительство газопровод южный поток французский немецкий получать за счет доля результат газпром сохранять а всего эксперт объяснять сговорчивость итальянец то уже добиваться газпром хотеть текущий контракт число льготный условие договор поставка газ'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.text[993]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"miller_count\"] = df_merged.text.str.findall(\"алекс+[а-я]*\\sмиллер | алекс | миллер\").apply(len) #|[алекс]|[миллер]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>len_orig</th>\n",
       "      <th>miller_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>30.06.2017</td>\n",
       "      <td>газпром оспаривать промежуточный решение стокг...</td>\n",
       "      <td>118.86</td>\n",
       "      <td>118.49</td>\n",
       "      <td>120.22</td>\n",
       "      <td>118.18</td>\n",
       "      <td>22483610</td>\n",
       "      <td>868</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>30.05.2017</td>\n",
       "      <td>газпром сообщение встреча глава компания алекс...</td>\n",
       "      <td>122.72</td>\n",
       "      <td>122.10</td>\n",
       "      <td>122.91</td>\n",
       "      <td>121.79</td>\n",
       "      <td>16159700</td>\n",
       "      <td>1056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>05.05.2017</td>\n",
       "      <td>газпром перехватывать инициатива борьба за суд...</td>\n",
       "      <td>133.68</td>\n",
       "      <td>134.41</td>\n",
       "      <td>134.94</td>\n",
       "      <td>132.91</td>\n",
       "      <td>26287190</td>\n",
       "      <td>389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>16.12.2016</td>\n",
       "      <td>предправление газпром алексей миллер называть ...</td>\n",
       "      <td>158.48</td>\n",
       "      <td>156.20</td>\n",
       "      <td>158.88</td>\n",
       "      <td>156.20</td>\n",
       "      <td>31710640</td>\n",
       "      <td>585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>21.09.2016</td>\n",
       "      <td>президент россия владимир путин поздравлять ро...</td>\n",
       "      <td>137.21</td>\n",
       "      <td>136.25</td>\n",
       "      <td>137.48</td>\n",
       "      <td>135.50</td>\n",
       "      <td>15958010</td>\n",
       "      <td>1454</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                               text    Open  \\\n",
       "40   30.06.2017  газпром оспаривать промежуточный решение стокг...  118.86   \n",
       "53   30.05.2017  газпром сообщение встреча глава компания алекс...  122.72   \n",
       "61   05.05.2017  газпром перехватывать инициатива борьба за суд...  133.68   \n",
       "115  16.12.2016  предправление газпром алексей миллер называть ...  158.48   \n",
       "146  21.09.2016  президент россия владимир путин поздравлять ро...  137.21   \n",
       "\n",
       "     ClosingPrice  DailyHigh  DailyLow  VolumePcs  len_orig  miller_count  \n",
       "40         118.49     120.22    118.18   22483610       868             2  \n",
       "53         122.10     122.91    121.79   16159700      1056             1  \n",
       "61         134.41     134.94    132.91   26287190       389             1  \n",
       "115        156.20     158.88    156.20   31710640       585             1  \n",
       "146        136.25     137.48    135.50   15958010      1454             1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged[\"miller_count\"] > 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010635076467578003"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"miller_count\"].corr(df_merged[\"ClosingPrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод - корреляция отсутствует"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Упоминаний какого газопровода в статьях больше:\n",
    "\"северный поток\"\n",
    "\"турецкий поток\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"north_way\"] = df_merged.text.str.findall(\"север+[а-я]*\\sпоток\").apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"north_way\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[\"turk_way\"] = df_merged.text.str.findall(\"туре+[а-я]*\\sпоток\").apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[\"turk_way\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод - о Турецком потоке говорили чаще"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### О каких санкциях пишут в статьях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sanc = df.copy()\n",
    "df_sanc.text = df.text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09.11.2017</td>\n",
       "      <td>компания рассчитывает на решение по газовому с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08.11.2017</td>\n",
       "      <td>как и предполагал “ъ”, «газпром», воспользова...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.11.2017</td>\n",
       "      <td>новая редакция американских санкций ставит по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.10.2017</td>\n",
       "      <td>как стало известно “ъ”, известный на рынке ри...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.10.2017</td>\n",
       "      <td>новатэк, который через пять лет собирается за...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text\n",
       "0  09.11.2017  компания рассчитывает на решение по газовому с...\n",
       "1  08.11.2017   как и предполагал “ъ”, «газпром», воспользова...\n",
       "2  01.11.2017   новая редакция американских санкций ставит по...\n",
       "3  30.10.2017   как стало известно “ъ”, известный на рынке ри...\n",
       "4  23.10.2017   новатэк, который через пять лет собирается за..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sanc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanc = df_sanc.text[df_sanc.text.str.findall(\"санкци+[а-я]*\").apply(lambda x : len(x) > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним тексты содержащие слово санкции в файл, что бы потом отдать это в syntaxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sancs.txt', \"w\") as f:\n",
    "    for i in sanc:\n",
    "#         print(i)\n",
    "        f.write(i)\n",
    "        f.write('\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-31 11:10:50.955998: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.956020: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.956055: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.956055: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.956065: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.956071: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.956071: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.956080: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.956080: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.956089: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.957718: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.957756: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.957873: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.958066: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.958388: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n",
      "2017-12-31 11:10:50.968605: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\r\n",
      "2017-12-31 11:10:50.969162: I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-tag input(-2).pred-tag input(-3).pred-tag input(-4).pred-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\r\n",
      "2017-12-31 11:10:50.969205: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\r\n",
      "2017-12-31 11:10:50.969212: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\r\n",
      "2017-12-31 11:10:50.969610: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\r\n",
      "2017-12-31 11:10:50.970053: I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-morph-tag input(-2).pred-morph-tag input(-3).pred-morph-tag input(-4).pred-morph-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\r\n",
      "2017-12-31 11:10:50.970092: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\r\n",
      "2017-12-31 11:10:50.970103: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\r\n",
      "2017-12-31 11:10:50.974714: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\r\n",
      "2017-12-31 11:10:50.975215: I syntaxnet/embedding_feature_extractor.cc:35] Features: stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack(1).child(2).label stack(1).child(-2).label; input.token.morphology-set input(1).token.morphology-set input(2).token.morphology-set input(3).token.morphology-set stack.token.morphology-set stack.child(1).token.morphology-set stack.child(1).sibling(-1).token.morphology-set stack.child(-1).token.morphology-set stack.child(-1).sibling(1).token.morphology-set stack.child(2).token.morphology-set stack.child(-2).token.morphology-set stack(1).token.morphology-set stack(1).child(1).token.morphology-set stack(1).child(1).sibling(-1).token.morphology-set stack(1).child(-1).token.morphology-set stack(1).child(-1).sibling(1).token.morphology-set stack(1).child(2).token.morphology-set stack(1).child(-2).token.morphology-set stack(2).token.morphology-set stack(3).token.morphology-set; input.token.tag input(1).token.tag input(2).token.tag input(3).token.tag stack.token.tag stack.child(1).token.tag stack.child(1).sibling(-1).token.tag stack.child(-1).token.tag stack.child(-1).sibling(1).token.tag stack.child(2).token.tag stack.child(-2).token.tag stack(1).token.tag stack(1).child(1).token.tag stack(1).child(1).sibling(-1).token.tag stack(1).child(-1).token.tag stack(1).child(-1).sibling(1).token.tag stack(1).child(2).token.tag stack(1).child(-2).token.tag stack(2).token.tag stack(3).token.tag; input.token.word input(1).token.word input(2).token.word input(3).token.word stack.token.word stack.child(1).token.word stack.child(1).sibling(-1).token.word stack.child(-1).token.word stack.child(-1).sibling(1).token.word stack.child(2).token.word stack.child(-2).token.word stack(1).token.word stack(1).child(1).token.word stack(1).child(1).sibling(-1).token.word stack(1).child(-1).token.word stack(1).child(-1).sibling(1).token.word stack(1).child(2).token.word stack(1).child(-2).token.word stack(2).token.word stack(3).token.word \r\n",
      "2017-12-31 11:10:50.975254: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: labels;morphology;tags;words\r\n",
      "2017-12-31 11:10:50.975265: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 32;32;32;64\r\n",
      "2017-12-31 11:10:50.976959: I syntaxnet/term_frequency_map.cc:101] Loaded 66 terms from ./syntaxnet/models/Russian-SynTagRus/morphology-map.\r\n",
      "2017-12-31 11:10:50.977759: I syntaxnet/term_frequency_map.cc:101] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-31 11:10:51.216288: I syntaxnet/term_frequency_map.cc:101] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "2017-12-31 11:10:51.226889: I syntaxnet/term_frequency_map.cc:101] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "2017-12-31 11:10:51.232739: I syntaxnet/term_frequency_map.cc:101] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "2017-12-31 11:10:52.357992: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [12 20 20 20] domain_sizes: [    37     66     33 103475]\n",
      "2017-12-31 11:10:52.573775: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [8 8 4 8 8 8 8 4 8] domain_sizes: [     7  18750      5   8502   8502   7249   7249    449 103475]\n",
      "2017-12-31 11:10:52.630024: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [8 8 4 8 8 8 8 4 8] domain_sizes: [     7  18750      5   8502   8502   7249   7249     34 103475]\n",
      "INFO:tensorflow:Restoring parameters from ./syntaxnet/models/Russian-SynTagRus/parser-params\n",
      "2017-12-31 11:10:53.394796: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2017-12-31 11:10:53.394871: I syntaxnet/embedding_feature_extractor.cc:35] Features: stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack(1).child(2).label stack(1).child(-2).label; input.token.morphology-set input(1).token.morphology-set input(2).token.morphology-set input(3).token.morphology-set stack.token.morphology-set stack.child(1).token.morphology-set stack.child(1).sibling(-1).token.morphology-set stack.child(-1).token.morphology-set stack.child(-1).sibling(1).token.morphology-set stack.child(2).token.morphology-set stack.child(-2).token.morphology-set stack(1).token.morphology-set stack(1).child(1).token.morphology-set stack(1).child(1).sibling(-1).token.morphology-set stack(1).child(-1).token.morphology-set stack(1).child(-1).sibling(1).token.morphology-set stack(1).child(2).token.morphology-set stack(1).child(-2).token.morphology-set stack(2).token.morphology-set stack(3).token.morphology-set; input.token.tag input(1).token.tag input(2).token.tag input(3).token.tag stack.token.tag stack.child(1).token.tag stack.child(1).sibling(-1).token.tag stack.child(-1).token.tag stack.child(-1).sibling(1).token.tag stack.child(2).token.tag stack.child(-2).token.tag stack(1).token.tag stack(1).child(1).token.tag stack(1).child(1).sibling(-1).token.tag stack(1).child(-1).token.tag stack(1).child(-1).sibling(1).token.tag stack(1).child(2).token.tag stack(1).child(-2).token.tag stack(2).token.tag stack(3).token.tag; input.token.word input(1).token.word input(2).token.word input(3).token.word stack.token.word stack.child(1).token.word stack.child(1).sibling(-1).token.word stack.child(-1).token.word stack.child(-1).sibling(1).token.word stack.child(2).token.word stack.child(-2).token.word stack(1).token.word stack(1).child(1).token.word stack(1).child(1).sibling(-1).token.word stack(1).child(-1).token.word stack(1).child(-1).sibling(1).token.word stack(1).child(2).token.word stack(1).child(-2).token.word stack(2).token.word stack(3).token.word \n",
      "2017-12-31 11:10:53.394890: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: labels;morphology;tags;words\n",
      "2017-12-31 11:10:53.394899: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 32;32;32;64\n",
      "2017-12-31 11:10:53.397653: I syntaxnet/term_frequency_map.cc:101] Loaded 66 terms from ./syntaxnet/models/Russian-SynTagRus/morphology-map.\n",
      "2017-12-31 11:10:53.399173: I syntaxnet/term_frequency_map.cc:101] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "INFO:tensorflow:Restoring parameters from ./syntaxnet/models/Russian-SynTagRus/morpher-params\n",
      "INFO:tensorflow:Restoring parameters from ./syntaxnet/models/Russian-SynTagRus/tagger-params\n",
      "2017-12-31 11:10:53.922205: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2017-12-31 11:10:53.922277: I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-morph-tag input(-2).pred-morph-tag input(-3).pred-morph-tag input(-4).pred-morph-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\n",
      "2017-12-31 11:10:53.922289: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\n",
      "2017-12-31 11:10:53.922298: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\n",
      "2017-12-31 11:10:53.966372: I syntaxnet/term_frequency_map.cc:101] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "2017-12-31 11:10:53.967092: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2017-12-31 11:10:53.967137: I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-tag input(-2).pred-tag input(-3).pred-tag input(-4).pred-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\n",
      "2017-12-31 11:10:53.967151: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\n",
      "2017-12-31 11:10:53.967160: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-31 11:10:54.169914: I syntaxnet/term_frequency_map.cc:101] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "2017-12-31 11:10:54.217678: I syntaxnet/term_frequency_map.cc:101] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "2017-12-31 11:10:54.823807: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "2017-12-31 11:10:55.517792: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "2017-12-31 11:10:55.611616: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Processed 116 documents\n",
      "INFO:tensorflow:Total processed documents: 116\n",
      "INFO:tensorflow:num correct tokens: 0\n",
      "INFO:tensorflow:total tokens: 6227\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 4.95, eval metric: 0.00%\n",
      "INFO:tensorflow:Processed 116 documents\n",
      "INFO:tensorflow:Total processed documents: 116\n",
      "INFO:tensorflow:num correct tokens: 0\n",
      "INFO:tensorflow:total tokens: 6227\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 8.04, eval metric: 0.00%\n",
      "INFO:tensorflow:Processed 116 documents\n",
      "INFO:tensorflow:Total processed documents: 116\n",
      "INFO:tensorflow:num correct tokens: 116\n",
      "INFO:tensorflow:total tokens: 6227\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 19.86, eval metric: 1.86%\n"
     ]
    }
   ],
   "source": [
    "! cat sancs.txt | docker run --rm -i inemo/syntaxnet_rus > data_sanc.conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import DependencyGraph\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "новая\n",
      "санкций\n",
      "\n",
      "американских\n",
      "санкций\n",
      "\n",
      "зарубежные\n",
      "санкций\n",
      "\n",
      "нефтяные\n",
      "санкций\n",
      "\n",
      "российских\n",
      "санкций\n",
      "\n",
      "американским\n",
      "санкций\n",
      "\n",
      "определенных\n",
      "санкций\n",
      "\n",
      "нефтяных\n",
      "санкций\n",
      "\n",
      "российским\n",
      "санкций\n",
      "\n",
      "аналогичных\n",
      "санкций\n",
      "\n",
      "которые\n",
      "санкций\n",
      "\n",
      "российской\n",
      "санкций\n",
      "\n",
      "первую\n",
      "санкций\n",
      "\n",
      "аяшском\n",
      "санкций\n",
      "\n",
      "крупное\n",
      "санкций\n",
      "\n",
      "геологические\n",
      "санкций\n",
      "\n",
      "тонн,\n",
      "санкций\n",
      "\n",
      "тонн,\n",
      "санкций\n",
      "\n",
      "экономической\n",
      "санкций\n",
      "\n",
      "первую\n",
      "санкций\n",
      "\n",
      "аяшском\n",
      "санкций\n",
      "\n",
      "крупное\n",
      "санкций\n",
      "\n",
      "геологические\n",
      "санкций\n",
      "\n",
      "тонн,\n",
      "санкций\n",
      "\n",
      "тонн,\n",
      "санкций\n",
      "\n",
      "экономической\n",
      "санкций\n",
      "\n",
      "основным\n",
      "санкций.\n",
      "\n",
      "испанской\n",
      "санкций.\n",
      "\n",
      "новые\n",
      "санкций.\n",
      "\n",
      "сих\n",
      "санкций.\n",
      "\n",
      "добычные\n",
      "санкций.\n",
      "\n",
      "худайнатова,\n",
      "санкций.\n",
      "\n",
      "особой\n",
      "санкций.\n",
      "\n",
      "испанской\n",
      "санкций.\n",
      "\n",
      "паритетных\n",
      "санкций.\n",
      "\n",
      "комфортным\n",
      "санкций.\n",
      "\n",
      "основным\n",
      "санкций.\n",
      "\n",
      "испанской\n",
      "санкций.\n",
      "\n",
      "новые\n",
      "санкций.\n",
      "\n",
      "сих\n",
      "санкций.\n",
      "\n",
      "добычные\n",
      "санкций.\n",
      "\n",
      "худайнатова,\n",
      "санкций.\n",
      "\n",
      "особой\n",
      "санкций.\n",
      "\n",
      "испанской\n",
      "санкций.\n",
      "\n",
      "паритетных\n",
      "санкций.\n",
      "\n",
      "комфортным\n",
      "санкций.\n",
      "\n",
      "крупные\n",
      "санкций,\n",
      "\n",
      "лизинговые\n",
      "санкций,\n",
      "\n",
      "железнодорожных\n",
      "санкций,\n",
      "\n",
      "подвижной\n",
      "санкций,\n",
      "\n",
      "текущей\n",
      "санкций,\n",
      "\n",
      "рыболовных\n",
      "санкций,\n",
      "\n",
      "западных\n",
      "санкций,\n",
      "\n",
      "высшая\n",
      "санкций\n",
      "\n",
      "судебная\n",
      "санкций\n",
      "\n",
      "европейского\n",
      "санкций\n",
      "\n",
      "других\n",
      "санкций\n",
      "\n",
      "долгосрочное\n",
      "санкций\n",
      "\n",
      "шельфе.\n",
      "санкций\n",
      "\n",
      "первым\n",
      "санкций\n",
      "\n",
      "крупнейших\n",
      "санкциями\n",
      "\n",
      "российских\n",
      "санкциями\n",
      "\n",
      "самопровозглашенных\n",
      "санкциями\n",
      "\n",
      "донецкой\n",
      "санкциями\n",
      "\n",
      "луганской\n",
      "санкциями\n",
      "\n",
      "народных\n",
      "санкциями\n",
      "\n",
      "февральского\n",
      "санкциями\n",
      "\n",
      "украинских\n",
      "санкциями\n",
      "\n",
      "недовольны\n",
      "санкциями\n",
      "\n",
      "крупнейших\n",
      "санкциями\n",
      "\n",
      "российских\n",
      "санкциями\n",
      "\n",
      "самопровозглашенных\n",
      "санкциями\n",
      "\n",
      "донецкой\n",
      "санкциями\n",
      "\n",
      "луганской\n",
      "санкциями\n",
      "\n",
      "народных\n",
      "санкциями\n",
      "\n",
      "февральского\n",
      "санкциями\n",
      "\n",
      "украинских\n",
      "санкциями\n",
      "\n",
      "недовольны\n",
      "санкциями\n",
      "\n",
      "коммерческих\n",
      "санкции.\n",
      "\n",
      "китайской\n",
      "санкции.\n",
      "\n",
      "трубопроводным\n",
      "санкции.\n",
      "\n",
      "дальнем\n",
      "санкции.\n",
      "\n",
      "неясны\n",
      "санкции.\n",
      "\n",
      "южно-киринского\n",
      "санкции.\n",
      "\n",
      "политическом\n",
      "санкции.\n",
      "\n",
      "который\n",
      "санкции.\n",
      "\n",
      "сахалинский\n",
      "санкции.\n",
      "\n",
      "киевского\n",
      "несанкционированного\n",
      "\n",
      "странным.\n",
      "несанкционированного\n",
      "\n",
      "украинском\n",
      "несанкционированного\n",
      "\n",
      "несанкционированного\n",
      "несанкционированного\n",
      "\n",
      "российского\n",
      "несанкционированного\n",
      "\n",
      "известно\n",
      "санкции\n",
      "\n",
      "новый\n",
      "санкции\n",
      "\n",
      "\"балтийский\n",
      "санкции\n",
      "\n",
      "самостоятельный\n",
      "санкции\n",
      "\n",
      "российской\n",
      "санкции\n",
      "\n",
      "иностранный\n",
      "санкции\n",
      "\n",
      "англо-голландская\n",
      "санкции\n",
      "\n",
      "российский\n",
      "санкции\n",
      "\n",
      "\"балтийский\n",
      "санкции\n",
      "\n",
      "дополнительные\n",
      "санкции\n",
      "\n",
      "налоговые\n",
      "санкции\n",
      "\n",
      "собственные\n",
      "санкции\n",
      "\n",
      "\"балтийского\n",
      "санкции\n",
      "\n",
      "вэб\n",
      "санкциями\n",
      "\n",
      "ближайшие\n",
      "санкциями\n",
      "\n",
      "\"газпром\"\n",
      "санкциями\n",
      "\n",
      "собственных\n",
      "санкциями\n",
      "\n",
      "реальные\n",
      "санкций\n",
      "\n",
      "технологической\n",
      "санкций\n",
      "\n",
      "уязвимых\n",
      "санкций\n",
      "\n",
      "спг\n",
      "санкций\n",
      "\n",
      "подводных\n",
      "санкций\n",
      "\n",
      "европейским\n",
      "санкций\n",
      "\n",
      "дальнем\n",
      "санкций\n",
      "\n",
      "западных\n",
      "санкций\n",
      "\n",
      "балтийскому\n",
      "санкций\n",
      "\n",
      "неясны.\n",
      "санкций\n",
      "\n",
      "частных\n",
      "санкциями\n",
      "\n",
      "государственные\n",
      "санкциями\n",
      "\n",
      "каспийском\n",
      "санкциями\n",
      "\n",
      "шельфе,\n",
      "санкциями\n",
      "\n",
      "новых\n",
      "санкций.\n",
      "\n",
      "экспортных\n",
      "санкций.\n",
      "\n",
      "первую\n",
      "санкций.\n",
      "\n",
      "президентской\n",
      "санкций.\n",
      "\n",
      "очередных\n",
      "санкций.\n",
      "\n",
      "российских\n",
      "санкций.\n",
      "\n",
      "последние\n",
      "санкций.\n",
      "\n",
      "реальное\n",
      "санкций.\n",
      "\n",
      "невелико.\n",
      "санкций.\n",
      "\n",
      "\"газпром-медиа\"\n",
      "несанкционированного\n",
      "\n",
      "партнерского\n",
      "несанкционированного\n",
      "\n",
      "несанкционированного\n",
      "несанкционированного\n",
      "\n",
      "который\n",
      "санкции\n",
      "\n",
      "сих\n",
      "санкции\n",
      "\n",
      "западные\n",
      "санкции\n",
      "\n",
      "черный\n",
      "санкции\n",
      "\n",
      "южно-киринское\n",
      "санкции\n",
      "\n",
      "газоконденсатное\n",
      "санкции\n",
      "\n",
      "американским\n",
      "санкции\n",
      "\n",
      "южно-киринского\n",
      "санкции\n",
      "\n",
      "этого\n",
      "санкции\n",
      "\n",
      "стратегическое\n",
      "санкции\n",
      "\n",
      "англо-голландской\n",
      "санкции\n",
      "\n",
      "«российская\n",
      "санкциями\n",
      "\n",
      "неплатежеспособной\n",
      "санкциями\n",
      "\n",
      "природного\n",
      "санкциями\n",
      "\n",
      "мировым\n",
      "санкциями\n",
      "\n",
      "экономическим\n",
      "санкциями\n",
      "\n",
      "западными\n",
      "санкциями\n",
      "\n",
      "экономическими\n",
      "санкциями\n",
      "\n",
      "туркменского\n",
      "санкциями\n",
      "\n",
      "природного\n",
      "санкциями\n",
      "\n",
      "крупные\n",
      "санкций\n",
      "\n",
      "российские\n",
      "санкций\n",
      "\n",
      "репутационных\n",
      "санкций\n",
      "\n",
      "рисков.\n",
      "санкций\n",
      "\n",
      "который\n",
      "санкций\n",
      "\n",
      "керченский\n",
      "санкций\n",
      "\n",
      "прокладкой\n",
      "санкций\n",
      "\n",
      "\"профильная\n",
      "санкций\n",
      "\n",
      "крымский\n",
      "санкций\n",
      "\n",
      "стратегического\n",
      "санкций\n",
      "\n",
      "\"балтийский\n",
      "санкций\n",
      "\n",
      "1 трлн\n",
      "санкций\n",
      "\n",
      "один\n",
      "санкций\n",
      "\n",
      "которых\n",
      "санкций\n",
      "\n",
      "англо-голландская\n",
      "санкций\n",
      "\n",
      "shell.\n",
      "санкций\n",
      "\n",
      "первой\n",
      "санкций\n",
      "\n",
      "крупной\n",
      "санкций\n",
      "\n",
      "иностранной\n",
      "санкций\n",
      "\n",
      "новый\n",
      "санкций\n",
      "\n",
      "российском\n",
      "санкций\n",
      "\n",
      "реальной\n",
      "санкций\n",
      "\n",
      "второго\n",
      "санкций\n",
      "\n",
      "стратегического\n",
      "санкций\n",
      "\n",
      "\"балтийский\n",
      "санкций\n",
      "\n",
      "1 трлн\n",
      "санкций\n",
      "\n",
      "один\n",
      "санкций\n",
      "\n",
      "которых\n",
      "санкций\n",
      "\n",
      "англо-голландская\n",
      "санкций\n",
      "\n",
      "shell.\n",
      "санкций\n",
      "\n",
      "первой\n",
      "санкций\n",
      "\n",
      "крупной\n",
      "санкций\n",
      "\n",
      "иностранной\n",
      "санкций\n",
      "\n",
      "новый\n",
      "санкций\n",
      "\n",
      "российском\n",
      "санкций\n",
      "\n",
      "реальной\n",
      "санкций\n",
      "\n",
      "второго\n",
      "санкций\n",
      "\n",
      "первым\n",
      "санкциями,\n",
      "\n",
      "российских\n",
      "санкциями,\n",
      "\n",
      "московской\n",
      "санкциями,\n",
      "\n",
      "основными\n",
      "санкциями,\n",
      "\n",
      "азиатские\n",
      "санкциями,\n",
      "\n",
      "якорные\n",
      "санкциями,\n",
      "\n",
      "большую\n",
      "санкциями,\n",
      "\n",
      "антироссийскими\n",
      "санкциями,\n",
      "\n",
      "которые\n",
      "санкциями,\n",
      "\n",
      "первого\n",
      "санкции\n",
      "\n",
      "государственные\n",
      "санкции\n",
      "\n",
      "персональные\n",
      "санкции\n",
      "\n",
      "«российский\n",
      "санкции\n",
      "\n",
      "финансово-экономическом\n",
      "санкции\n",
      "\n",
      "внебюджетные\n",
      "санкций\n",
      "\n",
      "энергетического\n",
      "санкций\n",
      "\n",
      "федерального\n",
      "санкций\n",
      "\n",
      "кубань--крым,\n",
      "санкций\n",
      "\n",
      "который\n",
      "санкций\n",
      "\n",
      "должен\n",
      "санкций\n",
      "\n",
      "необходимых\n",
      "санкций\n",
      "\n",
      "неизвестным.\n",
      "санкций\n",
      "\n",
      "готова\n",
      "санкции\n",
      "\n",
      "европейскую\n",
      "санкции\n",
      "\n",
      "высококонкурентном\n",
      "санкции\n",
      "\n",
      "европейском\n",
      "санкции\n",
      "\n",
      "рынке.\n",
      "санкции\n",
      "\n",
      "гибкого\n",
      "санкции\n",
      "\n",
      "новой\n",
      "санкции\n",
      "\n",
      "европейской\n",
      "санкции\n",
      "\n",
      "\"турецкого\n",
      "санкций\n",
      "\n",
      "который\n",
      "санкций\n",
      "\n",
      "должен\n",
      "санкций\n",
      "\n",
      "черному\n",
      "санкций\n",
      "\n",
      "европейскую\n",
      "санкций\n",
      "\n",
      "морскую\n",
      "санкций\n",
      "\n",
      "\"газпром\",\n",
      "санкций\n",
      "\n",
      "небольшой\n",
      "санкций\n",
      "\n",
      "сухопутный\n",
      "санкций\n",
      "\n",
      "первую\n",
      "санкций\n",
      "\n",
      "\"турецкого\n",
      "санкций\n",
      "\n",
      "главная\n",
      "санкций\n",
      "\n",
      "значительное\n",
      "санкции\n",
      "\n",
      "финансовые\n",
      "санкции\n",
      "\n",
      "финансовый\n",
      "санкции\n",
      "\n",
      "круглов.\n",
      "санкции\n",
      "\n",
      "возможные\n",
      "санкции\n",
      "\n",
      "существенного\n",
      "санкции\n",
      "\n",
      "финансовые\n",
      "санкции\n",
      "\n",
      "существенный\n",
      "санкции\n",
      "\n",
      "собственных\n",
      "санкции\n",
      "\n",
      "подобных\n",
      "санкции\n",
      "\n",
      "ощутимых\n",
      "санкции\n",
      "\n",
      "финансовых\n",
      "санкции\n",
      "\n",
      "значительное\n",
      "санкций\n",
      "\n",
      "финансовые\n",
      "санкций\n",
      "\n",
      "финансовый\n",
      "санкций\n",
      "\n",
      "круглов.\n",
      "санкций\n",
      "\n",
      "возможные\n",
      "санкций\n",
      "\n",
      "существенного\n",
      "санкций\n",
      "\n",
      "финансовые\n",
      "санкций\n",
      "\n",
      "существенный\n",
      "санкций\n",
      "\n",
      "собственных\n",
      "санкций\n",
      "\n",
      "подобных\n",
      "санкций\n",
      "\n",
      "ощутимых\n",
      "санкций\n",
      "\n",
      "финансовых\n",
      "санкций\n",
      "\n",
      "значительное\n",
      "санкциями,\n",
      "\n",
      "финансовые\n",
      "санкциями,\n",
      "\n",
      "финансовый\n",
      "санкциями,\n",
      "\n",
      "круглов.\n",
      "санкциями,\n",
      "\n",
      "возможные\n",
      "санкциями,\n",
      "\n",
      "существенного\n",
      "санкциями,\n",
      "\n",
      "финансовые\n",
      "санкциями,\n",
      "\n",
      "существенный\n",
      "санкциями,\n",
      "\n",
      "собственных\n",
      "санкциями,\n",
      "\n",
      "подобных\n",
      "санкциями,\n",
      "\n",
      "ощутимых\n",
      "санкциями,\n",
      "\n",
      "финансовых\n",
      "санкциями,\n",
      "\n",
      "штрафные\n",
      "санкции\n",
      "\n",
      "несогласованные\n",
      "санкции\n",
      "\n",
      "тендерных\n",
      "санкции\n",
      "\n",
      "любых\n",
      "санкции\n",
      "\n",
      "массовой\n",
      "санкции\n",
      "\n",
      "корпоративных\n",
      "санкции\n",
      "\n",
      "любом\n",
      "санкции\n",
      "\n",
      "другом\n",
      "санкции\n",
      "\n",
      "общедоступном\n",
      "санкции\n",
      "\n",
      "обязан\n",
      "санкции\n",
      "\n",
      "репутационных\n",
      "санкции\n",
      "\n",
      "имиджевых\n",
      "санкции\n",
      "\n",
      "существенного\n",
      "санкций\n",
      "\n",
      "финансовые\n",
      "санкций\n",
      "\n",
      "настоящее\n",
      "санкций\n",
      "\n",
      "существенное\n",
      "санкций\n",
      "\n",
      "финансовую\n",
      "санкций\n",
      "\n",
      "существенного\n",
      "санкций,\n",
      "\n",
      "финансовые\n",
      "санкций,\n",
      "\n",
      "настоящее\n",
      "санкций,\n",
      "\n",
      "существенное\n",
      "санкций,\n",
      "\n",
      "финансовую\n",
      "санкций,\n",
      "\n",
      "существенного\n",
      "санкций\n",
      "\n",
      "финансовые\n",
      "санкций\n",
      "\n",
      "настоящее\n",
      "санкций\n",
      "\n",
      "существенное\n",
      "санкций\n",
      "\n",
      "финансовую\n",
      "санкций\n",
      "\n",
      "существенного\n",
      "санкций,\n",
      "\n",
      "финансовые\n",
      "санкций,\n",
      "\n",
      "настоящее\n",
      "санкций,\n",
      "\n",
      "существенное\n",
      "санкций,\n",
      "\n",
      "финансовую\n",
      "санкций,\n",
      "\n",
      "национального\n",
      "санкций\n",
      "\n",
      "должно\n",
      "санкций\n",
      "\n",
      "западных\n",
      "санкций\n",
      "\n",
      "готово\n",
      "санкций\n",
      "\n",
      "других\n",
      "санкций\n",
      "\n",
      "национального\n",
      "санкций\n",
      "\n",
      "должно\n",
      "санкций\n",
      "\n",
      "западных\n",
      "санкций\n",
      "\n",
      "готово\n",
      "санкций\n",
      "\n",
      "других\n",
      "санкций\n",
      "\n",
      "продовольственное\n",
      "санкциями\n",
      "\n",
      "западных\n",
      "санкциями\n",
      "\n",
      "крупнейших\n",
      "санкциями\n",
      "\n",
      "российских\n",
      "санкциями\n",
      "\n",
      "которые\n",
      "санкциями\n",
      "\n",
      "финансовыми\n",
      "санкциями\n",
      "\n",
      "аграрного\n",
      "санкциями\n",
      "\n",
      "\"первого\n",
      "санкциями\n",
      "\n",
      "сельского\n",
      "санкциями\n",
      "\n",
      "первую\n",
      "санкциями\n",
      "\n",
      "третья\n",
      "санкциями\n",
      "\n",
      "финансово-экономическую\n",
      "санкциями\n",
      "\n",
      "основным\n",
      "санкциями\n",
      "\n",
      "аграрного\n",
      "санкциями\n",
      "\n",
      "сельского\n",
      "санкциями\n",
      "\n",
      "которые\n",
      "санкциями\n",
      "\n",
      "межбанковском\n",
      "санкциями\n",
      "\n",
      "рынке.\n",
      "санкциями\n",
      "\n",
      "западных\n",
      "санкциями\n",
      "\n",
      "сложное\n",
      "санкциями\n",
      "\n",
      "инвестиционных\n",
      "санкциями\n",
      "\n",
      "российский\n",
      "санкциями\n",
      "\n",
      "неравном\n",
      "санкциями\n",
      "\n",
      "другими\n",
      "санкциями\n",
      "\n",
      "финансовым\n",
      "санкциями\n",
      "\n",
      "продовольственное\n",
      "санкций\n",
      "\n",
      "западных\n",
      "санкций\n",
      "\n",
      "крупнейших\n",
      "санкций\n",
      "\n",
      "российских\n",
      "санкций\n",
      "\n",
      "которые\n",
      "санкций\n",
      "\n",
      "финансовыми\n",
      "санкций\n",
      "\n",
      "аграрного\n",
      "санкций\n",
      "\n",
      "\"первого\n",
      "санкций\n",
      "\n",
      "сельского\n",
      "санкций\n",
      "\n",
      "первую\n",
      "санкций\n",
      "\n",
      "третья\n",
      "санкций\n",
      "\n",
      "финансово-экономическую\n",
      "санкций\n",
      "\n",
      "основным\n",
      "санкций\n",
      "\n",
      "аграрного\n",
      "санкций\n",
      "\n",
      "сельского\n",
      "санкций\n",
      "\n",
      "которые\n",
      "санкций\n",
      "\n",
      "межбанковском\n",
      "санкций\n",
      "\n",
      "рынке.\n",
      "санкций\n",
      "\n",
      "западных\n",
      "санкций\n",
      "\n",
      "сложное\n",
      "санкций\n",
      "\n",
      "инвестиционных\n",
      "санкций\n",
      "\n",
      "российский\n",
      "санкций\n",
      "\n",
      "неравном\n",
      "санкций\n",
      "\n",
      "другими\n",
      "санкций\n",
      "\n",
      "финансовым\n",
      "санкций\n",
      "\n",
      "продовольственное\n",
      "санкций:\n",
      "\n",
      "западных\n",
      "санкций:\n",
      "\n",
      "крупнейших\n",
      "санкций:\n",
      "\n",
      "российских\n",
      "санкций:\n",
      "\n",
      "которые\n",
      "санкций:\n",
      "\n",
      "финансовыми\n",
      "санкций:\n",
      "\n",
      "аграрного\n",
      "санкций:\n",
      "\n",
      "\"первого\n",
      "санкций:\n",
      "\n",
      "сельского\n",
      "санкций:\n",
      "\n",
      "первую\n",
      "санкций:\n",
      "\n",
      "третья\n",
      "санкций:\n",
      "\n",
      "финансово-экономическую\n",
      "санкций:\n",
      "\n",
      "основным\n",
      "санкций:\n",
      "\n",
      "аграрного\n",
      "санкций:\n",
      "\n",
      "сельского\n",
      "санкций:\n",
      "\n",
      "которые\n",
      "санкций:\n",
      "\n",
      "межбанковском\n",
      "санкций:\n",
      "\n",
      "рынке.\n",
      "санкций:\n",
      "\n",
      "западных\n",
      "санкций:\n",
      "\n",
      "сложное\n",
      "санкций:\n",
      "\n",
      "инвестиционных\n",
      "санкций:\n",
      "\n",
      "российский\n",
      "санкций:\n",
      "\n",
      "неравном\n",
      "санкций:\n",
      "\n",
      "другими\n",
      "санкций:\n",
      "\n",
      "финансовым\n",
      "санкций:\n",
      "\n",
      "продовольственное\n",
      "санкции\",\n",
      "\n",
      "западных\n",
      "санкции\",\n",
      "\n",
      "крупнейших\n",
      "санкции\",\n",
      "\n",
      "российских\n",
      "санкции\",\n",
      "\n",
      "которые\n",
      "санкции\",\n",
      "\n",
      "финансовыми\n",
      "санкции\",\n",
      "\n",
      "аграрного\n",
      "санкции\",\n",
      "\n",
      "\"первого\n",
      "санкции\",\n",
      "\n",
      "сельского\n",
      "санкции\",\n",
      "\n",
      "первую\n",
      "санкции\",\n",
      "\n",
      "третья\n",
      "санкции\",\n",
      "\n",
      "финансово-экономическую\n",
      "санкции\",\n",
      "\n",
      "основным\n",
      "санкции\",\n",
      "\n",
      "аграрного\n",
      "санкции\",\n",
      "\n",
      "сельского\n",
      "санкции\",\n",
      "\n",
      "которые\n",
      "санкции\",\n",
      "\n",
      "межбанковском\n",
      "санкции\",\n",
      "\n",
      "рынке.\n",
      "санкции\",\n",
      "\n",
      "западных\n",
      "санкции\",\n",
      "\n",
      "сложное\n",
      "санкции\",\n",
      "\n",
      "инвестиционных\n",
      "санкции\",\n",
      "\n",
      "российский\n",
      "санкции\",\n",
      "\n",
      "неравном\n",
      "санкции\",\n",
      "\n",
      "другими\n",
      "санкции\",\n",
      "\n",
      "финансовым\n",
      "санкции\",\n",
      "\n",
      "китайского\n",
      "санкций\n",
      "\n",
      "который\n",
      "санкций\n",
      "\n",
      "должен\n",
      "санкций\n",
      "\n",
      "сам\n",
      "санкций\n",
      "\n",
      "\"газпром\"\n",
      "санкций\n",
      "\n",
      "сих\n",
      "санкций\n",
      "\n",
      "российский\n",
      "санкций\n",
      "\n",
      "кредитную\n",
      "санкций\n",
      "\n",
      "ключевой\n",
      "санкций\n",
      "\n",
      "западные\n",
      "санкций\n",
      "\n",
      "сам\n",
      "санкций\n",
      "\n",
      "российские\n",
      "санкций.\n",
      "\n",
      "одному\n",
      "санкций.\n",
      "\n",
      "сланцевой\n",
      "санкций.\n",
      "\n",
      "другое\n",
      "санкций.\n",
      "\n",
      "общей\n",
      "санкций.\n",
      "\n",
      "западных\n",
      "санкций.\n",
      "\n",
      "готова\n",
      "санкций.\n",
      "\n",
      "российские\n",
      "санкции\n",
      "\n",
      "одному\n",
      "санкции\n",
      "\n",
      "сланцевой\n",
      "санкции\n",
      "\n",
      "другое\n",
      "санкции\n",
      "\n",
      "общей\n",
      "санкции\n",
      "\n",
      "западных\n",
      "санкции\n",
      "\n",
      "готова\n",
      "санкции\n",
      "\n",
      "российские\n",
      "санкций.\n",
      "\n",
      "одному\n",
      "санкций.\n",
      "\n",
      "сланцевой\n",
      "санкций.\n",
      "\n",
      "другое\n",
      "санкций.\n",
      "\n",
      "общей\n",
      "санкций.\n",
      "\n",
      "западных\n",
      "санкций.\n",
      "\n",
      "готова\n",
      "санкций.\n",
      "\n",
      "российские\n",
      "санкции\n",
      "\n",
      "одному\n",
      "санкции\n",
      "\n",
      "сланцевой\n",
      "санкции\n",
      "\n",
      "другое\n",
      "санкции\n",
      "\n",
      "общей\n",
      "санкции\n",
      "\n",
      "западных\n",
      "санкции\n",
      "\n",
      "готова\n",
      "санкции\n",
      "\n",
      "европейскими\n",
      "несанкционированном\n",
      "\n",
      "западной\n",
      "несанкционированном\n",
      "\n",
      "западную\n",
      "несанкционированном\n",
      "\n",
      "надежный\n",
      "несанкционированном\n",
      "\n",
      "конечном\n",
      "несанкционированном\n",
      "\n",
      "энергетическую\n",
      "несанкционированном\n",
      "\n",
      "необоснованные\n",
      "несанкционированном\n",
      "\n",
      "несанкционированном\n",
      "несанкционированном\n",
      "\n",
      "первое\n",
      "санкции\n",
      "\n",
      "чистая\n",
      "санкции\n",
      "\n",
      "текущем\n",
      "санкции\n",
      "\n",
      "секторальных\n",
      "санкций\n",
      "\n",
      "секторальных\n",
      "санкций\n",
      "\n",
      "\"газпрома\"\n",
      "санкции\n",
      "\n",
      "радикального\n",
      "санкции\n",
      "\n",
      "российского\n",
      "санкции\n",
      "\n",
      "европейские\n",
      "санкции\n",
      "\n",
      "\"газпром\"\n",
      "санкции\n",
      "\n",
      "виртуальный\n",
      "санкции\n",
      "\n",
      "украинской\n",
      "санкции\n",
      "\n",
      "скептически.\n",
      "санкции\n",
      "\n",
      "трехлетний\n",
      "санкции\n",
      "\n",
      "синдицированный\n",
      "санкции\n",
      "\n",
      "кредитной\n",
      "санкции\n",
      "\n",
      "новой\n",
      "санкций\n",
      "\n",
      "центральный\n",
      "санкций\n",
      "\n",
      "каспийском\n",
      "санкций\n",
      "\n",
      "которого\n",
      "санкций\n",
      "\n",
      "бюрократических\n",
      "санкций\n",
      "\n",
      "которые\n",
      "санкций\n",
      "\n",
      "российским\n",
      "санкций\n",
      "\n",
      "новая\n",
      "санкций\n",
      "\n",
      "западных\n",
      "санкций\n",
      "\n",
      "технологические\n",
      "санкций\n",
      "\n",
      "новой\n",
      "санкций\n",
      "\n",
      "центральный\n",
      "санкций\n",
      "\n",
      "каспийском\n",
      "санкций\n",
      "\n",
      "которого\n",
      "санкций\n",
      "\n",
      "бюрократических\n",
      "санкций\n",
      "\n",
      "которые\n",
      "санкций\n",
      "\n",
      "российским\n",
      "санкций\n",
      "\n",
      "новая\n",
      "санкций\n",
      "\n",
      "западных\n",
      "санкций\n",
      "\n",
      "технологические\n",
      "санкций\n",
      "\n",
      "демонстрировать,\n",
      "санкции.\n",
      "\n",
      "западные\n",
      "санкции.\n",
      "\n",
      "которые\n",
      "санкции.\n",
      "\n",
      "антикризисной\n",
      "санкции.\n",
      "\n",
      "внешних\n",
      "санкции.\n",
      "\n",
      "40 млрд\n",
      "санкции.\n",
      "\n",
      "одновременным\n",
      "санкции.\n",
      "\n",
      "долговой\n",
      "санкции.\n",
      "\n",
      "своевременно,\n",
      "санкции.\n",
      "\n",
      "открытыми\n",
      "санкций,\n",
      "\n",
      "долгосрочными\n",
      "санкций,\n",
      "\n",
      "кредитными\n",
      "санкций,\n",
      "\n",
      "американских\n",
      "санкций,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "американский\n",
      "санкций,\n",
      "\n",
      "американское\n",
      "санкций,\n",
      "\n",
      "долгосрочной\n",
      "санкций,\n",
      "\n",
      "кредитной\n",
      "санкций,\n",
      "\n",
      "кредитных\n",
      "санкций,\n",
      "\n",
      "процентную\n",
      "санкций,\n",
      "\n",
      "максимальный\n",
      "санкций,\n",
      "\n",
      "открытыми\n",
      "санкций\n",
      "\n",
      "долгосрочными\n",
      "санкций\n",
      "\n",
      "кредитными\n",
      "санкций\n",
      "\n",
      "американских\n",
      "санкций\n",
      "\n",
      "американский\n",
      "санкций\n",
      "\n",
      "американское\n",
      "санкций\n",
      "\n",
      "долгосрочной\n",
      "санкций\n",
      "\n",
      "кредитной\n",
      "санкций\n",
      "\n",
      "кредитных\n",
      "санкций\n",
      "\n",
      "процентную\n",
      "санкций\n",
      "\n",
      "максимальный\n",
      "санкций\n",
      "\n",
      "крупные\n",
      "санкций\n",
      "\n",
      "российские\n",
      "санкций\n",
      "\n",
      "очередной\n",
      "санкций\n",
      "\n",
      "новатэк,\n",
      "санкций\n",
      "\n",
      "публичном\n",
      "санкций\n",
      "\n",
      "независимые\n",
      "санкций\n",
      "\n",
      "серьезных\n",
      "санкций\n",
      "\n",
      "велики\n",
      "санкций\n",
      "\n",
      "первую\n",
      "санкций\n",
      "\n",
      "западными\n",
      "санкций\n",
      "\n",
      "которых\n",
      "санкций\n",
      "\n",
      "ключевые\n",
      "санкций\n",
      "\n",
      "прямого\n",
      "санкций\n",
      "\n",
      "совместных\n",
      "санкций\n",
      "\n",
      "крупные\n",
      "санкции\n",
      "\n",
      "российские\n",
      "санкции\n",
      "\n",
      "очередной\n",
      "санкции\n",
      "\n",
      "новатэк,\n",
      "санкции\n",
      "\n",
      "публичном\n",
      "санкции\n",
      "\n",
      "независимые\n",
      "санкции\n",
      "\n",
      "серьезных\n",
      "санкции\n",
      "\n",
      "велики\n",
      "санкции\n",
      "\n",
      "первую\n",
      "санкции\n",
      "\n",
      "западными\n",
      "санкции\n",
      "\n",
      "которых\n",
      "санкции\n",
      "\n",
      "ключевые\n",
      "санкции\n",
      "\n",
      "прямого\n",
      "санкции\n",
      "\n",
      "совместных\n",
      "санкции\n",
      "\n",
      "крупный\n",
      "санкции\n",
      "\n",
      "нефтегазовой\n",
      "санкции\n",
      "\n",
      "«стройтрансгаз-м»\n",
      "санкции\n",
      "\n",
      "который\n",
      "санкции\n",
      "\n",
      "черного\n",
      "санкции\n",
      "\n",
      "оао\n",
      "санкции\n",
      "\n",
      "эффективная\n",
      "санкции\n",
      "\n",
      "крупный\n",
      "санкций.\n",
      "\n",
      "нефтегазовой\n",
      "санкций.\n",
      "\n",
      "«стройтрансгаз-м»\n",
      "санкций.\n",
      "\n",
      "который\n",
      "санкций.\n",
      "\n",
      "черного\n",
      "санкций.\n",
      "\n",
      "оао\n",
      "санкций.\n",
      "\n",
      "эффективная\n",
      "санкций.\n",
      "\n",
      "петербургского\n",
      "санкций,\n",
      "\n",
      "международного\n",
      "санкций,\n",
      "\n",
      "экономического\n",
      "санкций,\n",
      "\n",
      "настоящее\n",
      "санкций,\n",
      "\n",
      "процентная\n",
      "санкций,\n",
      "\n",
      "год.\n",
      "санкций,\n",
      "\n",
      "трагично,\n",
      "санкций,\n",
      "\n",
      "петербургского\n",
      "санкций,\n",
      "\n",
      "международного\n",
      "санкций,\n",
      "\n",
      "экономического\n",
      "санкций,\n",
      "\n",
      "настоящее\n",
      "санкций,\n",
      "\n",
      "процентная\n",
      "санкций,\n",
      "\n",
      "год.\n",
      "санкций,\n",
      "\n",
      "трагично,\n",
      "санкций,\n",
      "\n",
      "крупнейших\n",
      "санкции,\n",
      "\n",
      "российских\n",
      "санкции,\n",
      "\n",
      "визовые\n",
      "санкции,\n",
      "\n",
      "финансовые\n",
      "санкции,\n",
      "\n",
      "которые\n",
      "санкции,\n",
      "\n",
      "черный\n",
      "санкции,\n",
      "\n",
      "которым\n",
      "санкции,\n",
      "\n",
      "ес,\n",
      "санкции,\n",
      "\n",
      "российских\n",
      "санкции,\n",
      "\n",
      "трейдингового\n",
      "санкции,\n",
      "\n",
      "крупнейших\n",
      "санкции\n",
      "\n",
      "российских\n",
      "санкции\n",
      "\n",
      "визовые\n",
      "санкции\n",
      "\n",
      "финансовые\n",
      "санкции\n",
      "\n",
      "которые\n",
      "санкции\n",
      "\n",
      "черный\n",
      "санкции\n",
      "\n",
      "которым\n",
      "санкции\n",
      "\n",
      "ес,\n",
      "санкции\n",
      "\n",
      "российских\n",
      "санкции\n",
      "\n",
      "трейдингового\n",
      "санкции\n",
      "\n",
      "троицкой\n",
      "санкции\n",
      "\n",
      "осенне-зимнему\n",
      "санкции\n",
      "\n",
      "сих\n",
      "санкции\n",
      "\n",
      "вопросов,\n",
      "санкции.\n",
      "\n",
      "большие\n",
      "санкции.\n",
      "\n",
      "\"хорошие\n",
      "санкции.\n",
      "\n",
      "российского\n",
      "санкции.\n",
      "\n",
      "таким\n",
      "санкции.\n",
      "\n",
      "альмуния.\n",
      "санкции.\n",
      "\n",
      "том,\n",
      "несанкционированно\n",
      "\n",
      "транзитного\n",
      "несанкционированно\n",
      "\n",
      "соответствующее\n",
      "несанкционированно\n",
      "\n",
      "судебных\n",
      "несанкционированно\n",
      "\n",
      "украиной\n",
      "несанкционированно\n",
      "\n",
      "сам\n",
      "несанкционированно\n",
      "\n",
      "дальнейших\n",
      "несанкционированно\n",
      "\n",
      "которая\n",
      "санкции,—\n",
      "\n",
      "готовую\n",
      "санкции,—\n",
      "\n",
      "государственная\n",
      "санкции,—\n",
      "\n",
      "международные\n",
      "санкции,—\n",
      "\n",
      "кубе.\n",
      "санкции,—\n",
      "\n",
      "которая\n",
      "санкции,—\n",
      "\n",
      "готовую\n",
      "санкции,—\n",
      "\n",
      "государственная\n",
      "санкции,—\n",
      "\n",
      "международные\n",
      "санкции,—\n",
      "\n",
      "кубе.\n",
      "санкции,—\n",
      "\n",
      "российский\n",
      "санкций\n",
      "\n",
      "таможенный\n",
      "санкций\n",
      "\n",
      "штрафных\n",
      "санкций\n",
      "\n",
      "соответствующих\n",
      "санкций\n",
      "\n",
      "штрафных\n",
      "санкций\n",
      "\n",
      "контрактных\n",
      "санкций\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_sentences = []\n",
    "sentence = []\n",
    "for line in codecs.open('data_sanc.conll', 'r', 'utf-8'):\n",
    "    if len(line) == 1:\n",
    "        processed_sentences.append(sentence)\n",
    "        sentence = []\n",
    "    else:\n",
    "        word = line.split(\"\\t\")\n",
    "        sentence.append(word)\n",
    "deps = []\n",
    "res = []\n",
    "for sentence in processed_sentences:\n",
    "    s = u\"\"\n",
    "    for line in sentence:\n",
    "        s += u\"\\t\".join(line) + u'\\n'\n",
    "    deps.append(s)\n",
    "\n",
    "for sent_dep in deps:    \n",
    "    s_deps = sent_dep.split('\\n')\n",
    "    for t in s_deps:\n",
    "        if len(t) > 1:\n",
    "            splt = t.split('\\t')\n",
    "            if 'санкц' in splt[1]:\n",
    "                n = int(splt[0]) \n",
    "                for t2 in s_deps:\n",
    "                    splitted_sentence = t2.split('\\t')\n",
    "                    if len(splitted_sentence) > 1 :\n",
    "                        word_type = splitted_sentence[3]\n",
    "                        if word_type == 'ADJ' :\n",
    "                            word = splitted_sentence[1]\n",
    "                            print(word + \"\\n\" + splt[1])\n",
    "                            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Классификационная\n",
    "Вам предстоит решить следующую задачу: по текстам новостей за день определить, вырастет или понизится цена закрытия.\n",
    "Для этого:\n",
    "* бинаризуйте признак \"цена закрытия\":  новый признак ClosingPrice_bin равен 1, если по сравнению со вчера цена не упала, и 0 – в обратном случаея;\n",
    "* составьте бучающее и тестовое множество: данные до начала 2016 года используются для обучения, данные с 2016 года и позже – для тестирования.\n",
    "\n",
    "Таким образом, в каждлый момент времени мы знаем: \n",
    "* ClosingPrice_bin – бинарый целевой признак\n",
    "* слова из статей, опубликованных в этот день – объясняющие признаки\n",
    "\n",
    "В этой части задания вам нужно сделать baseline алгоритм и попытаться его улучшить в следующей части. \n",
    "\n",
    "Используйте любой известный вам алгоритм классификации текстов для того, Используйте $tf-idf$ преобразование, сингулярное разложение, нормировку признакого пространства и любые другие техники обработки данных, которые вы считаете нужным. Используйте accuracy и F-measure для оценки качества классификации. Покажите, как  $tf-idf$ преобразование или сингулярное разложение или любая другая использованная вами техника влияет на качество классификации.\n",
    "Если у выбранного вами алгоритма есть гиперпараметры (например, $\\alpha$ в преобразовании Лапласа для метода наивного Байеса), покажите, как изменение гиперпараметра влияет на качество классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### бинаризуйте признак \"цена закрытия\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin = pr_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1988 entries, 0 to 1987\n",
      "Data columns (total 6 columns):\n",
      "Date            1988 non-null object\n",
      "Open            1964 non-null float64\n",
      "ClosingPrice    1988 non-null float64\n",
      "DailyHigh       1986 non-null float64\n",
      "DailyLow        1986 non-null float64\n",
      "VolumePcs       1988 non-null int64\n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 93.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_bin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1988\n"
     ]
    }
   ],
   "source": [
    "bin = []\n",
    "for i in range(len(df_bin) - 1):  \n",
    "    row = df_bin.iloc[i]\n",
    "    row_prev = df_bin.iloc[i+1]\n",
    "    if row['ClosingPrice'] < row_prev['ClosingPrice']:  \n",
    "        bin.append(0)\n",
    "    else:\n",
    "        bin.append(1)\n",
    "\n",
    "bin.append(0)\n",
    "df_bin[\"ClosingPrice_bin\"] = bin        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>ClosingPrice_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08.12.2017</td>\n",
       "      <td>133.43</td>\n",
       "      <td>132.60</td>\n",
       "      <td>133.90</td>\n",
       "      <td>132.00</td>\n",
       "      <td>16037970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07.12.2017</td>\n",
       "      <td>133.70</td>\n",
       "      <td>133.02</td>\n",
       "      <td>133.87</td>\n",
       "      <td>132.81</td>\n",
       "      <td>18198430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06.12.2017</td>\n",
       "      <td>133.33</td>\n",
       "      <td>134.00</td>\n",
       "      <td>134.29</td>\n",
       "      <td>132.91</td>\n",
       "      <td>14641730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05.12.2017</td>\n",
       "      <td>133.48</td>\n",
       "      <td>133.65</td>\n",
       "      <td>133.99</td>\n",
       "      <td>132.78</td>\n",
       "      <td>12684800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04.12.2017</td>\n",
       "      <td>133.01</td>\n",
       "      <td>133.77</td>\n",
       "      <td>134.00</td>\n",
       "      <td>131.93</td>\n",
       "      <td>17818980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open  ClosingPrice  DailyHigh  DailyLow  VolumePcs  \\\n",
       "0  08.12.2017  133.43        132.60     133.90    132.00   16037970   \n",
       "1  07.12.2017  133.70        133.02     133.87    132.81   18198430   \n",
       "2  06.12.2017  133.33        134.00     134.29    132.91   14641730   \n",
       "3  05.12.2017  133.48        133.65     133.99    132.78   12684800   \n",
       "4  04.12.2017  133.01        133.77     134.00    131.93   17818980   \n",
       "\n",
       "   ClosingPrice_bin  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 1  \n",
       "3                 0  \n",
       "4                 1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим только те дни где есть новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>ClosingPrice_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09.11.2017</td>\n",
       "      <td>компания рассчитывать решение газовый спор укр...</td>\n",
       "      <td>132.31</td>\n",
       "      <td>131.50</td>\n",
       "      <td>132.82</td>\n",
       "      <td>131.14</td>\n",
       "      <td>33869650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08.11.2017</td>\n",
       "      <td>предполагать Ъ газпром воспользоваться жалоба ...</td>\n",
       "      <td>132.00</td>\n",
       "      <td>132.30</td>\n",
       "      <td>133.94</td>\n",
       "      <td>131.58</td>\n",
       "      <td>39381960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.11.2017</td>\n",
       "      <td>новый редакция американский санкция ставить по...</td>\n",
       "      <td>126.40</td>\n",
       "      <td>126.50</td>\n",
       "      <td>126.89</td>\n",
       "      <td>125.97</td>\n",
       "      <td>18232550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.10.2017</td>\n",
       "      <td>становиться известно Ъ известный рынок риск-ме...</td>\n",
       "      <td>125.96</td>\n",
       "      <td>125.98</td>\n",
       "      <td>126.93</td>\n",
       "      <td>125.53</td>\n",
       "      <td>19263340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.10.2017</td>\n",
       "      <td>новатэк через пять собираться запускать камчат...</td>\n",
       "      <td>127.05</td>\n",
       "      <td>126.80</td>\n",
       "      <td>127.47</td>\n",
       "      <td>126.37</td>\n",
       "      <td>17308800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text    Open  \\\n",
       "0  09.11.2017  компания рассчитывать решение газовый спор укр...  132.31   \n",
       "1  08.11.2017  предполагать Ъ газпром воспользоваться жалоба ...  132.00   \n",
       "2  01.11.2017  новый редакция американский санкция ставить по...  126.40   \n",
       "3  30.10.2017  становиться известно Ъ известный рынок риск-ме...  125.96   \n",
       "4  23.10.2017  новатэк через пять собираться запускать камчат...  127.05   \n",
       "\n",
       "   ClosingPrice  DailyHigh  DailyLow  VolumePcs  ClosingPrice_bin  \n",
       "0        131.50     132.82    131.14   33869650                 0  \n",
       "1        132.30     133.94    131.58   39381960                 1  \n",
       "2        126.50     126.89    125.97   18232550                 1  \n",
       "3        125.98     126.93    125.53   19263340                 1  \n",
       "4        126.80     127.47    126.37   17308800                 1  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.merge(df_cleared, df_bin, left_on='date', right_on='Date').drop('Date', axis=1)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### составьте бучающее и тестовое множество: данные до начала 2016 года используются для обучения, данные с 2016 года и позже – для тестирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем и в лоб найдем руками с какой строки начинается 2016 год, увидим что это 257 строка (11.01.2016) и разделим на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 901 entries, 258 to 1158\n",
      "Data columns (total 8 columns):\n",
      "date                901 non-null object\n",
      "text                901 non-null object\n",
      "Open                892 non-null float64\n",
      "ClosingPrice        901 non-null float64\n",
      "DailyHigh           901 non-null float64\n",
      "DailyLow            901 non-null float64\n",
      "VolumePcs           901 non-null int64\n",
      "ClosingPrice_bin    901 non-null int64\n",
      "dtypes: float64(4), int64(2), object(2)\n",
      "memory usage: 63.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train = df_merged[258:].copy()\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>ClosingPrice_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>29.12.2015</td>\n",
       "      <td>газпром отменять проведение рекордный история ...</td>\n",
       "      <td>135.26</td>\n",
       "      <td>137.49</td>\n",
       "      <td>137.55</td>\n",
       "      <td>134.74</td>\n",
       "      <td>21516980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>25.12.2015</td>\n",
       "      <td>газпром прогнозировать увеличение чистый прибы...</td>\n",
       "      <td>136.49</td>\n",
       "      <td>134.48</td>\n",
       "      <td>136.49</td>\n",
       "      <td>134.03</td>\n",
       "      <td>14866310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>24.12.2015</td>\n",
       "      <td>правительство приостанавливать обсуждение вопр...</td>\n",
       "      <td>135.85</td>\n",
       "      <td>136.00</td>\n",
       "      <td>138.08</td>\n",
       "      <td>134.45</td>\n",
       "      <td>36828650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>23.12.2015</td>\n",
       "      <td>фас продолжать атака газпром соглашаться повыш...</td>\n",
       "      <td>133.55</td>\n",
       "      <td>135.30</td>\n",
       "      <td>135.30</td>\n",
       "      <td>133.35</td>\n",
       "      <td>26760910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>22.12.2015</td>\n",
       "      <td>состоятельный банковский -клиент россия начина...</td>\n",
       "      <td>132.00</td>\n",
       "      <td>133.20</td>\n",
       "      <td>133.54</td>\n",
       "      <td>131.81</td>\n",
       "      <td>20022420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                               text    Open  \\\n",
       "258  29.12.2015  газпром отменять проведение рекордный история ...  135.26   \n",
       "259  25.12.2015  газпром прогнозировать увеличение чистый прибы...  136.49   \n",
       "260  24.12.2015  правительство приостанавливать обсуждение вопр...  135.85   \n",
       "261  23.12.2015  фас продолжать атака газпром соглашаться повыш...  133.55   \n",
       "262  22.12.2015  состоятельный банковский -клиент россия начина...  132.00   \n",
       "\n",
       "     ClosingPrice  DailyHigh  DailyLow  VolumePcs  ClosingPrice_bin  \n",
       "258        137.49     137.55    134.74   21516980                 1  \n",
       "259        134.48     136.49    134.03   14866310                 0  \n",
       "260        136.00     138.08    134.45   36828650                 1  \n",
       "261        135.30     135.30    133.35   26760910                 1  \n",
       "262        133.20     133.54    131.81   20022420                 1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 258 entries, 0 to 257\n",
      "Data columns (total 8 columns):\n",
      "date                258 non-null object\n",
      "text                258 non-null object\n",
      "Open                253 non-null float64\n",
      "ClosingPrice        258 non-null float64\n",
      "DailyHigh           257 non-null float64\n",
      "DailyLow            256 non-null float64\n",
      "VolumePcs           258 non-null int64\n",
      "ClosingPrice_bin    258 non-null int64\n",
      "dtypes: float64(4), int64(2), object(2)\n",
      "memory usage: 18.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test = df_merged[:258].copy()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>ClosingPrice_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09.11.2017</td>\n",
       "      <td>компания рассчитывать решение газовый спор укр...</td>\n",
       "      <td>132.31</td>\n",
       "      <td>131.50</td>\n",
       "      <td>132.82</td>\n",
       "      <td>131.14</td>\n",
       "      <td>33869650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08.11.2017</td>\n",
       "      <td>предполагать Ъ газпром воспользоваться жалоба ...</td>\n",
       "      <td>132.00</td>\n",
       "      <td>132.30</td>\n",
       "      <td>133.94</td>\n",
       "      <td>131.58</td>\n",
       "      <td>39381960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.11.2017</td>\n",
       "      <td>новый редакция американский санкция ставить по...</td>\n",
       "      <td>126.40</td>\n",
       "      <td>126.50</td>\n",
       "      <td>126.89</td>\n",
       "      <td>125.97</td>\n",
       "      <td>18232550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.10.2017</td>\n",
       "      <td>становиться известно Ъ известный рынок риск-ме...</td>\n",
       "      <td>125.96</td>\n",
       "      <td>125.98</td>\n",
       "      <td>126.93</td>\n",
       "      <td>125.53</td>\n",
       "      <td>19263340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.10.2017</td>\n",
       "      <td>новатэк через пять собираться запускать камчат...</td>\n",
       "      <td>127.05</td>\n",
       "      <td>126.80</td>\n",
       "      <td>127.47</td>\n",
       "      <td>126.37</td>\n",
       "      <td>17308800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text    Open  \\\n",
       "0  09.11.2017  компания рассчитывать решение газовый спор укр...  132.31   \n",
       "1  08.11.2017  предполагать Ъ газпром воспользоваться жалоба ...  132.00   \n",
       "2  01.11.2017  новый редакция американский санкция ставить по...  126.40   \n",
       "3  30.10.2017  становиться известно Ъ известный рынок риск-ме...  125.96   \n",
       "4  23.10.2017  новатэк через пять собираться запускать камчат...  127.05   \n",
       "\n",
       "   ClosingPrice  DailyHigh  DailyLow  VolumePcs  ClosingPrice_bin  \n",
       "0        131.50     132.82    131.14   33869650                 0  \n",
       "1        132.30     133.94    131.58   39381960                 1  \n",
       "2        126.50     126.89    125.97   18232550                 1  \n",
       "3        125.98     126.93    125.53   19263340                 1  \n",
       "4        126.80     127.47    126.37   17308800                 1  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте любой известный вам алгоритм классификации текстов для того, Используйте  tf−idftf−idf  преобразование, сингулярное разложение, нормировку признакого пространства и любые другие техники обработки данных, которые вы считаете нужным. Используйте accuracy и F-measure для оценки качества классификации. Покажите, как  tf−idftf−idf  преобразование или сингулярное разложение или любая другая использованная вами техника влияет на качество классификации. Если у выбранного вами алгоритма есть гиперпараметры (например,  αα  в преобразовании Лапласа для метода наивного Байеса), покажите, как изменение гиперпараметра влияет на качество классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведем документы в векторы признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 6027)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(df_train.text)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "def metrics_test(predicted, target):\n",
    "    acc = accuracy_score(predicted, target)\n",
    "    micro_f1 = f1_score(predicted, target, average = 'micro')\n",
    "    micro_p = f1_score(predicted, target, average = 'micro')\n",
    "    micro_r = f1_score(predicted, target, average = 'micro')\n",
    "    macro_f1 = f1_score(predicted, target, average = 'macro')\n",
    "    macro_p = f1_score(predicted, target, average = 'macro')\n",
    "    macro_r = f1_score(predicted, target, average = 'macro')\n",
    "    print('acc={0:1.4f}'.format(acc))\n",
    "    print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "    print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Мультиномиальный наивный Байес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_counts, df_train.ClosingPrice_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказываем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = count_vect.transform(df_test.text)\n",
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.4341\n",
      "micro F1=0.4341, micro P=0.4341, micro R=0.4341\n",
      "macro F1=0.4340, macro P=0.4340, macro R=0.4340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_test(predicted, df_test.ClosingPrice_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression().fit(X_train_counts, df_train.ClosingPrice_bin)\n",
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.4767\n",
      "micro F1=0.4767, micro P=0.4767, micro R=0.4767\n",
      "macro F1=0.4765, macro P=0.4765, macro R=0.4765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_test(predicted, df_test.ClosingPrice_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сеть прямого распространения - FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_LENGTH = 1800\n",
    "VOCABULARY_SIZE = 250000\n",
    "EMBEDDING_DIM = 100\n",
    "DIMS = 250\n",
    "MAX_FEATURES = 5000\n",
    "batch_size = 32\n",
    "\n",
    "nb_filter = 250\n",
    "filter_length = 3\n",
    "hidden_dims = 250\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(df_train.text)\n",
    "sequences = tokenizer.texts_to_sequences(df_train.text)\n",
    "X_train = tokenizer.sequences_to_matrix(sequences, mode='count')\n",
    "sequences = tokenizer.texts_to_sequences(df_test.text)\n",
    "X_test = tokenizer.sequences_to_matrix(sequences, mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.ClosingPrice_bin.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 810 samples, validate on 91 samples\n",
      "Epoch 1/20\n",
      "810/810 [==============================] - 1s 1ms/step - loss: 0.7115 - acc: 0.4802 - val_loss: 0.7109 - val_acc: 0.5604\n",
      "Epoch 2/20\n",
      "810/810 [==============================] - 0s 243us/step - loss: 0.4645 - acc: 0.9160 - val_loss: 0.7404 - val_acc: 0.5934\n",
      "Epoch 3/20\n",
      "810/810 [==============================] - 0s 257us/step - loss: 0.3083 - acc: 0.9679 - val_loss: 0.7852 - val_acc: 0.5934\n",
      "Epoch 4/20\n",
      "810/810 [==============================] - 0s 257us/step - loss: 0.1891 - acc: 0.9914 - val_loss: 0.8201 - val_acc: 0.5714\n",
      "Epoch 5/20\n",
      "810/810 [==============================] - 0s 236us/step - loss: 0.1158 - acc: 0.9963 - val_loss: 0.8975 - val_acc: 0.5824\n",
      "Epoch 6/20\n",
      "810/810 [==============================] - 0s 228us/step - loss: 0.0727 - acc: 0.9975 - val_loss: 0.9725 - val_acc: 0.5824\n",
      "Epoch 7/20\n",
      "810/810 [==============================] - 0s 239us/step - loss: 0.0488 - acc: 0.9988 - val_loss: 1.0571 - val_acc: 0.5495\n",
      "Epoch 8/20\n",
      "810/810 [==============================] - 0s 249us/step - loss: 0.0351 - acc: 1.0000 - val_loss: 1.0919 - val_acc: 0.5604\n",
      "Epoch 9/20\n",
      "810/810 [==============================] - 0s 235us/step - loss: 0.0263 - acc: 0.9988 - val_loss: 1.1312 - val_acc: 0.5385\n",
      "Epoch 10/20\n",
      "810/810 [==============================] - 0s 239us/step - loss: 0.0199 - acc: 0.9988 - val_loss: 1.1994 - val_acc: 0.5385\n",
      "Epoch 11/20\n",
      "810/810 [==============================] - 0s 251us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 1.2450 - val_acc: 0.5275\n",
      "Epoch 12/20\n",
      "810/810 [==============================] - 0s 232us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.2537 - val_acc: 0.5385\n",
      "Epoch 13/20\n",
      "810/810 [==============================] - 0s 245us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 1.3187 - val_acc: 0.5275\n",
      "Epoch 14/20\n",
      "810/810 [==============================] - 0s 248us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 1.3331 - val_acc: 0.5385\n",
      "Epoch 15/20\n",
      "810/810 [==============================] - 0s 248us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 1.3759 - val_acc: 0.5275\n",
      "Epoch 16/20\n",
      "810/810 [==============================] - 0s 233us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 1.3969 - val_acc: 0.5385\n",
      "Epoch 17/20\n",
      "810/810 [==============================] - 0s 237us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 1.4345 - val_acc: 0.5165\n",
      "Epoch 18/20\n",
      "810/810 [==============================] - 0s 247us/step - loss: 0.0055 - acc: 0.9988 - val_loss: 1.4639 - val_acc: 0.5165\n",
      "Epoch 19/20\n",
      "810/810 [==============================] - 0s 245us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 1.4779 - val_acc: 0.5275\n",
      "Epoch 20/20\n",
      "810/810 [==============================] - 0s 245us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 1.5285 - val_acc: 0.5275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2db15d68>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(MAX_FEATURES,), activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=nb_epoch, batch_size=batch_size,  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258/258 [==============================] - 0s 288us/step\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predicted.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.4884\n",
      "micro F1=0.4884, micro P=0.4884, micro R=0.4884\n",
      "macro F1=0.4873, macro P=0.4873, macro R=0.4873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_test(predicted, df_test.ClosingPrice_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.49      0.51       140\n",
      "          1       0.45      0.48      0.46       118\n",
      "\n",
      "avg / total       0.49      0.49      0.49       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test.ClosingPrice_bin, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df_train.text)\n",
    "X_train = pad_sequences(sequences, maxlen=TEXT_LENGTH)\n",
    "sequences = tokenizer.texts_to_sequences(df_test.text)\n",
    "X_test = pad_sequences(sequences, maxlen=TEXT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.ClosingPrice_bin.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 1800)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "embedding_layer = Embedding(VOCABULARY_SIZE,\n",
    "                            EMBEDDING_DIM,\n",
    "                            input_length=TEXT_LENGTH,\n",
    "                            trainable=True)\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(TEXT_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(32, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(64, 5)(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(128, 5)(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "preds = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 810 samples, validate on 91 samples\n",
      "Epoch 1/20\n",
      "810/810 [==============================] - 11s 14ms/step - loss: 0.6938 - acc: 0.5049 - val_loss: 0.6934 - val_acc: 0.4835\n",
      "Epoch 2/20\n",
      "810/810 [==============================] - 9s 12ms/step - loss: 0.6942 - acc: 0.4901 - val_loss: 0.6934 - val_acc: 0.4835\n",
      "Epoch 3/20\n",
      "810/810 [==============================] - 10s 12ms/step - loss: 0.6930 - acc: 0.5160 - val_loss: 0.6931 - val_acc: 0.5275\n",
      "Epoch 4/20\n",
      "810/810 [==============================] - 10s 12ms/step - loss: 0.6941 - acc: 0.4840 - val_loss: 0.6933 - val_acc: 0.4835\n",
      "Epoch 5/20\n",
      "810/810 [==============================] - 10s 12ms/step - loss: 0.6931 - acc: 0.4951 - val_loss: 0.6935 - val_acc: 0.4835\n",
      "Epoch 6/20\n",
      "810/810 [==============================] - 10s 13ms/step - loss: 0.6931 - acc: 0.5049 - val_loss: 0.6940 - val_acc: 0.4835\n",
      "Epoch 7/20\n",
      "810/810 [==============================] - 11s 13ms/step - loss: 0.6931 - acc: 0.5074 - val_loss: 0.6937 - val_acc: 0.4835\n",
      "Epoch 8/20\n",
      "810/810 [==============================] - 10s 12ms/step - loss: 0.6930 - acc: 0.5062 - val_loss: 0.6941 - val_acc: 0.4835\n",
      "Epoch 9/20\n",
      "810/810 [==============================] - 11s 14ms/step - loss: 0.6926 - acc: 0.4975 - val_loss: 0.6945 - val_acc: 0.4835\n",
      "Epoch 10/20\n",
      "810/810 [==============================] - 10s 12ms/step - loss: 0.6927 - acc: 0.5037 - val_loss: 0.6945 - val_acc: 0.4835\n",
      "Epoch 11/20\n",
      "810/810 [==============================] - 10s 13ms/step - loss: 0.6929 - acc: 0.5173 - val_loss: 0.6946 - val_acc: 0.4835\n",
      "Epoch 12/20\n",
      "810/810 [==============================] - 11s 13ms/step - loss: 0.6927 - acc: 0.5074 - val_loss: 0.6944 - val_acc: 0.4835\n",
      "Epoch 13/20\n",
      "810/810 [==============================] - 11s 13ms/step - loss: 0.6925 - acc: 0.5086 - val_loss: 0.6943 - val_acc: 0.4615\n",
      "Epoch 14/20\n",
      "810/810 [==============================] - 10s 13ms/step - loss: 0.6921 - acc: 0.5160 - val_loss: 0.6941 - val_acc: 0.4286\n",
      "Epoch 15/20\n",
      "810/810 [==============================] - 11s 13ms/step - loss: 0.6928 - acc: 0.4840 - val_loss: 0.6944 - val_acc: 0.4066\n",
      "Epoch 16/20\n",
      "810/810 [==============================] - 10s 13ms/step - loss: 0.6919 - acc: 0.5333 - val_loss: 0.6950 - val_acc: 0.4835\n",
      "Epoch 17/20\n",
      "810/810 [==============================] - 10s 13ms/step - loss: 0.6920 - acc: 0.5123 - val_loss: 0.6949 - val_acc: 0.4286\n",
      "Epoch 18/20\n",
      "810/810 [==============================] - 10s 13ms/step - loss: 0.6920 - acc: 0.5000 - val_loss: 0.6952 - val_acc: 0.4615\n",
      "Epoch 19/20\n",
      "810/810 [==============================] - 10s 13ms/step - loss: 0.6909 - acc: 0.5272 - val_loss: 0.6956 - val_acc: 0.4615\n",
      "Epoch 20/20\n",
      "810/810 [==============================] - 10s 13ms/step - loss: 0.6905 - acc: 0.5346 - val_loss: 0.6964 - val_acc: 0.5165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3d3dba90>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=nb_epoch, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probs_to_classes(probas):\n",
    "    classes = np.zeros(probas.shape, dtype=np.int)\n",
    "    for i, row in enumerate(probas):\n",
    "        if row > 0.5 :\n",
    "            classes[i] = 1\n",
    "    return classes\n",
    "\n",
    "y_pred = probs_to_classes(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.5543\n",
      "micro F1=0.5543, micro P=0.5543, micro R=0.5543\n",
      "macro F1=0.4338, macro P=0.4338, macro R=0.4338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_test(y_pred, df_test.ClosingPrice_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.94      0.69       140\n",
      "          1       0.57      0.10      0.17       118\n",
      "\n",
      "avg / total       0.56      0.55      0.46       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test.ClosingPrice_bin, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Творческая\n",
    "Придумайте и попытайтесь сделать еще что-нибудь, чтобы улучшить качество классификации. \n",
    "Направления развития:\n",
    "* Морфологический признаки: \n",
    "    * использовать в качестве признаков только существительные или только именованные сущности;\n",
    "* Модели скрытых тем:\n",
    "    * использовать в качестве признаков скрытые темы;\n",
    "    * использовать в качестве признаков динамические скрытые темы \n",
    "    пример тут: (https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/dtm_example.ipynb)\n",
    "* Синтаксические признаки:\n",
    "    * использовать SOV-тройки в качестве признаков\n",
    "    * кластеризовать SOV-тройки по эмбеддингам глаголов (обученные word2vec модели можно скачать отсюда: (http://rusvectores.org/ru/models/) и использовать только центроиды кластеров в качестве признаков\n",
    "* что-нибудь еще     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовим словарь и корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import *\n",
    "texts = [df_merged.text.iloc[i].split() for i in range(len(df_merged))]\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import  *\n",
    "tfidf = TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Попробуем обучить систему на моделях скрытых тем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = lsimodel.LsiModel(corpus=corpus_tfidf, id2word=dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lsi = lsi[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arr_to_model(corpus):\n",
    "    arr = np.array([])\n",
    "    for doc in corpus: # both bow->tfidf and tfidf->lsi transformations are actually executed here, on the fly\n",
    "        max_clazz = 0\n",
    "        max_pred = 0\n",
    "        for clazz, pred in doc:\n",
    "            if pred > max_pred:\n",
    "                max_pred = pred\n",
    "                max_clazz = clazz\n",
    "        arr = np.append(arr, max_clazz)\n",
    "    return arr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_lsi = add_arr_to_model(corpus_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(arr_lsi[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=10,\n",
    "                        alpha='auto', eta='auto', iterations = 20, passes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lda = lda[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_lda = add_arr_to_model(corpus_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  7.  2.  5.  3.  5.  3.  8.  4.  8.]\n"
     ]
    }
   ],
   "source": [
    "print(arr_lda[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.vstack((arr_lsi , arr_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = arr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1159, 2)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_train = arr[258:]\n",
    "arr_test = arr[:258]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Натренируем Мультиномиальный наивный Байес, на темах полученных с помощью методов LSI & LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(arr_train, df_train.ClosingPrice_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказываем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(arr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.5116\n",
      "micro F1=0.5116, micro P=0.5116, micro R=0.5116\n",
      "macro F1=0.4597, macro P=0.4597, macro R=0.4597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_test(predicted, df_test.ClosingPrice_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Так же ситуация, кога на основе сгененрированных тем пробуем делать предсказания с помощью сети прямого распространения - FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.ClosingPrice_bin.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 2)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 810 samples, validate on 91 samples\n",
      "Epoch 1/20\n",
      "810/810 [==============================] - 1s 1ms/step - loss: 0.7036 - acc: 0.5099 - val_loss: 0.6850 - val_acc: 0.5275\n",
      "Epoch 2/20\n",
      "810/810 [==============================] - 0s 344us/step - loss: 0.7076 - acc: 0.4938 - val_loss: 0.6936 - val_acc: 0.4835\n",
      "Epoch 3/20\n",
      "810/810 [==============================] - 0s 333us/step - loss: 0.7036 - acc: 0.4741 - val_loss: 0.6901 - val_acc: 0.5055\n",
      "Epoch 4/20\n",
      "810/810 [==============================] - 0s 340us/step - loss: 0.7016 - acc: 0.5012 - val_loss: 0.6934 - val_acc: 0.4835\n",
      "Epoch 5/20\n",
      "810/810 [==============================] - 0s 341us/step - loss: 0.7049 - acc: 0.4704 - val_loss: 0.6908 - val_acc: 0.5604\n",
      "Epoch 6/20\n",
      "810/810 [==============================] - 0s 367us/step - loss: 0.7028 - acc: 0.5210 - val_loss: 0.7080 - val_acc: 0.4835\n",
      "Epoch 7/20\n",
      "810/810 [==============================] - 0s 370us/step - loss: 0.7001 - acc: 0.4877 - val_loss: 0.6935 - val_acc: 0.5055\n",
      "Epoch 8/20\n",
      "810/810 [==============================] - 0s 353us/step - loss: 0.7014 - acc: 0.4815 - val_loss: 0.6961 - val_acc: 0.4835\n",
      "Epoch 9/20\n",
      "810/810 [==============================] - 0s 385us/step - loss: 0.6946 - acc: 0.5309 - val_loss: 0.6903 - val_acc: 0.5165\n",
      "Epoch 10/20\n",
      "810/810 [==============================] - 0s 383us/step - loss: 0.6960 - acc: 0.5222 - val_loss: 0.6870 - val_acc: 0.4835\n",
      "Epoch 11/20\n",
      "810/810 [==============================] - 0s 348us/step - loss: 0.7013 - acc: 0.4617 - val_loss: 0.6940 - val_acc: 0.4725\n",
      "Epoch 12/20\n",
      "810/810 [==============================] - 0s 353us/step - loss: 0.7010 - acc: 0.4889 - val_loss: 0.6906 - val_acc: 0.5165\n",
      "Epoch 13/20\n",
      "810/810 [==============================] - 0s 364us/step - loss: 0.6955 - acc: 0.5198 - val_loss: 0.7353 - val_acc: 0.4835\n",
      "Epoch 14/20\n",
      "810/810 [==============================] - 0s 358us/step - loss: 0.6967 - acc: 0.5062 - val_loss: 0.6954 - val_acc: 0.4835\n",
      "Epoch 15/20\n",
      "810/810 [==============================] - 0s 355us/step - loss: 0.6951 - acc: 0.5062 - val_loss: 0.6878 - val_acc: 0.5165\n",
      "Epoch 16/20\n",
      "810/810 [==============================] - 0s 350us/step - loss: 0.6929 - acc: 0.4926 - val_loss: 0.6956 - val_acc: 0.4835\n",
      "Epoch 17/20\n",
      "810/810 [==============================] - 0s 346us/step - loss: 0.7021 - acc: 0.4975 - val_loss: 0.6918 - val_acc: 0.5275\n",
      "Epoch 18/20\n",
      "810/810 [==============================] - 0s 353us/step - loss: 0.6919 - acc: 0.5296 - val_loss: 0.6878 - val_acc: 0.4835\n",
      "Epoch 19/20\n",
      "810/810 [==============================] - 0s 352us/step - loss: 0.6974 - acc: 0.5136 - val_loss: 0.6896 - val_acc: 0.5165\n",
      "Epoch 20/20\n",
      "810/810 [==============================] - 0s 337us/step - loss: 0.6958 - acc: 0.4975 - val_loss: 0.6937 - val_acc: 0.4725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4d7bbcc0>"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(2,), activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(arr_train, y_train, epochs=nb_epoch, batch_size=8,  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258/258 [==============================] - 0s 633us/step\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict_classes(arr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predicted.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.5388\n",
      "micro F1=0.5388, micro P=0.5388, micro R=0.5388\n",
      "macro F1=0.3649, macro P=0.3649, macro R=0.3649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_test(predicted, df_test.ClosingPrice_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.98      0.70       140\n",
      "          1       0.40      0.02      0.03       118\n",
      "\n",
      "avg / total       0.48      0.54      0.39       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test.ClosingPrice_bin, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
