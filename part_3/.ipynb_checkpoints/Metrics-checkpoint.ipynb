{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a108c5eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a108e1080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "\n",
    "plt.gray() \n",
    "plt.matshow(digits.images[0]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определите модель с наилучшим показателем метрики accuracy, используя различные модели и варьируя их параметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что мы имеем:\n",
    "Обучающиеся алгоритмы. Возьмем только изученные из пакета sklearn:\n",
    "\n",
    "0. linear_model.LogisticRegression(http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "1. linear_model.SGDClassifier (http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)\n",
    "2. ensemble.RandomForestClassifier (http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "3. ensemble.BaggingClassifier (http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)\n",
    "4. ensemble.ExtraTreesClassifier (http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html)\n",
    "5. ensemble.VotingClassifier (http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)\n",
    "6. ensemble.AdaBoostClassifier (http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "7. neighbors.KNeighborsClassifier (http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "8. tree.DecisionTreeClassifier (http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "9. tree.ExtraTreeClassifier (http://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь подготовим данные для обучения, для этого разобъем данные на обучающую и тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь надо подготовить разные наборы параметов для обучения, для этого для каждого алгоритма нужно прописать серию параметов которые мы будем менять. Начнем по порядку:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDClassifier\n",
    "Основные параметры: \n",
    "- loss : str, default: ‘hinge’\n",
    "Функция потерь\n",
    "Возможные параметры для классификации: \n",
    "\n",
    "1. ‘hinge’ - кусочно-линейная функция потерь (или hinge loss). Которая зануляется на тех объектах, которые достаточно далеко от разделяющей поверхности\n",
    "2. ‘log’ - $$\\large logloss = - \\frac{1}{l} \\cdot \\sum_{i=1}^l (y_i \\cdot log(\\hat y_i) + (1 - y_i) \\cdot log(1 - \\hat y_i))$$  \n",
    "\n",
    "можно представить минимизацию logloss как задачу максимизации accuracy путем штрафа за неверные предсказания. Однако необходимо отметить, что logloss крайне сильно штрафует за уверенность классификатора в неверном ответе.\n",
    "\n",
    "3. ‘modified\\_huber’ - Функция потерь Хьюбера — это функция потерь, используемая в устойчивой регрессии, которая менее чувствительна к выбросам, чем квадратичная ошибка. ( https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D0%BF%D0%BE%D1%82%D0%B5%D1%80%D1%8C_%D0%A5%D1%8C%D1%8E%D0%B1%D0%B5%D1%80%D0%B0 )\n",
    "4. ‘squared_hinge’ - квадратичная функция потерь\n",
    "5. ‘perceptron’ - ХЗ что это за функция такая\n",
    "\n",
    "\n",
    "- penalty : str,\n",
    "Нормализация, т.е. штраф за выбросы\n",
    "Возможные параметры:\n",
    "‘none’, ‘l2’, ‘l1’, ‘elasticnet’\n",
    "\n",
    "- alpha : float\n",
    "\n",
    "Мультипликатор/множитель регуляризации. По умолчанию 0.0001 Так же используется для learning_rate когда он задан как ‘optimal’.\n",
    "\n",
    "- max_iter : int, optional\n",
    "\n",
    "Максимальное кол-во проходов по тренировочным данным \n",
    "\n",
    "- tol : float or None, optional\n",
    "\n",
    "Критерий остановки. Если None то остановка произойдет при условии (loss > previous_loss - tol)\n",
    "\n",
    "- shuffle : bool, optional\n",
    "\n",
    "Будут ли перемешаны данные после каждой эпохи/прохода. Defaults to True.\n",
    "\n",
    "- epsilon : float\n",
    "\n",
    "Указывает на интенсивность действия функции потерь. Только для функций потерь ‘huber’, ‘epsilon_insensitive’, ‘squared_epsilon_insensitive’. Для «huber» определяет порог, при котором становится менее важным получить правильное предсказание. Для эпсилон-чувствительности любые различия между текущим прогнозом и правильной меткой игнорируются, если они меньше этого порога.\n",
    "\n",
    "- learning_rate : string, optional\n",
    "\n",
    "Тип скорости обучения. \n",
    "Возможные значения:\n",
    "‘constant’: eta = eta0\n",
    "‘optimal’: eta = 1.0 / (alpha * (t + t0)) [default]\n",
    "‘invscaling’: eta = eta0 / pow(t, power_t)\n",
    "\n",
    "- eta0 : double\n",
    "\n",
    "Начальная скорость обучения для типов скорости обучения «constant» или «invscaling». Значение по умолчанию равно 0.0, так как eta0 не используется в типе по умолчанию ‘optimal’\n",
    "\n",
    "- class_weight : dict, {class_label: weight} or “balanced” or None, optional\n",
    "\n",
    "Предустановлен для параметра fit_weight. Веса, связанные с классами. Если не указано, все классы должны иметь вес один. «balanced» режим использует значения y для автоматической регулировки весов, обратно пропорциональных частотам класса во входных данных, как  n_samples / (n_classes * np.bincount(y))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создадим набор (структуру) для изменения параметров для grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimir/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SGD_data = {\n",
    "    \"model\" : SGDClassifier(),\n",
    "    \"params\" : {\n",
    "        \"loss\" : [\"hinge\", \"log\", \"modified_huber\", \"squared_hinge\", \"perceptron\"],\n",
    "        \"penalty\" : ['none', 'l2', 'l1', 'elasticnet'],\n",
    "        \"alpha\" : [10**float(c) for c in np.arange(-5,-3)],\n",
    "        \"shuffle\" : [True, False],\n",
    "        \"epsilon\" : [10**float(c) for c in np.arange(-5,0)],\n",
    "        \"learning_rate\" : [\"constant\", \"optimal\",\"invscaling\"],\n",
    "        \"eta0\" : [10**float(c) for c in np.arange(-5,0)],\n",
    "        \"class_weight\" : [\"balanced\", None],\n",
    "#         \"max_iter\" : np.linspace(5, 20, 10) # запишем сразу сюда то что получилось,а то больно долго считать еще раз\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression\n",
    "Основные параметры: \n",
    "- penalty : str, default: ‘l2’\n",
    "Нормализация, т.е. штраф за выбросы\n",
    "Возможные параметры:\n",
    "‘l2’, ‘l1’\n",
    "\n",
    "- dual : bool, default: False\n",
    "ХЗ что это, похоже на какой то двойной доп штраф когда количество фичей больше кол-ва примеров. По умолчанию выключено.\n",
    "Dual or primal formulation. Dual formulation is only implemented for l2 penalty with liblinear solver. Prefer dual=False when n_samples > n_features.\n",
    "\n",
    "- tol : float, default: 1e-4\n",
    "Tolerance - критерий остановки\n",
    "\n",
    "- C : float, default: 1.0\n",
    "Инвертированный коэффициент штрафа для регулляризации\n",
    "\n",
    "- class_weight : dict or ‘balanced’, default: None\n",
    "Либо в ручную засовываем веса для классов, либо выбираем balanced или никак не взвешиваем классы\n",
    "Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one.\n",
    "“balanced” режим использует значения y для автоматической корректировки весов, обратно пропорциональных частотам класса во входных данных, как n_samples / (n_classes * np.bincount(y)).\n",
    "\n",
    "- solver : {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default: ‘liblinear’ \n",
    "Алгоритм для решения оптимизационных проблем:\n",
    "Для маленьких выборок ‘liblinear’ - хороший выбор, в то время как ‘sag’ и ‘saga’ гораздо быстрее для больших выборок.\n",
    "Для мультиклассовых задач используется только ‘newton-cg’, ‘sag’, ‘saga’ и ‘lbfgs’\n",
    "\n",
    "‘liblinear’ ограничен схемой один против всех.\n",
    "\n",
    "‘newton-cg’, ‘lbfgs’ и ‘sag’ обрабатывают только L2 нормализацию, в то время как ‘liblinear’ и ‘saga’ обрабатывают L1 нормализацию.\n",
    "\n",
    "- max_iter : int, default: 100\n",
    "Используется только для newton-cg, sag и lbfgs решателей. Максимальное количество итераций, принятых для решателей.\n",
    "\n",
    "- multi_class : str, {‘ovr’, ‘multinomial’}, default: ‘ovr’\n",
    "Если выбранно ‘ovr’, то двоичная проблема обучается на каждой метке. Кроме того, минимизация потерь - это многочленная потеря, соответствующая всему распределению вероятности. Не работает для liblinear solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Создадим набор (структуру) для изменения параметров для grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_data = {\n",
    "    \"model\" : LogisticRegression(),\n",
    "    \"params\" : {\n",
    "#         \"penalty\" : ['l2', 'l1'],\n",
    "        \"tol\" : [10**float(c) for c in np.arange(-6,0)],\n",
    "        \"C\" : 10**np.linspace(-3, 1, 10),    \n",
    "        \"class_weight\" : [\"balanced\", None],\n",
    "        \"solver\" : ['newton-cg', 'sag', 'saga' , 'lbfgs'],\n",
    "#         \"max_iter\" : np.linspace(100, 1000, 10) #запишем сразу сюда то что получилось,а то больно долго считать еще раз\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем модели из записанного ранее кэша"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data for model SGDClassifier\n",
      "no data for model LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "models = [SGD_data, LR_data]\n",
    "results = {}\n",
    "for data in models:\n",
    "    model = data[\"model\"]\n",
    "    try:\n",
    "        results[model.__class__.__name__] = joblib.load('{}.pkl'.format(model.__class__.__name__)) \n",
    "        models.remove(data)\n",
    "    except:\n",
    "        print(\"no data for model {}\".format(model.__class__.__name__))\n",
    "    \n",
    "# type(result['SGDClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for data in models:\n",
    "    model = data[\"model\"]\n",
    "    params = data[\"params\"]\n",
    "    grid = params\n",
    "    gridsearch = GridSearchCV(model, grid, scoring='accuracy', cv=5)\n",
    "    result = gridsearch.fit(x_train, y_train)\n",
    "    results[ model.__class__.__name__] = result.best_estimator_\n",
    "    print(\"\"\"{} : \n",
    "best score: {}\n",
    "best estimator: {}\"\"\".format(key, result.best_score_, result.best_estimator_))\n",
    "    joblib.dump(result.best_estimator_ , '{}.pkl'.format(model.__class__.__name__)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
